.\"                                      Hey, EMACS: -*- nroff -*-
.\" First parameter, NAME, should be all caps
.\" Second parameter, SECTION, should be 1-8, maybe w/ subsection
.\" other parameters are allowed: see man(7), man(1)
.TH STRESS-NG 1 "23 October 2025"
.\" Please adjust this date whenever revising the manpage.
.\"
.\" Some roff macros, for reference:
.\" .nh        disable hyphenation
.\" .hy        enable hyphenation
.\" .ad l      left justify
.\" .ad b      justify to both left and right margins
.\" .nf        disable filling
.\" .fi        enable filling
.\" .br        insert line break
.\" .sp <n>    insert n+1 empty lines
.\" for manpage-specific macros, see man(7)
.\"
.\" left margin - right margin minus a fudge factor
.nr TW 0
.SH NAME
stress\-ng \- stress "next generation", a tool to load and stress a computer system
.sp 1
.SH SYNOPSIS
.B stress\-ng
[\fIOPTION \fR[\fIARG\fR]] ...
.sp 1
.SH DESCRIPTION
stress\-ng will stress test a computer system in various selectable ways. It
was designed to exercise physical subsystems of a computer as well as operating
system kernel interfaces.  stress\-ng also has a wide range of CPU specific
stress tests that exercise floating point, integer, bit manipulation, cache,
vector instructions and control flow.
.PP
stress\-ng was originally intended to make a machine work hard and trip
hardware issues such as thermal overruns as well as operating
system bugs that only occur when a system is being thrashed hard. Use
stress\-ng with caution as some of the tests can make a system run hot
on poorly designed hardware and also can cause excessive system thrashing
which may be difficult to stop.
.PP
stress\-ng can also measure test throughput rates; this can be
useful to observe performance changes across different
operating system releases or types of hardware. However, it has never been
intended to be used as a precise benchmark test suite, so do NOT use it
in this manner.
.PP
Running stress\-ng with root privileges will adjust out of memory settings
on Linux systems to make the stressors unkillable in low memory situations,
so use this judiciously.  With the appropriate privilege, stress\-ng can allow
the ionice class and ionice levels to be adjusted, again, this should be
used with care.
.PP
One can specify the number of processes to invoke per type of stress test;
specifying a zero value will select the number of processors
available as defined by sysconf(_SC_NPROCESSORS_CONF), if that can't be
determined then the number of online CPUs is used. If the value is less
than zero then the number of online CPUs is used. Specifying the number as
a percentage will select the percentage of configured CPUs (truncated
down to nearest whole number).
.SH OPTIONS
.PP
.B General stress\-ng control options:
.TP
.B \-\-abort
this option will force all running stressors to abort (terminate) if any
other stressor terminates prematurely because of a failure.
.TP
.B \-A, \-\-aggressive
enables more file, cache and memory aggressive options as well as forcing
processes to change CPU affinity very frequently. This will slow tests
down, increase latencies and reduce the number of bogo ops as well as changing
the balance of user time vs system time used depending on the type of stressor
being used.
.TP
.B \-a N, \-\-all N, \-\-parallel N
start N instances of all stressors in parallel. If N is less than zero, then
the number of CPUs online is used for the number of instances.  If N is zero,
then the number of configured CPUs in the system is used. Specifying N as a
percentage will select the percentage of configured CPUs (truncated down to
nearest whole number).
.SH OPTIONS
.TP
.B \-\-autogroup
with this option any successful nice(2) call will attempt to also set the
/proc/self/autogroup setting to the niceness level of the calling process. This
is a Linux only option for the CFS scheduler when CONFIG_SCHED_AUTOGROUP is
enabled, see sched(7) for more details on how this affects interactive scheduling
behaviour.
.TP
.B \-b N, \-\-backoff N
wait N microseconds between the start of each stress worker process. This
allows one to ramp up the stress tests over time.
.TP
.B \-\-buildinfo
report build information such as build date and time, compiler used,
compilation and linker flags, standard C version used.
.TP
.B \-\-c\-states
report CPU C-state residencies.
.TP
.B \-\-change\-cpu
this forces child processes of some stressors to change to a different CPU from the
parent on startup. Note that during the execution of the stressor the scheduler
may choose move the parent onto the same CPU as the child. The stressors affected
by this option are client/server style stressors, such as the network stressors
(sock, sockmany, udp, etc) or context switching stressors (switch, pipe, etc).
.TP
.B \-\-class name
specify the class of stressors to run. Stressors are classified into one or
more of the following classes: compute, cpu, cpu\-cache, device, fp, gpu, interrupt,
integer, ipc, io, filesystem, memory, network, os, pipe, scheduler, search, signal,
sort, vector and vm.
Some stressors fall into just one class. For example the `get' stressor is
just in the `os' class. Other stressors fall into more than one class, for example,
the `lsearch' stressor falls into the `cpu', `cpu\-cache', `memory' and `search'
classes as it exercises all these four.  Selecting a specific class
will run all the stressors that fall into that class only when run with
the \-\-sequential option.

Specifying a name followed by an escaped question mark (for example \-\-class vm\\?) will
print out all the stressors in that specific class.
.TP
.B \-\-config
print out the configuration used to build stress\-ng.
.TP
.B \-n, \-\-dry\-run
parse options, but do not run stress tests. A no-op.
.TP
.B \-\-ftrace
enable kernel function call tracing (Linux only).  This will use the
kernel debugfs ftrace mechanism to record all the kernel functions
used on the system while stress\-ng is running.  This is only as accurate
as the kernel ftrace output, so there may be some variability on the
data reported.
.TP
.B \-h, \-\-help
show help.
.TP
.B \-\-ignite\-cpu
alter kernel controls to try and maximize the CPU. This requires root
privilege to alter various /sys interface controls.  Currently this only
works for Intel P-State enabled x86 systems on Linux.
.TP
.B \-\-interrupts
check for any system management interrupts or error interrupts that occur,
for example thermal overruns, machine check exceptions, etc. Note that the
interrupts are accounted to all the concurrently running stressors, so total
count for all stressors is over accounted.
.TP
.B \-\-ionice\-class class
specify ionice class (only on Linux). Can be idle (default), besteffort, be,
realtime, rt.
.TP
.B \-\-ionice\-level level
specify ionice level (only on Linux). For idle, 0 is the only possible
option. For besteffort or realtime values 0 (highest priority) to 7 (lowest
priority). See ionice(1) for more details.
.TP
.B \-I S, \-\-iostat S
every S seconds show I/O statistics on the device that stores the stress\-ng
temporary files. This is either the device of the current working directory
or the \-\-temp\-path specified path. Currently a Linux only option.
The fields output are:
.sp
.TS
lB lB
l lx.
Column Heading	Explanation
T{
Inflight
T}	T{
number of I/O requests that have been issued to
the device driver but have not yet completed
T}
T{
Rd K/s
T}	T{
read rate in 1024 bytes per second
T}
T{
Wr K/s
T}	T{
write rate in 1024 bytes per second
T}
T{
Rd/s
T}	T{
reads per second
T}
T{
Wr/s
T}	T{
writes per second
T}
.TE
.TP
.B \-j jobfile, \-\-job jobfile
run stressors using a jobfile.  The jobfile is essentially a file containing
stress\-ng options (without the leading \-\-) with one option per line. Lines
may have comments with comment text proceeded by the # character. A simple
example is as follows:
.PP
.RS
.nf
\f[CR]
run sequential   # run stressors sequentially
verbose          # verbose output
metrics\-brief    # show metrics at end of run
timeout 60s      # stop each stressor after 60 seconds
#
# vm stressor options:
#
vm 2             # 2 vm stressors
vm\-bytes 128M    # 128 MB available memory shared by 2 vm stressors
vm\-keep          # keep vm mapping
vm\-populate      # populate memory
#
# memcpy stressor options:
#
memcpy 5         # 5 memcpy stressors
\f[]
.fi
.RE
.RS
.PP
The job file introduces the run command that specifies how to run the
stressors:
.PP
run sequential \- run stressors sequentially
.br
run parallel \- run stressors together in parallel
.PP
Note that `run parallel' is the default.
.RE
.TP
.B \-\-keep\-files
do not remove files and directories created by the stressors. This can be
useful for debugging purposes. Not generally recommended as it can fill up
a file system.
.TP
.B \-k, \-\-keep\-name
by default, stress\-ng will attempt to change the name of the stress
processes according to their functionality; this option disables this and
keeps the process names to be the name of the parent process, that is,
stress\-ng.
.TP
.B \-K, \-\-klog\-check
check the kernel log for kernel error and warning messages and report these
as soon as they are detected. Linux only and requires root capability to read
the kernel log.
.TP
.B \-\-ksm
enable kernel samepage merging (Linux only). This is a memory-saving de-duplication
feature for merging anonymous (private) pages.
.TP
.B \-\-limit\-as
set stressor process's maximum size of the virtual memory
(address space), see rlimit(2) RLIMIT_AS. The parameter can be specified
as an absolute number of bytes (e.g. 1G for 1 GB) or a percentage of
the current free memory, e.g. 20%
.TP
.B \-\-limit\-data
set stressor process's maximum size of the data segment (initialized data,
uninitialized data, and heap), see rlimit(2) RLIMIT_DATA. The parameter can
be specified as an absolute number of bytes (e.g. 128M for 128 MB) or a
percentage of the current free memory, e.g. 5%
.TP
.B \-\-limit\-stack
set stressor process's maximum size of the stack, see rlimit(2)
RLIMIT_STACK. The parameter can be specified as an absolute number of
bytes (e.g. 2M for 2 MB) or a percentage of the current free memory, e.g. 1%
.TP
.B \-\-log\-brief
by default stress\-ng will report the name of the program, the message type
and the process id as a prefix to all output. The \-\-log\-brief option will
output messages without these fields to produce a less verbose output.
.TP
.B \-L filename, \-\-log\-file filename
write messages to the specified log file, this does not replace the output
from stdout, but creates a logged copy of it in the specified file. Lines of
output are automatically fsync'd to the log file to try to reduce data loss.
.TP
.B \-\-log\-lockless
log messages use a lock to avoid intermingling of blocks of stressor messages,
however this may cause contention when emitting a high rate of logging messages
in verbose mode with many stressors are running, for example when testing CPU
scaling with many processes on many CPUs. This option disables log message
locking.
.TP
.B \-\-maximize
overrides the default stressor settings and instead sets these to the maximum
settings allowed.  These defaults can always be overridden by the per stressor
settings options if required.
.TP
.B \-\-max\-fd N
set the maximum limit on file descriptors (value or a % of system allowed
maximum).  By default, stress\-ng can use all the available file descriptors;
this option sets the limit in the range from 10 up to the maximum limit of
RLIMIT_NOFILE.  One can use a % setting too, e.g. 50% is half the maximum
allowed file descriptors.  Note that stress\-ng will use about 5 of the
available file descriptors so take this into consideration when using this
setting.
.TP
.B \-\-mbind list
set strict NUMA memory allocation based on the list of NUMA nodes provided;
page allocations will come from the node with sufficient free memory closest
to the specified node(s) where the allocation takes place. This uses the
Linux set_mempolicy(2) call using the MPOL_BIND mode.  The NUMA nodes to be
used are specified by a comma separated list of node (0 to N-1). One can
specify a range of NUMA nodes using `-', for example: \f[CR]\-\-mbind 0,2\-3,6,7\-11\f[]
.TP
.B \-M, \-\-metrics
output number of bogo operations in total performed by the stress processes.
Note that these are
.B not a reliable metric of performance or throughput
and
.B
have not been designed to be used for benchmarking whatsoever.
Some stressors have additional metrics that are more useful than bogo-ops, and
these are generally more useful for observing how a system behaves when under
various kinds of load.
.RS
.PP
The following columns of information are output:
.sp
.TS
lB lB
l lx.
Column Heading	Explanation
T{
bogo ops
T}	T{
number of iterations of the stressor during the run. This is metric of
how much overall "work" has been achieved in bogo operations.
.B
Do not use this as a reliable measure of throughput for benchmarking.
T}
T{
real time (secs)
T}	T{
average wall clock duration (in seconds) of the stressor. This is the total
wall clock time of all the instances of that particular stressor divided by
the number of these stressors being run.
T}
T{
usr time (secs)
T}	T{
total user time (in seconds) consumed running all the instances of the
stressor.
T}
T{
sys time (secs)
T}	T{
total system time (in seconds) consumed running all the instances of the
stressor.
T}
T{
bogo ops/s (real time)
T}	T{
total bogo operations per second based on wall clock run time. The wall clock
time reflects the apparent run time. The more processors one has on a system
the more the work load can be distributed onto these and hence the wall clock
time will reduce and the bogo ops rate will increase.  This is essentially
the "apparent" bogo ops rate of the system.
T}
T{
bogo ops/s (usr+sys time)
T}	T{
total bogo operations per second based on cumulative user and system time.
This is the real bogo ops rate of the system taking into consideration the
actual time execution time of the stressor across all the processors.
Generally this will decrease as one adds more concurrent stressors due to
contention on cache, memory, execution units, buses and I/O devices.
T}
T{
CPU used per instance (%)
T}	T{
total percentage of CPU used divided by number of stressor instances. 100%
is 1 full CPU. Some stressors run multiple threads so it is possible to have
a figure greater than 100%.
T}
T{
RSS Max (KB)
T}	T{
resident set size (RSS), the portion of memory (measured in Kilobytes) occupied by a process in main memory.
T}
.TE
.RE
.TP
.B \-\-metrics\-brief
show shorter list of stressor metrics (no CPU used per instance).
.TP
.B \-\-minimize
overrides the default stressor settings and instead sets these to the minimum
settings allowed.  These defaults can always be overridden by the per stressor
settings options if required.
.TP
.B \-\-no\-madvise
from version 0.02.26 stress\-ng automatically calls madvise(2) with random
advise options before each mmap and munmap to stress the vm subsystem a
little harder. The \-\-no\-advise option turns this default off.
.TP
.B \-\-no\-oom\-adjust
disable any form of out-of-memory score adjustments, keep the system defaults.
Normally stress\-ng will adjust the out-of-memory scores on stressors to try
to create more memory pressure. This option disables the adjustments.
.TP
.B \-\-no\-rand\-seed
Do not seed the stress\-ng pseudo\-random number generator with a quasi random
start seed, but instead seed it with constant values. This forces tests to
run each time using the same start conditions which can be useful when one
requires reproducible stress tests.
.TP
.B \-\-oom\-avoid
Attempt to avoid out-of-memory conditions that can lead to the Out-of-Memory
(OOM) killer terminating stressors. This checks for low memory scenarios and
swapping before making memory allocations and hence adds some overhead to the
stressors and will slow down stressor allocation speeds.
.TP
.B \-\-oom\-avoid\-bytes N
Specify a low memory threshold to avoid making any further memory allocations.
The parameter can be specified as an absolute number of bytes (e.g. 2M for 2 MB)
or a percentage of the current free memory, e.g. 5% (the default is 2.5%).
This option implicitly enables \-\-oom\-avoid.  The option allows the system
to have enough free memory to try to avoid the out-of-memory killer terminating
processes.
.TP
.B \-\-oom\-no\-child
Disable running stressor as a child process with a parent that checks for
Out-of-Memory (OOM) issues. This  reduces additional child process overhead but
indirectly also disables respawning of OOM'd stressors, OOM detection and
may lead to bogo-op verification errors.
.TP
.B \-O, \-\-oomable
Do not respawn a stressor if it gets killed by the Out-of-Memory (OOM) killer.
The default behaviour is to restart a new instance of a stressor if the kernel
OOM killer terminates the process. This option disables this default
behaviour.
.TP
.B \-\-page\-in
touch allocated pages that are not in core, forcing them to be paged back in.
This is a useful option to force all the allocated pages to be paged in when
using the bigheap, mmap and vm stressors.  It will severely degrade
performance when the memory in the system is less than the allocated buffer
sizes.  This uses mincore(2) to determine the pages that are not in core and
hence need touching to page them back in.
.TP
.B \-\-pathological
enable stressors that are known to hang systems. Some stressors can
rapidly consume resources that may hang a system, or perform actions that
can lock a system up or cause it to reboot. These stressors are not enabled
by default, this option enables them, but you probably don't want to do this.
You have been warned. This option applies to the stressors: bad\-ioctl,
bind\-mount, cpu\-online, mlockmany, oom\-pipe, smi, sysinval and watchdog.
.TP
.B \-\-pause T
pause T seconds between each stressor. This is useful for allowing systems
to cool down between each stressor invocation. By default this option is
disabled.
.TP
.B \-\-perf
measure processor and system activity using perf events. Linux only and
caveat emptor, according to perf_event_open(2): "Always double-check your
results! Various generalized events have had wrong values".  Note that
with Linux 4.7 one needs to have CAP_SYS_ADMIN capabilities for this
option to work, or adjust  /proc/sys/kernel/perf_event_paranoid to below
2 to use this without CAP_SYS_ADMIN.
.TP
.B \-\-permute N
run all permutations of the selected stressors with N instances of the
permutated stressors per run.  If N is less than zero, then the number
of CPUs online is used for the number of instances. If N is zero, then
the number of configured CPUs in the system is used.  Specifying N
as a percentage will select the percentage of configured CPUs
(truncated down to nearest whole number).  This will perform multiple
runs with all the permutations of the stressors up to 2\[ua]20
permumtations. Use this in conjunction with the \-\-with or \-\-class
option to specify the stressors to permute.
.TP
.B \-\-progress
display the run progress when running stressors with the \-\-sequential
option.
.TP
.B \-q, \-\-quiet
do not show any output.
.TP
.B \-r N, \-\-random N
start N random stress workers. If N is 0, then the number of configured
processors is used for N.
.TP
.B \-\-randprocname
enable random stressor process name generation. This scrambles the
stressor process names to try to confuse process monitoring and potential smart
process scheduling that uses process names to make system tuning changes.
.TP
.B \-\-rapl
Report the Running Average Power Limit (RAPL) energy measurements of
stressor instances. Currently Linux and x86 only, requires root access
rights to read RAPL kernel interfaces. Note that the RAPL domains supported
may vary between devices.
.TP
.B \-\-raplstat S
every S seconds show RAPL energy measurements. Currently Linux and x86 only,
requires root access rights to read RAPL kernel interfaces.
.TP
.B \-\-resctrl p1[,p2,..,pn],s1[,s2..,sm]
specify resource control cache partitions and apply to stressor instances (ARM MPAM only)
.IP
p1..pn are a list of 1 to n cache partitioning definitions, where p1..pn are of
the form:
.IP
pN=node[:cachelevel]:hexbitmask:bandwidth
.IP
where:
.RS
\(bu pN is the partition definition name where N is a number, e.g. p1
.br
\(bu node specifies cluster node of CPUs to use
.br
\(bu cachelevel specifies the cache level to use (optional, the default is the MPAM default L3 level)
.br
\(bu hexbitmask is a hexadecimal bitmask specifying cache portions to use
.br
\(bu bandwidth is the bandwidth to use, for MPAM this is % utilization 1..100
.RE
.IP
for example: \f[CR]p1=1:L3:fff:50\f[]
.IP
s1..sm are a list of 1 to m of stressor instances that apply these cache partitioning
settings of the form:
.IP
stressor-name=stressor-instances@pN
.IP
where:
.RS
\(bu stressor-name is the name of a stressor
.br
\(bu stressor-instances is a list of instances where cache partitioning setting pN is applied.
.br
\(bu pN specifies the cache partition pN
.RE
.IP
the following example applies resctrl partition p1 to the matrix stressor on instances 0, 1, 5, 8, 12, 13 and 14:
.IP
\f[CR]matrix=0-1,5,8,12-14@p1\f[]
.IP
The following example specifies two resctrl partitions, p1 uses cluster node 1, L3 cache,
uses the first 3 cache portions and sets this to 10% utilisation. p2 uses cluaser 1,
the default L3 cache, all cache portions except the first 32 and sets this to 90% utilisation.
The 3 stream stressor instances are run where stream stressor instances 0 to 1 use p1, and instance 2 uses p2.
.RS
.sp 1
.EX
\f[CR]sudo stress-ng --resctrl p1=1:l3:7:10,p2=1:ff8:90,\\
stream=0-1@p1,stream=2@p2 --stream 3\f[]
.EE
.PP
Note that invalid resctrl parameters applied to the resctrl sysfs will
generate EINVAL errors. They are not sanity checked during option parsing
as these can only be determined at the time they are applied.
.RE
.TP
.B \-\-sched scheduler
select the named scheduler (only on Linux). To see the list of available
schedulers use: stress\-ng \-\-sched which
.TP
.B \-\-sched\-prio prio
select the scheduler priority level (only on Linux). If the scheduler does
not support this then the default priority level of 0 is chosen.
.TP
.B \-\-sched\-period period
select the period parameter for deadline scheduler (only on Linux). Default
value is 0 (in nanoseconds).
.TP
.B \-\-sched\-runtime runtime
select the runtime parameter for deadline scheduler (only on Linux). Default
value is 99999 (in nanoseconds).
.TP
.B \-\-sched\-deadline deadline
select the deadline parameter for deadline scheduler (only on Linux). Default
value is 100000 (in nanoseconds).
.TP
.B \-\-sched\-reclaim
use cpu bandwidth reclaim feature for deadline scheduler (only on Linux).
.TP
.B \-\-seed N
set the random number generate seed with a 64 bit value. Allows stressors to
use the same random number generator sequences on each invocation.
.TP
.B \-\-settings
show the various option settings.
.TP
.B \-\-sequential N
sequentially run all the stressors one by one for a default of 60 seconds. The
number of instances of each of the individual stressors to be started is N.  If
N is less than zero, then the number of CPUs online is used for the number
of instances.  If N is zero, then the number of CPUs in the system is used.
Specifying N as a percentage will select the percentage of configured
CPUs (truncated down to nearest whole number).
.SH OPTIONS
Use the \-\-timeout option to specify the duration to run each stressor.
.TP
.B \-\-skip\-silent
silence messages that report that a stressor has been skipped because it
requires features not supported by the system, such as unimplemented system
calls, missing resources or processor specific features.
.TP
.B \-\-smart
scan the block devices for changes S.M.A.R.T. statistics (Linux only). This
requires root privileges to read the Self-Monitoring, Analysis and Reporting
Technology data from all block devies and will report any changes in the
statistics. One caveat is that device manufacturers provide different sets
of data, the exact meaning of the data can be vague and the data may be
inaccurate.
.TP
.B \-\-sn
use scientific notation (e.g. 2.412e+01) for metrics.
.TP
.B \-\-status N
report every N seconds the number of running, exiting, reaped and failed stressors,
number of stressors that received SIGARLM termination signal as well as the current
run duration.
.TP
.B \-\-stderr
write messages to stderr. With version 0.15.08 output is written to stdout,
previously due to a historical oversight output went to stderr. This
option allows one to revert to the pre-0.15.08 behaviour.
.TP
.B \-\-stdout
all output goes to stdout. This is the new default for version 0.15.08. Use
the \-\-stderr option for the original behaviour.
.TP
.B \-\-stressor\-time
(requires \-v flag) log as debug the start and finish run times of each stressor
instance, logged in the format: stressor [start|finish] HR:MN:SS.HS YYYY:MM:DD
where HR is hours, MN is minutes, SS is seconds, HS is hundredths of seconds,
YYYY is years, MM is months, DD is day of the month. If localtime(2) is not
supported the time is logged as seconds past the Epoch.
.TP
.B \-\-stressors
output the names of the available stressors.
.TP
.B \-\-sync\-start
synchromize start, wait for stressors to be created and start all stressors
once they are all in a ready to run state.
.TP
.B \-\-syslog
log output (except for verbose \-v messages) to the syslog.
.TP
.B \-\-taskset list
set CPU affinity based on the list of CPUs provided; stress\-ng is bound to
just use these CPUs (for systems that provide sched_setaffinity(2)). The CPUs
to be used are specified by a comma separated list of CPU (0 to N-1). One
can specify a range of CPUs using `-', for example: \f[CR]\-\-taskset 0,2\-3,6,7\-11\f[]
or the following keywords:
.sp
.TS
lB2 lB
l lx.
Keyword	Description
even	T{
even numbered CPUs
T}
odd	T{
odd numbered CPUs
T}
all	T{
all CPUs
T}
random	T{
random selection of CPUs
T}
packageN	T{
CPUs in package N as specified by /sys/devices/system/cpu/cpu*/topology/package_cpus_list
T}
clusterN	T{
CPUs in package N as specified by /sys/devices/system/cpu/cpu*/topology/cluster_cpus_list
T}
dieN	T{
CPUs in package N as specified by /sys/devices/system/cpu/cpu*/topology/die_cpus_list
T}
coreN	T{
CPUs in package N as specified by /sys/devices/system/cpu/cpu*/topology/core_cpus_list
T}
.TE
.TP
.B \-\-taskset\-random
randomly change stressor CPU affinity at five times the clock tick rate (if
defined) or at 400Hz while waiting for stressors to complete.
.TP
.B \-\-temp\-path path
specify a path for stress\-ng temporary directories and temporary files;
the default path is the current working directory.  This path must have
read and write access for the stress\-ng stress processes.
.TP
.B \-\-thermalstat S
every S seconds show CPU and thermal load statistics. This option shows
average CPU frequency in GHz (average of online-CPUs), the minimum CPU
frequency, the maximum CPU frequency, load averages (1 minute, 5 minute
and 15 minutes) and available thermal zone temperatures in degrees
Centigrade.
.TP
.B \-\-thrash
This can only be used when running on Linux and with root privilege. This
option starts a background thrasher process that works through all the
processes on a system and tries to page-in as many pages in the processes
as possible. It also periodically drops the page cache, frees reclaimable
slab objects and pagecache as well as assign pages to different NUMA nodes.
This will cause considerable amount of thrashing of swap on an
over-committed system.
.TP
.B \-t N, \-\-timeout T
run each stress test for at least T seconds. One can also specify the units
of time in seconds, minutes, hours, days or years with the suffix s, m, h,
d or y. Each stressor will be sent a SIGALRM signal at the timeout time, however
if the stress test is swapped out, in an uninterruptible system call or
performing clean up (such as removing hundreds of test file) it may take a
while to finally terminate.  A 0 timeout will run stress\-ng for ever with
no timeout. The default timeout is 24 hours.
.TP
.B \-\-times
show the cumulative user and system times of all the child processes at the
end of the stress run.  The percentage of utilisation of available CPU time is
also calculated from the number of on-line CPUs in the system.
.TP
.B \-\-timestamp
add a timestamp in hours, minutes, seconds and hundredths of a second to the
log output.
.TP
.B \-\-timer\-slack N
adjust the per process timer slack to N nanoseconds (Linux only). Increasing
the timer slack allows the kernel to coalesce timer events by adding some
fuzziness to timer expiration times and hence reduce wakeups.  Conversely,
decreasing the timer slack will increase wakeups.  A value of 0 for the
timer\-slack will set the system default of 50000 nanoseconds.
.TP
.B \-\-tz
collect temperatures from the available thermal zones on the machine (Linux
only).  Some devices may have one or more thermal zones, where as others may
have none.
.TP
.B \-v, \-\-verbose
show all debug, warnings and normal information output.
.TP
.B \-\-verify
verify results when a test is run. This is not available on all tests. This
will sanity check the computations or memory contents from a test run and
report with the `fail' tag failures that are detected.
.TP
.B \-\-verifiable
print the names of stressors that can be verified with the \-\-verify option.
.TP
.B \-V, \-\-version
show version of stress\-ng, version of toolchain used to build stress\-ng
and system information.
.TP
.B \-\-vmstat S
every S seconds show statistics about processes, memory, paging, block I/O,
interrupts, context switches, disks and cpu activity.  The output is similar
that to the output from the vmstat(8) utility. Not fully supported on various
UNIX systems.
.TP
.B \-\-vmstat\-units [ k | m | g | t | p | e ]
specify vmstat memory units in terms of kilobytes (k), megabytes (m), gigabytes (g),
terabytes (t), petabytes (p) or exabytes (e). Default is in kilobytes.
.TP
.B \-w, \-\-with list
specify stressors to run when using the \-\-all, \-\-seq or \-\-permute options.
For example to run 5 instances of the cpu, hash, nop and vm stressors one after
another (sequentially) for 1 minute per stressor use:
.PP
.in +10n
.EX
\f[CR]stress\-ng \-\-seq 5 \-\-with cpu,hash,nop,vm \-\-timeout 1m\f[]
.EE
.in -10n
.PP
.TP
.B \-x, \-\-exclude list
specify a list of one or more stressors to exclude (that is, do not run them).
This is useful to exclude specific stressors when one selects many stressors
to run using the \-\-class option, \-\-sequential, \-\-all and \-\-random
options. Example, run the cpu class stressors concurrently and exclude the
numa and search stressors:
.PP
.in +10n
.EX
\f[CR]stress\-ng \-\-class cpu \-\-all 1 \-x numa,bsearch,hsearch,lsearch\f[]
.EE
.in -10n
.PP
.TP
.B \-Y, \-\-yaml filename
output gathered statistics to a YAML formatted file named `filename'.
.br
.sp 2
.PP
.B Stressor specific options:
.TP
.B Access stressor
.RS 5
.TQ
.B \-\-access N
start N workers that work through various settings of file mode bits
(read, write, execute) for the file owner and checks if the user permissions
of the file using access(2) and faccessat(2) are sane.
.TP
.B \-\-access\-ops N
stop access workers after N bogo access sanity checks.
.RE
.TP
.B POSIX Access Control List Stressor
.RS 5
.TQ
.B \-\-acl N
start N workers that exercise permutations of ACL access permission settings
on user, group and other tags.
.TP
.B \-\-acl\-rand
randomize (by shuffling) the order of the ACL access permissions before exercising
ACLs.
.TP
.B \-\-acl\-ops N
stop acl workers after N bogo acl settings have been set.
.RE
.TP
.B Affinity stressor
.RS 5
.TQ
.B \-\-affinity N
start N workers that run 16 processes that rapidly change CPU affinity
(for systems that provide sched_setaffinity(2)). Rapidly switching CPU
affinity can contribute to poor cache behaviour and high context switch rate.
.TP
.B \-\-affinity\-delay N
delay for N nanoseconds before changing affinity to the next CPU.
The delay will spin on CPU scheduling yield operations for N nanoseconds
before the process is moved to another CPU. The default is 0 nanosconds.
.TP
.B \-\-affinity\-ops N
stop affinity workers after N bogo affinity operations.
.TP
.B \-\-affinity\-pin
pin all the 16 per stressor processes to a CPU. All 16 processes follow the
CPU chosen by the main parent stressor, forcing heavy per CPU loading.
.TP
.B \-\-affinity\-rand
switch CPU affinity randomly rather than the default of sequentially.
.TP
.B \-\-affinity\-sleep N
sleep for N nanoseconds before changing affinity to the next CPU.
.RE
.TP
.B Kernel crypto AF_ALG API stressor
.RS 5
.TQ
.B \-\-af\-alg N
start N workers that exercise the AF_ALG socket domain by hashing and encrypting
various sized random messages. This exercises the available hashes, ciphers,
rng and aead crypto engines in the Linux kernel.
.TP
.B \-\-af\-alg\-dump
dump the internal list representing cryptographic algorithms
parsed from the /proc/crypto file to standard output (stdout).
.TP
.B \-\-af\-alg\-ops N
stop af\-alg workers after N AF_ALG messages are hashed.
.RE
.TP
.B Asynchronous I/O stressor (POSIX AIO)
.RS 5
.TQ
.B \-\-aio N
start N workers that issue multiple small asynchronous I/O writes and reads on
a relatively small temporary file using the POSIX aio interface.  This will
just hit the file system cache and soak up a lot of user and kernel time in
issuing and handling I/O requests.  By default, each worker process will
handle 16 concurrent I/O requests.
.TP
.B \-\-aio\-ops N
stop POSIX asynchronous I/O workers after N bogo asynchronous I/O requests.
.TP
.B \-\-aio\-requests N
specify the number of POSIX asynchronous I/O requests each worker should issue,
the default is 16; 1 to 4096 are allowed.
.RE
.TP
.B Asynchronous I/O stressor (Linux AIO)
.RS 5
.TQ
.B \-\-aiol N
start N workers that issue multiple 4 K random asynchronous I/O writes using
the Linux aio system calls io_setup(2), io_submit(2), io_getevents(2) and
io_destroy(2).  By default, each worker process will handle 16 concurrent I/O
requests.
.TP
.B \-\-aiol\-ops N
stop Linux asynchronous I/O workers after N bogo asynchronous I/O requests.
.TP
.B \-\-aiol\-requests N
specify the number of Linux asynchronous I/O requests each worker should issue,
the default is 16; 1 to 4096 are allowed.
.RE
.TP
.B Alarm stressor
.RS 5
.TQ
.B \-\-alarm N
start N workers that exercise alarm(2) with MAXINT, 0 and random alarm and
sleep delays that get prematurely interrupted. Before each alarm is scheduled
any previous pending alarms are cancelled with zero second alarm calls.
.TP
.B \-\-alarm\-ops N
stop after N alarm bogo operations.
.RE
.TP
.B AppArmor stressor
.RS 5
.TQ
.B \-\-apparmor N
start N workers that exercise various parts of the AppArmor interface. Currently
one needs root permission to run this particular test. Only available
on Linux systems with AppArmor support and requires the CAP_MAC_ADMIN capability.
.TP
.B \-\-apparmor\-ops
stop the AppArmor workers after N bogo operations.
.RE
.TP
.B Atomic stressor
.RS 5
.TQ
.B \-\-atomic N
start N workers that exercise various GCC __atomic_*() built in operations
on 8, 16, 32 and 64 bit integers that are shared among the N workers. This
stressor is only available for builds using GCC 4.7.4 or higher. The stressor
forces many front end cache stalls and cache references. Note that 32 bit systems
do not currently exercise 64 bit integers.
.TP
.B \-\-atomic\-ops N
stop the atomic workers after N bogo atomic operations.
.RE
.TP
.B Bad alternative stack stressor
.RS 5
.TQ
.B \-\-bad\-altstack N
start N workers that create broken alternative signal stacks for SIGSEGV
and SIGBUS handling that in turn create secondary SIGSEGV/SIGBUS errors.
A variety of randomly selected nefarious methods are used to create the stacks:
.PP
.RS
.PD 0
.IP \(bu 2
Unmapping the alternative signal stack, before triggering the signal handling.
.IP \(bu 2
Changing the alternative signal stack to just being read only, write only, execute only.
.IP \(bu 2
Using a NULL alternative signal stack.
.IP \(bu 2
Using the signal handler object as the alternative signal stack.
.IP \(bu 2
Unmapping the alternative signal stack during execution of the signal handler.
.IP \(bu 2
Using a read-only text segment for the alternative signal stack.
.IP \(bu 2
Using an undersized alternative signal stack.
.IP \(bu 2
Using the VDSO as an alternative signal stack.
.IP \(bu 2
Using an alternative stack mapped onto /dev/zero.
.IP \(bu 2
Using an alternative stack mapped to a zero sized temporary file to generate a SIGBUS error.
.PD
.RE
.TP
.B \-\-bad\-altstack\-ops N
stop the bad alternative stack stressors after N SIGSEGV bogo operations.
.RE
.TP
.B Bad ioctl stressor
.RS 5
.TQ
.B \-\-bad\-ioctl N
start N workers that perform a range of illegal bad read ioctl(2) calls (using _IOR) and
write ioctls (using _IOR with PROT_NONE mapped pages) across the device drivers. This
exercises page size, 64 bit, 32 bit, 16 bit and 8 bit reads as well as NULL addresses,
non-readable pages and PROT_NONE mapped pages. Currently only for Linux and requires
the \-\-pathological option.
.TP
.B \-\-bad\-ioctl\-method [ inc | random | random\-inc | stride ]
select the method of changing the ioctl command (number, type) tuple per iteration, the
default is random\-inc.  Available bad-ioctl methods are described as follows:
.sp
.TS
lB2 lB
l lx.
Method	Description
inc	T{
increment ioctl command by 1
T}
random	T{
use a random ioctl command
T}
random\-inc	T{
increment ioctl command by a random value
T}
random\-stride	T{
increment ioctl command number by 1 and decrement command type by 3
T}
.TE
.TP
.B \-\-bad\-ioctl\-ops N
stop the bad ioctl stressors after N bogo ioctl operations.
.RE
.TP
.B Bessel functions
.RS 5
.TQ
.B \-\-besselmath N
start N workers that exercise various Bessel functions.  Results are sanity checked to
ensure no variation occurs after each round of 10000 computations.
.TP
.B \-\-besselmath\-ops N
stop after N bessel bogo-operation loops.
.TP
.B \-\-besselmath\-method method
specify a Bessel function to exercise. Available bessel stress methods are described
as follows:
.sp
.TS
lB2 lB
l lx.
Method	Description
all	T{
iterate over all the below Bessel functions methods
T}
j0	T{
double precision Bessel function of the first kind of order 0
T}
j1	T{
double precision Bessel function of the first kind of order 1
T}
jn	T{
double precision Bessel function of the first kind of order n (where n \(eq 5 for this test)
T}
j0f	T{
float precision Bessel function of the first kind of order 0
T}
j1f	T{
float precision Bessel function of the first kind of order 1
T}
jnf	T{
float precision Bessel function of the first kind of order n (where n \(eq 5 for this test)
T}
j0l	T{
long double precision Bessel function of the first kind of order 0
T}
j1l	T{
long double precision Bessel function of the first kind of order 1
T}
jnl	T{
long double precision Bessel function of the first kind of order n (where n \(eq 5 for this test)
T}
y0	T{
double precision Bessel function of the second kind of order 0
T}
y1	T{
youble precision Bessel function of the second kind of order 1
T}
yn	T{
double precision Bessel function of the second kind of order n (where n \(eq 5 for this test)
T}
y0f	T{
float precision Bessel function of the second kind of order 0
T}
y1f	T{
float precision Bessel function of the second kind of order 1
T}
ynf	T{
float precision Bessel function of the second kind of order n (where n \(eq 5 for this test)
T}
y0l	T{
long double precision Bessel function of the second kind of order 0
T}
y1l	T{
long double precision Bessel function of the second kind of order 1
T}
ynl	T{
long double precision Bessel function of the second kind of order n (where n \(eq 5 for this test)
T}
.TE
.RE
.TP
.B Big heap stressor
.RS 5
.TQ
.B \-B N, \-\-bigheap N
start N workers that grow their heaps by reallocating memory. If the out of
memory killer (OOM) on Linux kills the worker or the allocation fails then the
allocating process starts all over again.  Note that the OOM adjustment for the
worker is set so that the OOM killer will treat these workers as the first
candidate processes to kill.
.TP
.B \-\-bigheap\-bytes N
maximum heap growth as N bytes per bigheap worker. One can specify the size
as % of total available memory or in units of Bytes, KBytes, MBytes and GBytes
using the suffix b, k, m or g.
.TP
.B \-\-bigheap\-growth N
specify amount of memory to grow heap by per iteration. Size can be from 4 K to
64 MB. Default is 64 K.
.TP
.B \-\-bigheap\-mlock
attempt to mlock(2) future allocated pages into memory causing more memory pressure. If
mlock(MCL_FUTURE) is implemented then this will stop newly allocated pages from being
swapped out.
.TP
.B \-\-bigheap\-ops N
stop the big heap workers after N bogo allocation operations are completed.
.RE
.TP
.B Binderfs stressor
.RS 5
.TQ
.B \-\-binderfs N
start N workers that mount, exercise and unmount binderfs. The binder control
device is exercised with 256 sequential BINDER_CTL_ADD ioctl(2) calls per loop.
.TP
.B \-\-binderfs\-ops N
stop after N binderfs cycles.
.RE
.TP
.B Bind mount stressor
.RS 5
.TQ
.B \-\-bind\-mount N
start N workers that repeatedly bind mount / to / inside a user namespace. This
can consume resources rapidly, forcing out of memory situations. Do not use this
stressor unless you want to risk hanging your machine.
.TP
.B \-\-bind\-mount\-ops N
stop after N bind mount bogo operations.
.RE
.TP
.B Bitonic sort stressor
.RS 5
.TQ
.B \-\-bitonicsort N
start N workers that sort 32 bit integers using bitonic sort.
.TP
.B \-\-bitonicsort\-ops N
stop bitonic sort stress workers after N bogo bitonic sorts.
.TP
.B \-\-bitonicsort\-size N
specify number of 32 bit integers to sort, default is 262144 (256 \(mu 1024).
.RE
.TP
.B Bit Manipulation Operations
.RS 5
.TQ
.B \-\-bitops N
start N workers that perform various calculations using 32 bit integer manipulation operations. Many of these are derived from the Standford "Bit Twiddling Hacks" (Sean Eron Anderson) and Hacker's Delight (Henry S. Warren, Jr.)
.TP
.B \-\-bitops\-ops N
stop after N bitop operations.
.TP
.B \-\-bitops\-method method
specify bitops stress method. By default, all the bitops stress methods are exercised
sequentially, however one can specify just one method to be used if required.
Available bitops stress methods are described as follows:
.sp
.TS
lB2 lB
l lx.
Method	Description
all	T{
iterate over all the below bitops stress methods.
T}
abs	T{
calculate the absolute value of a 32 bit signed integer. Computed two different ways, one with masking and addition, one with masking and subtraction.
T}
countbits	T{
count the number of bits set to 1 in a 32 bit unsigned integer. Computed six different ways, two with bit counting, one with 64 bit multiplication, one with parallelised masking and shifting, one using triple masking and shifts, one using a builtin popcount function.
T}
clz	T{
count the number of leading zero bits in a 32 bit unsigned integer. Computed four different ways, one with bit counting, one with log2 shifting, one using a builtin popcount function, one using a builtin clz function,
T}
ctz	T{
count the number of trailing zero bits in a 32 bit unsigned integer. Computed five different ways, one with bit cointing, one using masking and shifting, one using the masking and ternary operator Gaudet method, one using a builtin clz function, one using a builtin popcount function.
T}
cmp	T{
compare two 32 bit unsigned integers with comparison results of -1, 0, 1 for less than, equal or greater than. Computed 3 ways, one using simple comparisons, two using comparisons and subtraction.
T}
log2	T{
calculate log base 2 of a 32 bit unsigned integer. Computed four ways, one using bit counting, one using masking and shifting and branching, one using masking and shifting with no branching, one using shifting and bitwise or'ing.
T}
max	T{
find the maximum of two 32 bit unsigned integers without a temporary variable. Computed two ways, one using xor'ing and masking, one using the ternary operator.
T}
min	T{
find the minimum of two 32 bit unsigned integers without a temporary variable. Computed two ways, one using xor'ing and masking, one using the ternary operator.
T}
parity	T{
compute the parity of a 32 bit unsigned integer. Computed five ways, two using bit counting, one using multiplication, shifting and xor'ing, one using shifting and xor'ing, one using a builtin parity function.
T}
pwr2	T{
determine if a 32 bit unsigned integer is a power of 2. Computed using bit counting and with mask of value \(mi 1.
T}
rnddnpwr2	T{
find the nearest power of 2 of a 32 bit unsigned integer, rounded down. Computed three ways, one using bit counting and shifting, one using shifting and or'ing, one using a shift and the builtin ctz function.
T}
rnduppwr2	T{
find the nearest power of 2 of a 32 bit unsigned integer, rounded up. Computed three ways, one using bit counting
and shifting, one using shifting and or'ing, one using a shift and the builtin ctz function.
T}
reverse	T{
reverse the bits of a 32 bit unsigned integer. Computed six ways, one using bit shifting loop, one using bit shitting and mask loop, one using parallelised masking and shifting, one using 64 bit multiplication, one using 32 bit multiplication, one using the builtin bitreverse32 function.
T}
sign	T{
calculate the sign of a 32 bit signed integer. Computed two ways, one using a branchless less than zero operator, one using sign bit shifting and negation.
T}
swap	T{
swap two 32 bit signed integers without a temporary variable. Computed two ways, one using subtraction and addition, one using xor'ing.
T}
zerobyte	T{
determine of a 32 bit unsigned integer contains one or more zero bytes. Computed two ways, one with per byte zero checking, one using bit masking.
T}
.TE
.RE
.TP
.B Branch stressor
.RS 5
.TQ
.B \-\-branch N
start N workers that randomly branch to 1024 randomly selected locations and
hence exercise the CPU branch prediction logic.
.TP
.B \-\-branch\-ops N
stop the branch stressors after N \(mu 1024 branches
.RE
.TP
.B Brk stressor
.RS 5
.TQ
.B \-\-brk N
start N workers that grow the data segment by one page at a time using multiple
brk(2) calls. Each successfully allocated new page is touched to ensure it is
resident in memory.  If an out of memory condition occurs then the test will
reset the data segment to the point before it started and repeat the data
segment resizing over again.  The process adjusts the out of memory setting so
that it may be killed by the out of memory (OOM) killer before other processes.
If it is killed by the OOM killer then it will be automatically re-started by
a monitoring parent process.
.TP
.B \-\-brk\-bytes N
maximum brk growth as N bytes per brk worker. One can specify the size
as % of total available memory or in units of Bytes, KBytes, MBytes and GBytes
using the suffix b, k, m or g.
.TP
.B \-\-brk\-mlock
attempt to mlock(2) future brk pages into memory causing more memory pressure. If
mlock(MCL_FUTURE) is implemented then this will stop new brk pages from being
swapped out.
.TP
.B \-\-brk\-notouch
do not touch each newly allocated data segment page. This disables the default
of touching each newly allocated page and hence avoids the kernel from
necessarily backing the page with physical memory.
.TP
.B \-\-brk\-ops N
stop the brk workers after N bogo brk operations.
.RE
.TP
.B Binary search stressor
.RS 5
.TQ
.B \-\-bsearch N
start N workers that binary search a sorted array of 32 bit integers using
bsearch(3). By default, there are 65536 elements in the array.  This is a
useful method to exercise random access of memory and processor cache.
.TP
.B \-\-bsearch\-method [ bsearch\-libc | bsearch\-nonlibc | ternary ]
select either the libc implementation of bsearch or a slightly optimized non-libc
implementation of bsearch or a 3-day ternary search. The default is the libc
implementation if it exists, otherwise the non-libc version.
.TP
.B \-\-bsearch\-ops N
stop the bsearch worker after N bogo bsearch operations are completed.
.TP
.B \-\-bsearch\-size N
specify the size (number of 32 bit integers) in the array to bsearch. Size can
be from 1 K to 64 M.
.RE
.TP
.B bubblesort stressor
.RS 5
.TQ
.B \-\-bubblesort N
start N workers that sort 32 bit integers using bubblesort.
.TP
.B \-\-bubblesort\-method [ bubblesort\-fast | bubblesort\-naive ]
select either a standard optimized implementation of bubblesort or a
naive unoptimized implementation of bubblesort. The default is the standard
optimized version.
.TP
.B \-\-bubblesort\-ops N
stop bubblesort stress workers after N bogo bubblesorts.
.TP
.B \-\-bubblesort\-size N
specify number of 32 bit integers to sort, default is 16384.
.RE
.TP
.B Cache stressor
.RS 5
.TQ
.B \-C N, \-\-cache N
start N workers that perform random wide spread memory read and writes to
thrash the CPU cache.  The code does not intelligently determine the CPU cache
configuration and so it may be sub-optimal in producing hit-miss read/write
activity for some processors.  Note: to exercise cache misses it is recommended
to instead use the matrix-3d stressor using the \-\-matrix\-3d\-zyx option.
.TP
.B \-\-cache\-cldemote
cache line demote (x86 only). This is a no-op for non-x86
architectures and older x86 processors that do not support this feature.
.TP
.B \-\-cache\-clflushopt
use optimized cache line flush (x86 only). This is a no-op for non-x86
architectures and older x86 processors that do not support this feature.
.TP
.B \-\-cache\-clwb
cache line writeback (x86 only). This is a no-op for non-x86
architectures and older x86 processors that do not support this feature.
.TP
.B \-\-cache\-enable\-all
where appropriate exercise the cache using cldemote, clflushopt, fence, flush, sfence and prefetch.
.TP
.B \-\-cache\-fence
force write serialization on each store operation (x86 only). This is a no-op
for non-x86 architectures.
.TP
.B \-\-cache\-flush
force flush cache on each store operation (x86 only). This is a no-op for
non-x86 architectures.
.TP
.B \-\-cache\-level N
specify level of cache to exercise (1 \(eq L1 cache, 2 \(eq L2 cache, 3 \(eq L3/LLC cache (the default)).
If the cache hierarchy cannot be determined, built-in defaults will apply.
.TP
.B \-\-cache\-no\-affinity
do not change processor affinity when
.B \-\-cache
is in effect.
.TP
.B \-\-cache\-ops N
stop cache thrash workers after N bogo cache thrash operations.
.TP
.B \-\-cache\-permute
permute the selected cache flags when exercising cache for an improved mix
of cache operations. Recommend also using \-\-cache\-enable\-all with this
option.
.TP
.B \-\-cache\-prefetch
force read prefetch on read address on architectures that support
prefetching.
.TP
.B \-\-cache\-prefetchw
force a redundant write prefetch on architectures that support
write prefetching.
.TP
.B \-\-cache\-sfence
force write serialization on each store operation using the sfence instruction
(x86 only). This is a no-op for non-x86 architectures.
.TP
.B \-\-cache\-size N
override the default cache size setting to N bytes. One can specify the
in units of Bytes, KBytes, MBytes and GBytes using the suffix b, k, m or g.
.TP
.B \-\-cache\-ways N
specify the number of cache ways to exercise. This allows a subset of
the overall cache size to be exercised.
.RE
.TP
.B Cache hammering stessor
.RS 5
.TQ
.B \-\-cachehammer N
start N workers that exercise the cache with a randomized mix of memory
read/writes and where possible cache prefetches and cache flushes to
random addresses in three memory mapped regions, one of which is shared
among all the cache stressors and is the size of the L3 cache, one is
local to each instance and is 4 times the L3 cache size and one is a single
page mapping that cannot be read or written.
.TP
.B \-\-cachehammer\-numa
periodically assign exercised pages to randomly selected NUMA nodes. This is disabled
for systems that do not support NUMA.
.TP
.B \-\-cachehammer\-ops N
stop after N cache hammer operations.
.RE
.TP
.B Cache line stressor
.RS 5
.TQ
.B \-\-cacheline N
start N workers that exercise reading and writing individual bytes
in a shared buffer that is the size of a cache line. Each stressor will run
1 or more processes to exercise bytes that are next to each other. The number
of per stressor processes run will be scaled so that at least all N bytes of
a N byte cache line are exercised.  The intent is to try and trigger
cacheline corruption, stalls and misses with shared memory accesses.
.TP
.B \-\-cacheline\-affinity
frequently change CPU affinity, spread cacheline processes evenly across all
online CPUs to try and maximize lower-level cache activity. Attempts to keep
adjacent cachelines being exercised by adjacent CPUs.
.TP
.B \-\-cacheline\-method method
specify a cacheline stress method. By default, all the stress methods are exercised
sequentially, however one can specify just one method to be used if required.
Available cacheline stress methods are described as follows:
.sp
.TS
lB2 lB
l lx.
Method	Description
all	T{
iterate over all the below cpu stress methods.
T}
adjacent	T{
increment a specific byte in a cacheline and read the adjacent byte, check for
corruption every 7 increments.
T}
atomicinc	T{
atomically increment a specific byte in a cacheline and check for
corruption every 7 increments.
T}
bits	T{
write and read back shifted bit patterns into specific byte in a cacheline
and check for corruption.
T}
copy	T{
copy an adjacent byte to a specific byte in a cacheline.
T}
inc	T{
increment and read back a specific byte in a cacheline and check for
corruption every 7 increments.
T}
mix	T{
perform a mix of increment, left and right rotates a specific byte in a
cacheline and check for corruption.
T}
rdfwd64	T{
increment a specific byte in a cacheline and then read in forward direction
an entire cacheline using 64 bit reads.
T}
rdints	T{
increment a specific byte in a cacheline and then read data at that byte
location in naturally aligned locations integer values of size 8, 16, 32, 64
and 128 bits.
T}
rdrev64	T{
increment a specific byte in a cacheline and then read in reverse direction
an entire cacheline using 64 bit reads.
T}
rdwr	T{
read and write the same 8 bit value into a specific byte in a cacheline and
check for corruption.
T}
.TE
.TP
.B \-\-cacheline\-ops N
stop cacheline workers after N loops of the byte exercising in a cacheline.
.RE
.TP
.B Process capabilities stressor
.RS 5
.TQ
.B \-\-cap N
start N workers that read per process capabilities via calls to capget(2)
(Linux only).
.TP
.B \-\-cap\-ops N
stop after N cap bogo operations.
.RE
.TP
.B Cgroup stressor
.RS 5
.TQ
.B \-\-cgroup N
start N workers that mount a cgroup, move a child to the cgroup, read, write and
remove the child from the cgroup and umount the cgroup per bogo-op iteration.
This uses cgroup v2 and is only available for Linux systems.
.TP
.B \-\-cgroup\-ops N
stop after N cgroup bogo operations.
.RE
.TP
.B Chattr stressor
.RS 5
.TQ
.B \-\-chattr N
start N workers that attempt to exercise file attributes via the
EXT2_IOC_SETFLAGS ioctl(2). This is intended to be intentionally racy and
exercise a range of chattr attributes by enabling and disabling them on
a file shared amongst the N chattr stressor processes. (Linux only).
.TP
.B \-\-chattr\-ops N
stop after N chattr bogo operations.
.RE
.TP
.B Chdir stressor
.RS 5
.TQ
.B \-\-chdir N
start N workers that change directory between directories using chdir(2).
.TP
.B \-\-chdir\-dirs N
exercise chdir on N directories. The default is 8192 directories, this allows
64 to 65536 directories to be used instead.
.TP
.B \-\-chdir\-ops N
stop after N chdir bogo operations.
.RE
.TP
.B Chmod stressor
.RS 5
.TQ
.B \-\-chmod N
start N workers that change the file mode bits via chmod(2) and fchmod(2) on
the same file. The greater the value for N then the more contention on the
single file.  The stressor will work through all the combination of mode bits.
.TP
.B \-\-chmod\-ops N
stop after N chmod bogo operations.
.RE
.TP
.B Chown stressor
.RS 5
.TQ
.B \-\-chown N
start N workers that exercise chown(2) on the same file. The greater the
value for N then the more contention on the single file.
.TP
.B \-\-chown\-ops N
stop the chown workers after N bogo chown(2) operations.
.RE
.TP
.B Chroot stressor
.RS 5
.TQ
.B \-\-chroot N
start N workers that exercise chroot(2) on various valid and invalid
chroot paths. Only available on Linux systems and requires the CAP_SYS_ADMIN
capability.
.TP
.B \-\-chroot\-ops N
stop the chroot workers after N bogo chroot(2) operations.
.RE
.TP
.B Complex hyperbolic functions stressor
.RS 5
.TQ
.B \-\-chyperbolic N
start N workers that exercise complex sinh, cosh, and tanh libm complex
hyperbolic functions using complex float, complex double and complex long
double floating point variants. Each function is exercised 10000 times per
bogo-operation.
.TP
.B \-\-chyperbolic\-method function
specify a complex hyperbolic stress function. By default, all the functions
are exercised sequentially, however one can specify just one function to be
used if required.  Available options are as follows:
.sp
.TS
lB2 lB
l lx.
Method	Description
all	T{
iterate through all of the following complex hyperbolic functions
T}
ccosh	T{
complex hyperbolic cosine (complex double precision)
T}
ccoshf	T{
complex hyperbolic cosine (complex float precision)
T}
ccoshl	T{
complex hyperbolic cosine (complex long double precision)
T}
csinh	T{
complex hyperbolic sine (complex double precision)
T}
csinhf	T{
complex hyperbolic sine (complex float precision)
T}
csinhl	T{
complex hyperbolic sine (complex long double precision)
T}
ctanh	T{
complex hyperbolic tangent (complex double precision)
T}
ctanhf	T{
complex hyperbolic tangent (complex float precision)
T}
ctanhl 	T{
complex hyperbolic tangent (complex long double precision)
T}
.TE
.TP
.B \-\-chyperbolic\-ops N
stop after N bogo-operations.
.RE
.TP
.B Clock stressor
.RS 5
.TQ
.B \-\-clock N
start N workers exercising clocks and POSIX timers. For all known clock types
this will exercise clock_getres(2), clock_gettime(2) and clock_nanosleep(2).
For all known timers it will create a random duration timer and busy poll this
until it expires. This stressor will cause frequent context switching.
.TP
.B \-\-clock\-ops N
stop clock stress workers after N bogo operations.
.RE
.TP
.B Clone stressor
.RS 5
.TQ
.B \-\-clone N
start N workers that create clones (via the clone(2) and clone3(2) system calls).
This will rapidly try to create a default of 8192 clones that immediately die
and wait in a zombie state until they are reaped.  Once the maximum number of
clones is reached (or clone fails because one has reached the maximum allowed)
the oldest clone thread is reaped and a new clone is then created in a first-in
first-out manner, and then repeated.  A random clone flag is selected for each
clone to try to exercise different clone operations.  The clone stressor is a Linux
only option.
.TP
.B \-\-clone\-max N
try to create as many as N clone threads. This may not be reached if the system
limit is less than N.
.TP
.B \-\-clone\-ops N
stop clone stress workers after N bogo clone operations.
.RE
.TP
.B Close stressor
.RS 5
.TQ
.B \-\-close N
start N workers that try to force race conditions on closing opened file
descriptors.  These file descriptors have been opened in various ways to try
and exercise different kernel close handlers.
.TP
.B \-\-close\-ops N
stop close workers after N bogo close operations.
.RE
.TP
.B Swapcontext stressor
.RS 5
.TQ
.B \-\-context N
start N workers that run three threads that use swapcontext(3) to implement the
thread-to-thread context switching. This exercises rapid process context saving
and restoring and is bandwidth limited by register and memory save and restore
rates.
.TP
.B \-\-context\-ops N
stop context workers after N bogo context switches.  In this stressor, 1 bogo
op is equivalent to 1000 swapcontext calls.
.RE
.TP
.B Copy file stressor
.RS 5
.TQ
.B \-\-copy\-file N
start N stressors that copy a file using the Linux copy_file_range(2) system
call. 128 KB chunks of data are copied from random locations from one file to
random locations to a destination file.  By default, the files are 256 MB in
size. Data is sync'd to the filesystem after each copy_file_range(2) call.
.TP
.B \-\-copy\-file\-bytes N
copy file size, the default is 256 MB. One can specify the size as % of free
space on the file system or in units of Bytes, KBytes, MBytes and GBytes using
the suffix b, k, m or g.
.TP
.B \-\-copy\-file\-ops N
stop after N copy_file_range() calls.
.RE
.TP
.B CPU stressor
.RS 5
.TQ
.B \-c N, \-\-cpu N
start N workers exercising the CPU by sequentially working through all the
different CPU stress methods. Instead of exercising all the CPU stress methods,
one can specify a specific CPU stress method with the \-\-cpu\-method option.
.TP
.B \-l P, \-\-cpu\-load P
load CPU with P percent loading for the CPU stress workers. 0 is effectively a
sleep (no load) and 100 is full loading.  The loading loop is broken into
compute time (load%) and sleep time (100% - load%). Accuracy depends on the
overall load of the processor and the responsiveness of the scheduler, so the
actual load may be different from the desired load.  Note that the number of
bogo CPU operations may not be linearly scaled with the load as some systems
employ CPU frequency scaling and so heavier loads produce an increased CPU
frequency and greater CPU bogo operations.

Note: This option only applies to the \-\-cpu stressor option and not to
all of the cpu class of stressors.
.TP
.B \-\-cpu\-load\-slice S
note: this option is only useful when \-\-cpu\-load is less than 100%. The
CPU load is broken into multiple busy and idle cycles. Use this option to
specify the duration of a busy time slice.  A negative value for S specifies
the number of iterations to run before idling the CPU (e.g. -30 invokes 30
iterations of a CPU stress loop).  A zero value selects a random busy time
between 0 and 0.5 seconds.  A positive value for S specifies the number of
milliseconds to run before idling the CPU (e.g. 100 keeps the CPU busy for
0.1 seconds).  Specifying small values for S lends to small time slices and
smoother scheduling.  Setting \-\-cpu\-load as a relatively low value and
\-\-cpu\-load\-slice to be large will cycle the CPU between long idle and
busy cycles and exercise different CPU frequencies.  The thermal range of
the CPU is also cycled, so this is a good mechanism to exercise the scheduler,
frequency scaling and passive/active thermal cooling mechanisms.

Note: This option only applies to the \-\-cpu stressor option and not to
all of the cpu class of stressors.
.TP
.B \-\-cpu\-method method
specify a cpu stress method. By default, all the stress methods are exercised
sequentially, however one can specify just one method to be used if required.
Available cpu stress methods are described as follows:
.sp
.TS
lB2 lB
l lx.
Method	Description
all	T{
iterate over all the below cpu stress methods
T}
ackermann	T{
Ackermann function: compute A(3, 7), where:
 A(m, n) \(eq n \(pl 1 if m \(eq 0;
 A(m \(mi 1, 1) if m > 0 and n \(eq 0;
 A(m \(mi 1, A(m, n \(mi 1)) if m > 0 and n > 0
.br
For other recursive methods, refer to the hanoi cpu stress method.
T}
apery	T{
calculate Apery's constant \[*z](3); the sum of 1/(n \[ua] 3) to a precision of 1.0x10\[ua]14
T}
bitops	T{
various bit operations from bithack, namely: reverse bits, parity check, bit
count, round to nearest power of 2
T}
callfunc	T{
recursively call 8 argument C function to a depth of 1024 calls and unwind
T}
cfloat	T{
1000 iterations of a mix of floating point complex operations
T}
cdouble	T{
1000 iterations of a mix of double floating point complex operations
T}
clongdouble	T{
1000 iterations of a mix of long double floating point complex operations
T}
collatz	T{
compute the 1348 steps in the collatz sequence starting from number 989345275647.
Where f(n) \(eq n / 2 (for even n) and f(n) \(eq 3n \(pl 1 (for odd n).
T}
correlate	T{
perform a 8192 \(mu 512 correlation of random doubles
T}
crc16	T{
compute 1024 rounds of CCITT CRC16 on random data
T}
decimal32	T{
1000 iterations of a mix of 32 bit decimal floating point operations (GCC only)
T}
decimal64	T{
1000 iterations of a mix of 64 bit decimal floating point operations (GCC only)
T}
decimal128	T{
1000 iterations of a mix of 128 bit decimal floating point operations (GCC
only)
T}
dither	T{
Floyd-Steinberg dithering of a 1024 \(mu 768 random image from 8 bits down to
1 bit of depth
T}
div8	T{
50000 8 bit unsigned integer divisions
T}
div16	T{
50000 16 bit unsigned integer divisions
T}
div32	T{
50000 32 bit unsigned integer divisions
T}
div64	T{
50000 64 bit unsigned integer divisions
T}
div128	T{
50000 128 bit unsigned integer divisions
T}
double	T{
1000 iterations of a mix of double precision floating point operations
T}
euler	T{
compute e using n \[eq] (1 \(pl (1 \[di] n)) \[ua] n
T}
explog	T{
iterate on n \[eq] exp(log(n) \[di] 1.00002)
T}
factorial	T{
find factorials from 1..150 using Stirling's and Ramanujan's approximations
T}
fibonacci	T{
compute Fibonacci sequence of 0, 1, 1, 2, 5, 8...
T}
fft	T{
4096 sample Fast Fourier Transform
T}
fletcher16	T{
1024 rounds of a na\[:i]ve implementation of a 16 bit Fletcher's checksum
T}
float	T{
1000 iterations of a mix of floating point operations
T}
float16	T{
1000 iterations of a mix of 16 bit floating point operations
T}
float32	T{
1000 iterations of a mix of 32 bit floating point operations
T}
float64	T{
1000 iterations of a mix of 64 bit floating point operations
T}
float80	T{
1000 iterations of a mix of 80 bit floating point operations
T}
float128	T{
1000 iterations of a mix of 128 bit floating point operations
T}
floatconversion	T{
perform 65536 iterations of floating point conversions between
float, double and long double floating point variables.
T}
gamma	T{
calculate the Euler\-Mascheroni constant \(*g using the limiting difference
between the harmonic series (1 \(pl 1/2 \(pl 1/3 \(pl 1/4 \(pl 1/5 ... \(pl 1/n) and the
natural logarithm ln(n), for n \(eq 80000.
T}
gcd	T{
compute GCD of integers
T}
gray	T{
calculate binary to gray code and gray code back to binary for integers
from 0 to 65535
T}
hamming	T{
compute Hamming H(8,4) codes on 262144 lots of 4 bit data. This turns 4 bit
data into 8 bit Hamming code containing 4 parity bits. For data bits d1..d4,
parity bits are computed as:
  p1 \(eq d2 \(pl d3 \(pl d4
  p2 \(eq d1 \(pl d3 \(pl d4
  p3 \(eq d1 \(pl d2 \(pl d4
  p4 \(eq d1 \(pl d2 \(pl d3
T}
hanoi	T{
solve a 21 disc Towers of Hanoi stack using the recursive solution. For
other recursive methods, refer to the ackermann cpu stress method.
T}
hyperbolic	T{
compute sinh(\(*h) \(mu cosh(\(*h) \(pl sinh(2\(*h) \(pl cosh(3\(*h) for float,
double and long double hyperbolic sine and cosine functions where \(*h \(eq 0
to 2\(*p in 1500 steps
T}
idct	T{
8 \(mu 8 IDCT (Inverse Discrete Cosine Transform).
T}
int8	T{
1000 iterations of a mix of 8 bit integer operations.
T}
int16	T{
1000 iterations of a mix of 16 bit integer operations.
T}
int32	T{
1000 iterations of a mix of 32 bit integer operations.
T}
int64	T{
1000 iterations of a mix of 64 bit integer operations.
T}
int128	T{
1000 iterations of a mix of 128 bit integer operations (GCC only).
T}
int32float	T{
1000 iterations of a mix of 32 bit integer and floating point operations.
T}
int32double	T{
1000 iterations of a mix of 32 bit integer and double precision floating point
operations.
T}
int32longdouble	T{
1000 iterations of a mix of 32 bit integer and long double precision floating
point operations.
T}
int64float	T{
1000 iterations of a mix of 64 bit integer and floating point operations.
T}
int64double	T{
1000 iterations of a mix of 64 bit integer and double precision floating point
operations.
T}
int64longdouble	T{
1000 iterations of a mix of 64 bit integer and long double precision floating
point operations.
T}
int128float	T{
1000 iterations of a mix of 128 bit integer and floating point operations
(GCC only).
T}
int128double	T{
1000 iterations of a mix of 128 bit integer and double precision floating point
operations (GCC only).
T}
int128longdouble	T{
1000 iterations of a mix of 128 bit integer and long double precision floating
point operations (GCC only).
T}
int128decimal32	T{
1000 iterations of a mix of 128 bit integer and 32 bit decimal floating point
operations (GCC only).
T}
int128decimal64	T{
1000 iterations of a mix of 128 bit integer and 64 bit decimal floating point
operations (GCC only).
T}
int128decimal128	T{
1000 iterations of a mix of 128 bit integer and 128 bit decimal floating point
operations (GCC only).
T}
intconversion	T{
perform 65536 iterations of integer conversions between
int16, int32 and int64 variables.
T}
ipv4checksum	T{
compute 1024 rounds of the 16 bit ones' complement IPv4 checksum.
T}
jmp	T{
Simple unoptimised compare >, <, == and jmp branching.
T}
lfsr32	T{
16384 iterations of a 32 bit Galois linear feedback shift register using
the polynomial x\[ua]32 \(pl x\[ua]31 \(pl x\[ua]29 \(pl x \(pl 1. This generates a
ring of 2\[ua]32 \(mi 1 unique values (all 32 bit values except for 0).
T}
ln2	T{
compute ln(2) based on series:
 1 \(mi 1/2 \(pl 1/3 \(mi 1/4 \(pl 1/5 \(mi 1/6 ...
T}
logmap	T{
16384 iterations computing chaotic double precision values using the logistic map
\[*X]\dn\(pl1\u \(eq r \(mu  \[*X]n \(mu (1 \(mi \[*X]n) where r > \(ap 3.56994567
T}
longdouble	T{
1000 iterations of a mix of long double precision floating point operations.
T}
loop	T{
simple empty loop.
T}
matrixprod	T{
matrix product of two 128 \(mu 128 matrices of double floats. Testing on 64
bit x86 hardware shows that this is provides a good mix of memory, cache and
floating point operations and is probably the best CPU method to use to make
a CPU run hot.
T}
nsqrt	T{
compute sqrt() of long doubles using Newton-Raphson.
T}
omega	T{
compute the omega constant defined by \(*We\[ua]\(*W \(eq 1 using efficient
iteration of \(*W\dn\(pl1\u \(eq (1 \(pl \(*Wn) / (1 \(pl e\[ua]\(*Wn).
T}
parity	T{
compute parity using various methods from the Standford Bit Twiddling Hacks.
Methods employed are: the na\[:i]ve way, the na\[:i]ve way with the Brian
Kernigan bit counting optimisation, the multiply way, the parallel way,
the lookup table ways (2 variations) and using the __builtin_parity(3) function.
T}
phi	T{
compute the Golden Ratio \(*f using series.
T}
pi	T{
compute \(*p using the Srinivasa Ramanujan fast convergence algorithm.
T}
prime	T{
find the first 10000 prime numbers using a slightly optimised brute
force na\[:i]ve trial division search.
T}
psi	T{
compute \(*q (the reciprocal Fibonacci constant) using the sum of the
reciprocals of the Fibonacci numbers.
T}
queens	T{
compute all the solutions of the classic 8 queens problem for board sizes 1..11.
T}
rand	T{
16384 iterations of rand(), where rand is the MWC pseudo
random number generator.
The MWC random function concatenates two 16 bit multiply\-with\-carry
generators:
 x(n) \(eq 36969 \(mu x(n \(mi 1) \(pl carry,
 y(n) \(eq 18000 \(mu y(n \(mi 1) \(pl carry mod 2 \[ua] 16
.sp 1
and has period of around 2 \[ua] 60.
T}
rand48	T{
16384 iterations of drand48(3) and lrand48(3).
T}
rgb	T{
convert RGB to YUV and back to RGB (CCIR 601).
T}
sieve	T{
find the first 10000 prime numbers using the sieve of Eratosthenes.
T}
stats	T{
calculate minimum, maximum, arithmetic mean, geometric mean, harmoninc mean
and standard deviation on 250 randomly generated positive double precision
values.
T}
sqrt	T{
compute sqrt(rand()), where rand is the MWC pseudo random number generator.
T}
trig	T{
compute sin(\(*h) \(mu cos(\(*h) \(pl sin(2\(*h) \(pl cos(3\(*h) for float, double
and long double sine and cosine functions where \(*h \(eq 0 to 2\(*p in 1500 steps.
T}
union	T{
perform integer arithmetic on a mix of bit fields in a C union.  This exercises
how well the compiler and CPU can perform integer bit field loads and stores.
T}
zeta	T{
compute the Riemann Zeta function \[*z](s) for s \(eq 2.0..10.0
T}
.TE
.RS
.PP
Note that some of these methods try to exercise the CPU with computations found
in some real world use cases. However, the code has not been optimised on a
per-architecture basis, so may be a sub-optimal compared to hand-optimised code
used in some applications.  They do try to represent the typical instruction
mixes found in these use cases.
.RE
.TP
.B \-\-cpu\-old\-metrics
as of version V0.14.02 the cpu stressor now normalizes each of the cpu
stressor method bogo-op counters to try and ensure a similar bogo-op rate
for all the methods to avoid the shorter running (and faster) methods from
skewing the bogo-op rates when using the default "all" method.
This is based on a reference Intel i5-8350U processor and hence the bogo-ops
normalizing factors will be skew somewhat on different CPUs, but so
significantly as the original bogo-op counter rates. To disable the normalization
and fall back to the original metrics, use this option.
.TP
.B \-\-cpu\-ops N
stop cpu stress workers after N bogo operations.
.RE
.TP
.B CPU onlining stressor
.RS 5
.TQ
.B \-\-cpu\-online N
start N workers that put randomly selected CPUs offline and online. This Linux
only stressor requires root privilege to perform this action. By default the
first CPU (CPU 0) is never offlined as this has been found to be problematic
on some systems and can result in a shutdown.
.TP
.B \-\-cpu\-online\-affinity
move the stressor worker to the CPU that will be next offlined.
.TP
.B \-\-cpu\-online\-all
The default is to never offline the first CPU.  This option will offline and
online all the CPUs including CPU 0. This may cause some systems to shutdown.
.TP
.B \-\-cpu\-online\-ops N
stop after offline/online operations.
.RE
.TP
.B CPU affinity scheduler stressor
.RS 5
.TQ
.B \-\-cpu\-sched N
start N workers that exercise the scheduler by moving processes to
different CPUs. Each worker starts 16 child processes and repeatedly
moves the processes to different CPUs and attempts changes their scheduler
policy using SCHED_OTHER, SCHED_BATCH, SCHED_IDLE, SCHED_EXT, SCHED_DEADLINE,
SCHED_RR and SCHED_FIFO policies. The choice of CPU placement is based on
8 different mechanisms and is changed every second to mix process placements
on all the available CPUS. The child processes are run with randomizied
nice settings to exercise scheduler prioritization.
.TP
.B \-\-cpu\-sched\-ops N
stop after N child process move attempts.
.RE
.TP
.B Crypt stressor
.RS 5
.TQ
.B \-\-crypt N
start N workers that encrypt a 16 character random password using crypt(3).
The password is encrypted using bcrypt bsdicrypt descrypt gost-yescrypt
MD5 NT scrypt SHA-1 SHA-256 SHA-512 SunMD5 and yescrypt encryption methods.
.TP
.B \-\-crypt\-method method
select the encryption method, may be one of: bcrypt, bsdicrypt, descrypt,
gost-yescrypt, MD5, NT, scrypt, SHA-1, SHA-256, SHA-512, SunMD5 and yescrypt.
The `all' method selects all the methods and is the default.
.TP
.B \-\-crypt\-ops N
stop after N bogo encryption operations.
.RE
.TP
.B Complex trigonometric functions stressor
.RS 5
.TQ
.B \-\-ctrig N
start N workers that exercise complex sin, complex cos and complex tan
libm trigonometric functions using complex float, complex double and
complex long double floating point variants. Each function is exercised
10000 times per bogo-operation.
.TP
.B \-\-ctrig\-method function
specify a trigonometric stress function. By default, all the functions are exercised
sequentially, however one can specify just one function to be used if required.
Available options are as follows:
.sp
.TS
lB2 lB
l lx.
Method	Description
all	T{
iterate through all of the following complex trigonometric functions
T}
ccos	T{
complex cosine (complex double precision)
T}
ccosf	T{
complex cosine (complex float precision)
T}
ccosl	T{
complex cosine (complex long double precision)
T}
csin	T{
complex sine (complex double precision)
T}
csinf	T{
complex sine (complex float precision)
T}
csinl	T{
complex sine (complex long double precision)
T}
ctan	T{
complex tangent (complex double precision)
T}
ctanf	T{
complex tangent (complex float precision)
T}
ctanl 	T{
complex tangent (complex long double precision)
T}
.TE
.RE
.TP
.B Cyclic stressor
.RS 5
.TQ
.B \-\-cyclic N
start N workers that exercise schedulers
with cyclic nanosecond sleeps. Normally one would just use 1 worker instance
with this stressor to get reliable statistics. By default this stressor measures the
first 10 thousand latencies and calculates the mean, mode, minimum, maximum
latencies along with various latency percentiles for the just the first
cyclic stressor instance. One has to run this stressor with CAP_SYS_NICE
capability to enable the real time scheduling policies. The FIFO scheduling
policy is the default.
.TP
.B \-\-cyclic\-dist N
calculate and print a latency distribution with the interval of N nanoseconds.
This is helpful to see where the latencies are clustering.
.TP
.B \-\-cyclic\-method [ clock_ns | itimer | poll | posix_ns | pselect | usleep ]
specify the cyclic method to be used, the default is clock_ns. The available
cyclic methods are as follows:
.sp
.TS
lB2 lB
l lx.
Method	Description
clock_ns	T{
sleep for the specified time using the clock_nanosleep(2) high
resolution nanosleep and the CLOCK_REALTIME real time clock.
T}
itimer	T{
wakeup a paused process with a CLOCK_REALTIME itimer signal.
T}
poll	T{
delay for the specified time using a poll delay loop that checks
for time changes using clock_gettime(2) on the CLOCK_REALTIME clock.
T}
posix_ns	T{
sleep for the specified time using the POSIX nanosleep(2) high
resolution nanosleep.
T}
pselect	T{
sleep for the specified time using pselect(2) with null file descriptors.
T}
usleep	T{
sleep to the nearest microsecond using usleep(2).
T}
.TE
.TP
.B \-\-cyclic\-ops N
stop after N sleeps.
.TP
.B \-\-cyclic\-policy [ batch | deadline | ext | fifo | idle| other | rr ]
specify the desired scheduling policy;  batch, deadline, ext, fifo (first\-in, first\-out)
idle, other or rr (round\-robin).
.TP
.B \-\-cyclic\-prio P
specify the scheduling priority P. Range from 1 (lowest) to 100 (highest).
.TP
.B \-\-cyclic\-samples N
measure N samples. Range from 1 to 100000000 samples.
.TP
.B \-\-cyclic\-sleep N
sleep for N nanoseconds per test cycle using clock_nanosleep(2) with the
CLOCK_REALTIME timer. Range from 1 to 1000000000 nanoseconds.
.RE
.TP
.B Daemon stressor
.RS 5
.TQ
.B \-\-daemon N
start N workers that each create a daemon that dies immediately after creating
another daemon and so on. This effectively works through the process table with
short lived processes that do not have a parent and are waited for by init.
This puts pressure on init to do rapid child reaping.  The daemon processes
perform the usual mix of calls to turn into typical UNIX daemons, so this
artificially mimics very heavy daemon system stress.
.TP
.B \-\-daemon\-ops N
stop daemon workers after N daemons have been created.
.TP
.B \-\-daemon\-wait
wait for daemon child processes rather than let init handle the waiting. Enabling
this option will reduce the daemon fork rate because of the synchronous wait
delays.
.RE
.TP
.B Datagram congestion control protocol (DCCP) stressor
.RS 5
.TQ
.B \-\-dccp N
start N workers that send and receive data using the Datagram Congestion
Control Protocol (DCCP) (RFC4340). This involves a pair of client/server
processes performing rapid connect, send and receives and disconnects on
the local host.
.TP
.B \-\-dccp\-domain D
specify the domain to use, the default is ipv4. Currently ipv4 and ipv6
are supported.
.TP
.B \-\-dccp\-if NAME
use network interface NAME. If the interface NAME does not exist, is not
up or does not support the domain then the loopback (lo) interface is used as the default.
.TP
.B \-\-dccp\-msgs N
send N messages per connect, send/receive, disconnect iteration. The default is 10000
messages. If N is too small then the rate is throttled back by the overhead of dccp
socket connect and disconnects.
.TP
.B \-\-dccp\-port P
start DCCP at port P. For N dccp worker processes, ports P to P \(mi 1 are
used.
.TP
.B \-\-dccp\-ops N
stop dccp stress workers after N bogo operations.
.TP
.B \-\-dccp\-opts [ send | sendmsg | sendmmsg ]
by default, messages are sent using send(2). This option allows one to specify
the sending method using send(2), sendmsg(2) or sendmmsg(2).  Note that
sendmmsg is only available for Linux systems that support this system call.
.RE
.TP
.B Mutex using Dekker algorithm stressor
.RS 5
.TQ
.B \-\-dekker N
start N workers that exercises mutex exclusion between two processes using
shared memory with the Dekker Algorithm. Where possible this uses memory fencing
and falls back to using GCC __sync_synchronize if they are not available. The
stressors contain simple mutex and memory coherency sanity checks.
.TP
.B \-\-dekker\-ops N
stop dekker workers after N mutex operations.
.RE
.TP
.B Dentry stressor
.RS 5
.TQ
.B \-D N, \-\-dentry N
start N workers that create and remove directory entries.  This should create
file system meta data activity. The directory entry names are suffixed by a
gray-code encoded number to try to mix up the hashing of the namespace.
.TP
.B \-\-dentry\-ops N
stop denty thrash workers after N bogo dentry operations.
.TP
.B \-\-dentry\-order [ forward | reverse | stride | random ]
specify unlink order of dentries, can be one of forward, reverse, stride
or random.
By default, dentries are unlinked in random order.  The forward
order will unlink them from first to last, reverse order will unlink
them from last to first, stride order will unlink them by stepping
around order in a quasi-random pattern and random order will randomly
select one of forward, reverse or stride orders.
.TP
.B \-\-dentries N
create N dentries per dentry thrashing loop, default is 2048.
.RE
.TP
.B /dev stressor
.RS 5
.TQ
.B \-\-dev N
start N workers that exercise the /dev devices. Each worker runs 5
concurrent threads that perform open(2), fstat(2), lseek(2), poll(2),
fcntl(2), mmap(2), munmap(2), fsync(2) and close(2) on each device.
Note that watchdog devices are not exercised.
.TP
.B \-\-dev\-file filename
specify the device file to exercise, for example, /dev/null. By default
the stressor will work through all the device files it can fine, however,
this option allows a single device file to be exercised.
.TP
.B \-\-dev\-ops N
stop dev workers after N bogo device exercising operations.
.RE
.TP
.B /dev/shm stressor
.RS 5
.TQ
.B \-\-dev\-shm N
start N workers that fallocate large files in /dev/shm and then mmap
these into memory and touch all the pages. This exercises pages being
moved to/from the buffer cache. Linux only.
.TP
.B \-\-dev\-shm\-ops N
stop after N bogo allocation and mmap /dev/shm operations.
.RE
.TP
.B Decimal floating point operations stressor
.RS 5
.TQ
.B \-\-dfp N
start N workers that exercise addition, multiplication and division
operations on a range of decimal floating point types. For each type,
8 floating point values are operated upon 65536 times in a loop per bogo op.
.TP
.B \-\-dfp\-method method
select the decimal floating point method to use, available methods are:
.sp
.TS
lB2 lB
l lx.
Method	Description
all	iterate over all the following floating point methods:
df32add	32 bit decimal floating point addition (_Decimal32)
df64add	64 bit decimal floating point addition (_Decimal64)
df128add	128 bit decimal floating point addition (_Decimal128)
df32sub	32 bit decimal floating point subtraction (_Decimal32)
df64sub	64 bit decimal floating point subtraction (_Decimal64)
df128sub	128 bit decimal floating point subtraction (_Decimal128)
df32mul	32 bit decimal floating point multiplication (_Decimal32)
df64mul	64 bit decimal floating point multiplication (_Decimal64)
df128mul	128 bit decimal floating point multiplication (_Decimal128)
df32div	32 bit decimal floating point division (_Decimal32)
df64div	64 bit decimal floating point division (_Decimal64)
df128div	128 bit decimal floating point division (_Decimal128)
.TE
.RS
.PP
Note that some of these decimal floating point methods may not be available on some systems.
.RE
.TP
.B \-\-dfp\-ops N
stop after N decimal floating point bogo ops.
.RE
.TP
.B Directories stressor
.RS 5
.TQ
.B \-\-dir N
start N workers that create, rename and remove directories using mkdir(2),
rename(2) and rmdir(2).
.TP
.B \-\-dir\-dirs N
exercise dir on N directories. The default is 8192 directories, this allows
64 to 65536 directories to be used instead.
.TP
.B \-\-dir\-ops N
stop directory thrash workers after N bogo directory operations.
.RE
.TP
.B Deep directories stressor
.RS 5
.TQ
.B \-\-dirdeep N
start N workers that create a depth-first tree of directories to a maximum
depth as limited by PATH_MAX or ENAMETOOLONG (which ever occurs first).
By default, each level of the tree contains one directory, but this can
be increased to a maximum of 10 sub-trees using the \-\-dirdeep\-dir option.
To stress inode creation, a symlink and a hardlink to a file at the root
of the tree is created in each level.
.TP
.B \-\-dirdeep\-bytes N
allocated file size, the default is 0. One can specify the size as % of free
space on the file system or in units of Bytes, KBytes, MBytes and GBytes using
the suffix b, k, m or g. Used in conjunction with the \-\-dirdeep\-files
option.
.TP
.B \-\-dirdeep\-dirs N
create N directories at each tree level. The default is just 1 but can be
increased to a maximum of 36 per level.
.TP
.B \-\-dirdeep\-files N
create N files  at each tree level. The default is 0 with the file size specified
by the \-\-dirdeep\-bytes option.
.TP
.B \-\-dirdeep\-inodes N
consume up to N inodes per dirdeep stressor while creating directories and
links. The value N can be the number of inodes or a percentage of the total
available free inodes on the filesystem being used.
.TP
.B \-\-dirdeep\-ops N
stop directory depth workers after N bogo directory operations.
.RE
.TP
.B Maximum files creation in a directory stressor
.RS 5
.TQ
.B \-\-dirmany N
start N stressors that create as many files in a directory as possible
and then remove them. The file creation phase stops when an error occurs
(for example, out of inodes, too many files, quota reached, etc.) and then
the files are removed. This cycles until the run time is reached or the
file creation count bogo-ops metric is reached. This is a much faster and
light weight directory exercising stressor compared to the dentry stressor.
.TP
.B \-\-dirmany\-bytes N
allocated file size, the default is 0. One can specify the size as % of free
space on the file system or in units of Bytes, KBytes, MBytes and GBytes using
the suffix b, k, m or g.
.TP
.B \-\-dirmany\-ops N
stop dirmany stressors after N empty files have been created.
.RE
.TP
.B Dnotify stressor
.RS 5
.TQ
.B \-\-dnotify N
start N workers performing file system activities such as making/deleting
files/directories, renaming files, etc. to stress exercise the various dnotify
events (Linux only).
.TP
.B \-\-dnotify\-ops N
stop dnotify stress workers after N dnotify bogo operations.
.RE
.TP
.B Dup stressor
.RS 5
.TQ
.B \-\-dup N
start N workers that perform dup(2) and then close(2) operations on /dev/zero.
The maximum opens at one time is system defined, so the test will run up to
this maximum, or 65536 open file descriptors, which ever comes first.
.TP
.B \-\-dup\-ops N
stop the dup stress workers after N bogo open operations.
.RE
.TP
.B Dynamic libraries loading stressor
.RS 5
.TQ
.B \-\-dynlib N
start N workers that dynamically load and unload various shared libraries. This
exercises memory mapping and dynamic code loading and symbol lookups. See
dlopen(3) for more details of this mechanism.
.TP
.B \-\-dynlib\-ops N
stop workers after N bogo load/unload cycles.
.RE
.TP
.B Easy CPU opcode stressor
.RS 5
.TQ
.B \-\-easy\-opcode N
start N workers that exercise 64 continuous pages of radomly selected
simple CPU opcodes.  For example, for x86 processors this just exercises
single byte opcodes such as nop and op-codes that set/clear CPU flags
to put pressure on the front-end decoder and instruction cache. For
RISC processors opcodes such as nop and simple register moves to/from
the same registers are used. Smart emulators may remove some of these
opcodes (e.g move r0,r0) and hence opcode rates may be artificially
high.
.TP
.B \-\-easy\-opcode\-ops N
stop after N executions of 64 continuous pages of opcodes.
.RE
.TP
.B Eigen C++ matrix library stressor
.RS 5
.TQ
.B \-\-eigen N
start N workers that exercise the Eigen C++ matrix library for 2D matrix
addition, multiplication, determinant, inverse and transpose operations
on long double, double and float matrices. This currently is only available
for gcc/g++ builds.
.TP
.B \-\-eigen\-method method
select the floating point method to use, available methods are:
.sp
.TS
lB lB
l lx.
Method	Description
all	T{
iterate over all the Eigen 2D matrix operations
T}
add\-longdouble	T{
addition of two matrices of long double floating point values
T}
add\-double	T{
addition of two matrices of double floating point values
T}
add\-float	T{
addition of two matrices of floating point values
T}
determinant\-longdouble	T{
determinant of matrix of long double floating point values
T}
determinant\-double	T{
determinant of matrix of double floating point values
T}
determinant\-float	T{
determinant of matrix of floating point values
T}
inverse\-longdouble	T{
inverse of matrix of long double floating point values
T}
inverse\-double	T{
inverse of matrix of double floating point values
T}
inverse\-float	T{
inverse of matrix of floating point values
T}
multiply\-longdouble	T{
multiplication of two matrices of long double floating point values
T}
multiply\-doublee	T{
multiplication of two matrices of double floating point values
T}
multiply\-float	T{
multiplication of two matrices of floating point values
T}
transpose\-longdouble	T{
transpose of matrix of long double floating point values
T}
transpose\-double	T{
transpose of matrix of double floating point values
T}
transpose\-float	T{
transpose of matrix of floating point values
T}
.TE
.TP
.B \-\-eigen\-ops N
stop after N Eigen matrix computations
.TP
.B \-\-eigen\-size N
specify the 2D matrix size N \(mu N. The default is a 32 \(mu 32 matrix.
.RE
.TP
.B EFI variables stressor
.RS 5
.TQ
.B \-\-efivar N
start N workers that exercise the Linux /sys/firmware/efi/efivars and
/sys/firmware/efi/vars interfaces by reading the EFI variables. This
is a Linux only stress test for platforms that support the EFI vars
interface and may require the CAP_SYS_ADMIN capability.
.TP
.B \-\-efivar\-ops N
stop the efivar stressors after N EFI variable read operations.
.RE
.TP
.B Non-functional system call (ENOSYS) stressor
.RS 5
.TQ
.B \-\-enosys N
start N workers that exercise non-functional system call numbers. This calls
a wide range of system call numbers to see if it can break a system where these
are not wired up correctly.  It also keeps track of system calls that exist
(ones that don't return ENOSYS) so that it can focus on purely finding and
exercising non-functional system calls. This stressor exercises system calls
from 0 to __NR_syscalls \(pl 1024, random system calls within constrained in the
ranges of 0 to 2\[ua]8, 2\[ua]16, 2\[ua]24, 2\[ua]32, 2\[ua]40, 2\[ua]48,
2\[ua]56 and 2\[ua]64 bits, high system call numbers and various other bit
patterns to try to get wide coverage. To keep the environment clean, each
system call being tested runs in a child process with reduced capabilities.
.TP
.B \-\-enosys\-ops N
stop after N bogo enosys system call attempts
.RE
.TP
.B Environment variables stressor
.RS 5
.TQ
.B \-\-env N
start N workers that creates numerous large environment variables to try to
trigger out of memory conditions using setenv(3).  If ENOMEM occurs then the
environment is emptied and another memory filling retry occurs.  The process
is restarted if it is killed by the Out Of Memory (OOM) killer.
.TP
.B \-\-env\-ops N
stop after N bogo setenv/unsetenv attempts.
.RE
.TP
.B Epoll stressor
.RS 5
.TQ
.B \-\-epoll N
start N workers that perform various related socket stress activity using
epoll_wait(2) to monitor and handle new connections. This involves
client/server processes performing rapid connect, send/receives and disconnects
on the local host.  Using epoll allows a large number of connections to be
efficiently handled, however, this can lead to the connection table filling up
and blocking further socket connections, hence impacting on the epoll bogo op
stats.  For ipv4 and ipv6 domains, multiple servers are spawned on multiple
ports. The epoll stressor is for Linux only.
.TP
.B \-\-epoll\-domain D
specify the domain to use, the default is unix (aka local). Currently ipv4,
ipv6 and unix are supported.
.TP
.B \-\-epoll\-ops N
stop epoll workers after N bogo operations.
.TP
.B \-\-epoll\-port P
start at socket port P. For N epoll worker processes, ports P to (P \(mu 4) \(mi 1
are used for ipv4, ipv6 domains and ports P to P \(mi 1 are used for the unix
domain.
.TP
.B \-\-epoll\-sockets N
specify the maximum number of concurrently open sockets allowed in server.
Setting a high value impacts on memory usage and may trigger out of memory
conditions.
.RE
.TP
.B Event file descriptor (eventfd) stressor
.RS 5
.TQ
.B \-\-eventfd N
start N parent and child worker processes that read and write 8 byte event
messages between them via the eventfd mechanism (Linux only).
.TP
.B \-\-eventfd\-nonblock
enable EFD_NONBLOCK to allow non-blocking on the event file descriptor. This
will cause reads and writes to return with EAGAIN rather the blocking and hence
causing a high rate of polling I/O.
.TP
.B \-\-eventfd\-ops N
stop eventfd workers after N bogo operations.
.RE
.TP
.B Exec processes stressor
.RS 5
.TQ
.B \-\-exec N
start N workers continually forking children that exec stress\-ng and then exit
almost immediately. If a system has pthread support then 1 in 4 of the exec's
will be from inside a pthread to exercise exec'ing from inside a pthread
context.
.TP
.B \-\-exec\-fork\-method [ clone | fork | rfork | spawn | vfork ]
select the process creation method using clone(2), fork(2), BSD rfork(2),
posix_spawn(3) or vfork(2). Note that vfork will only exec programs using
execve due to the constraints on the shared stack between the parent and
the child process.
.TP
.B \-\-exec\-max P
create P child processes that exec stress\-ng and then wait for them to exit per
iteration. The default is 4096; higher values may create many temporary
zombie processes that are waiting to be reaped. One can potentially fill up the
process table using high values for \-\-exec\-max and \-\-exec.
.TP
.B \-\-exec\-method [ all | execve | execveat | fexecve ]
select the exec system call to use; all will perform a random choice between
execve(2), execveat(2) and fexecve(3), execve will use execve(2), execveat will use
execveat(2) (if available) and fexecve will use fexecve(3) (if available).
.TP
.B \-\-exec\-no\-pthread
do not use pthread_create(3).
.TP
.B \-\-exec\-ops N
stop exec stress workers after N bogo operations.
.RE
.TP
.B Exiting pthread groups stressor
.RS 5
.TQ
.B \-\-exit\-group N
start N workers that create 16 pthreads and terminate the pthreads and
the controlling child process using exit_group(2). (Linux only stressor).
.TP
.B \-\-exit\-group\-ops N
stop after N iterations of pthread creation and deletion loops.
.RE
.TP
.B Exponential functions
.RS 5
.TQ
.B \-\-expmath N
start N workers that exercise various exponential functions with input values 0 to 1 in steps of 0.001;
the results are sanity checked to ensure no variation occurs after each round of 10000 computations.
.TP
.B \-\-expmath\-ops N
stop after N exponential bogo-operation loops.
.TP
.B \-\-expmath\-method method
specify a exponential function to exercise. Available exponential stress methods are described
as follows:
.sp
.TS
lB2 lB
l lx.
Method	Description
all	T{
iterate over all the below exponential functions methods
T}
cexp	T{
double complex natural exponential
T}
cexpf	T{
float complex natural exponential
T}
cexpl	T{
long double complex natural exponential
T}
exp	T{
double natural exponential
T}
expf	T{
float natural exponential
T}
expl	T{
long double natural exponential
T}
exp10	T{
double base-10 exponential
T}
exp10f	T{
float base-10 exponential
T}
exp10l	T{
long double base-10 exponential
T}
exp2	T{
double base-2 exponential
T}
exp2f	T{
float base-2 exponential
T}
exp2l	T{
long double base-2 exponential
T}
.TE
.RE
.TP
.B Factorization of large integers stressor
.RS 5
.TQ
.B \-\-factor N
start N workers that factorize large integers using the GNU Multiple Precision
Arithmetic Library. Randomized values to be factorized are computed so that
an N digit value is comprised of about 0.4 \(mu N random factors,
for N > 100. The default number of digits in the value to be factorized is 10.
.TP
.B \-\-factor\-digits N
select the number of digits in the values to be factorized. Range 8 to 100000000
digits, default is 10.
.TP
.B \-\-factor\-ops N
stop after N factorizations.
.RE
.TP
.B File space allocation (fallocate) stressor
.RS 5
.TQ
.B \-F N, \-\-fallocate N
start N workers continually fallocating (preallocating file space) and
ftruncating (file truncating) temporary files.  If the file is larger than the
free space, fallocate will produce an ENOSPC error which is ignored by this
stressor.
.TP
.B \-\-fallocate\-bytes N
allocated file size, the default is 1 GB. One can specify the size as % of free
space on the file system or in units of Bytes, KBytes, MBytes and GBytes using
the suffix b, k, m or g.
.TP
.B \-\-fallocate\-ops N
stop fallocate stress workers after N bogo fallocate operations.
.RE
.TP
.B Filesystem notification (fanotify) stressor
.RS 5
.TQ
.B \-\-fanotify N
start N workers performing file system activities such as creating, opening,
writing, reading and unlinking files to exercise the fanotify event monitoring
interface (Linux only). Each stressor runs a child process to generate file
events and a parent process to read file events using fanotify. Has to be run
with CAP_SYS_ADMIN capability.
.TP
.B \-\-fanotify\-ops N
stop fanotify stress workers after N bogo fanotify events.
.RE
.TP
.B CPU branching instruction cache stressor
.RS 5
.TQ
.B \-\-far\-branch N
start N workers that exercise calls to tens of thousands of
functions that are relatively far from the caller. All functions
are 1 op instructions that return to the caller. The functions
are placed in pages that are memory mapped with a wide spread of
fixed virtual addresses.  Function calls are pre-shuffled
to create a randomized mix of addresses to call. This stresses the
instruction cache and any instruction TLBs.
.TP
.B \-\-far\-branch\-flush
attempt to periodically flush instruction cache to produce instruction
cache misses.
.TP
.B \-\-far\-branch\-ops N
stop after N far branch bogo-ops. One full cycle of calling all
the tens of thousands of functions equates to one bogo-op.
.TP
.B \-\-far\-branch\-pageout
where possible pageout and soft-offline randomly selected pages
that contain the far branch functions. This uses madvise(2) MADV_PAGEOUT
and MADV_SOFT_OFFLINE to perform these actions.
.TP
.B \-\-far\-branch\-pages N
specify the number of pages to allocate for far branch functions. The
number for functions per page depends on the processor architecture,
for example, x86 will have 4096 x 1 byte return instructions per 4 K
page, where as SPARC64 will have only 512 x 8 byte return instructions
per 4 K page.
.RE
.TP
.B Page fault stressor
.RS 5
.TQ
.B \-\-fault N
start N workers that generates minor and major page faults.
.TP
.B \-\-fault\-ops N
stop the page fault workers after N bogo page fault operations.
.RE
.TP
.B Fcntl stressor
.RS 5
.TQ
.B \-\-fcntl N
start N workers that perform fcntl(2) calls with various commands.  The
exercised commands (if available) are: F_CREATED_QUERY, F_DUPFD,
F_DUPFD_CLOEXEC, F_GETFD, F_SETFD, F_GETFL, F_SETFL, F_GETOWN,
F_SETOWN, F_GETOWN_EX, F_SETOWN_EX, F_GETSIG, F_SETSIG, F_GETOWNER_UIDS,
F_GETLEASE, F_GETLK, F_SETLK, F_SETLKW, F_UNLCK, F_OFD_GETLK, F_OFD_SETLK,
F_OFD_SETLKW, F_GET_FILE_RW_HINT, F_SET_FILE_RW_HINT, F_GET_RW_HINT
and F_SET_RW_HINT.
.TP
.B \-\-fcntl\-ops N
stop the fcntl workers after N bogo fcntl operations.
.RE
.TP
.B File descriptor abusing stressor
.RS 5
.TQ
.B \-\-fd\-abuse N
start N workers that open file descriptors using various ways (file, dup,
socket, pipe, timerfd, pidfd, userfaultfd, etc.) and perform valid
and invalid file operations on these descriptors. This exercises a mix of
successful and failed file operations on a wide range of file descriptor types.
.TP
.B \-\-fd\-abuse\-ops N
stop after N file abuse file operation bogo-ops.
.RE
.TP
.B File descriptor duplication and closing stressor
.RS 5
.TQ
.B \-\-fd\-fork N
start N workers that open files using dup(2) on a file (/dev/zero by default)
and then copies these using multiple fork'd child processes and closes them
with the fast clone_range(2) or close(2) or by directly ending the processes
using _exit(2). For every bogo-op, the stressor attempts to dup(2) another
10000 file descriptors up to the maximum allowed, fork 8 child processes
that then close their copies of the file descriptors.
.TP
.B \-\-fd\-fork\-fds N
specify maximum number of file descriptors to be opened. The default
is 2 million, with a range of 1000 to 16 million. The actual number
used may be less depending on the system defined limits of the number
of open files per process.
.TP
.B \-\-fd\-fork\-file [ null | random | stdin | stdout | zero ]
specify file to dup: null for /dev/null, random for /dev/random,
stdin for standard input, stdout for standard output, zero for /dev/zero.
Default is /dev/zero.
.TP
.B \-\-fd\-fork\-ops N
stop after N rounds of 10000 dups, forking/closing/exiting and waiting for
the child processes. Note that the bogo\-ops metric rate will slow down
over time as this stressor increases the number of open files per bogo-loop
and this increases the fork and close run times.
.RE
.TP
.B File descriptor race stressor
.RS 5
.TQ
.B \-\-fd\-race N
start N workers that attempt to force race conditions on opened file descriptors.
Opened file descriptors are passed from a server to a client over a socket. At
periodic intervals batches of the file descriptors are duplicated by creating multiple
pthreads and then closed en-masse with synchronized pthread termination. Also other
concurrent pthreads exercise various file based system calls on file descriptors that
are in the process of being created. By default a single file is used for the
open calls, however /dev and /proc files can be exercised using the appropriate
fd\-race options.
.TP
.B \-\-fd\-race\-dev
exercise /dev files for race conditions.
.TP
.B \-\-fd\-race\-race\-ops N
stop after N file descriptors have been exercised.
.TP
.B \-\-fd\-race\-proc
exercise /proc files for race conditions.
.RE
.TP
.B Fibonacci search stressor
.RS 5
.TQ
.B \-\-fibsearch N
start N workers that use a search a sorted array of 32 bit
integers using a Fibonacci search. A Fibonacci seaarch is similar to a bsearch
except that it uses the Fibonacci series to divide the search into unequal sized spaces. It
avoids the costly division operator found in bsearches and examines closer elements on each
search step so there is a slight compute and cache advantage over bsearch.
By default, there are 65536 elements in the array.
This is a useful method to exercise random access of memory and processor cache.
.TP
.B \-\-fibsearch\-ops N
stop the fibsearch worker after N bogo fibsearch operations are completed.
.TP
.B \-\-fibsearch\-size N
specify the size (number of 32 bit integers) in the array to fibsearch. Size can
be from 1 K to 4 M.
.RE
.TP
.B File extent (fiemap) stressor
.RS 5
.TQ
.B \-\-fiemap N
start N workers that each create a file with many randomly changing extents
and has 4 child processes per worker that gather the extent information using
the FS_IOC_FIEMAP ioctl(2).
.TP
.B \-\-fiemap\-bytes N
specify the size of the fiemap'd file in bytes.  One can specify the size
as % of free space on the file system or in units of Bytes, KBytes, MBytes
and GBytes using the suffix b, k, m or g.  Larger files will contain more
extents, causing more stress when gathering extent information.
.TP
.B \-\-fiemap\-ops N
stop after N fiemap bogo operations.
.RE
.TP
.B FIFO named pipe stressor
.RS 5
.TQ
.B \-\-fifo N
start N workers that exercise a named pipe by transmitting 64 bit integers.
.TP
.B \-\-fifo\-data\-size N
set the byte size of the fifo write/reads, default is 8, range 8..4096.
.TP
.B \-\-fifo\-ops N
stop fifo workers after N bogo pipe write operations.
.TP
.B \-\-fifo\-readers N
for each worker, create N fifo reader workers that read
the named pipe using simple blocking reads. Default is 4, range 1..64.
.RE
.TP
.B File I/O control (ioctl) stressor
.RS 5
.TQ
.B \-\-file\-ioctl N
start N workers that exercise various file specific ioctl(2) calls. This will
attempt to use the FIONBIO, FIOQSIZE, FIGETBSZ, FIOCLEX, FIONCLEX, FIONBIO,
FIOASYNC, FIOQSIZE, FIFREEZE, FITHAW, FICLONE, FICLONERANGE, FIONREAD,
FIONWRITE and FS_IOC_RESVSP ioctls if these are defined.
.TP
.B \-\-file\-ioctl\-ops N
stop file\-ioctl workers after N file ioctl bogo operations.
.RE
.TP
.B Filename stressor
.RS 5
.TQ
.B \-\-filename N
start N workers that exercise file creation using various length filenames
containing a range of allowed filename characters.  This will try to see if
it can exceed the file system allowed filename length was well as test
various filename lengths between 1 and the maximum allowed by the file system.
.TP
.B \-\-filename\-ops N
stop filename workers after N bogo filename tests.
.TP
.B \-\-filename\-opts opt
use characters in the filename based on option `opt'. Valid options are:
.sp
.TS
lB lB
l lx.
Option	Description
probe	T{
default option, probe the file system for valid allowed characters in a file name
and use these
T}
posix	T{
use characters as specified by The Open Group Base Specifications Issue 7,
POSIX.1-2008, 3.278 Portable Filename Character Set
T}
ext	T{
use characters allowed by the ext2, ext3, ext4 file systems, namely any 8
bit character apart from NUL and /
T}
utf8	T{
use struct utf8 characters in filename
T}
urf8-like	T{
use utf8 like characters with illegal utf8 encodings when generating random
filenames
T}
.TE
.RE
.TP
.B File race stressor
.RS 5
.TQ
.B \-\-filerace N
start N workers that each run 8 concurrent processes that exercise a randomized
set of file related system calls on 64 random files. This attempts to trip any
file system race conditions while files are being operated upon. The randomized
operations will cause some invalid file operations to fail, these failures are
silently ignored.
.TP
.B \-\-filerace\-ops N
stop after N randomized file bogo-operations, this is not a reliable metric
of performance because of the highly randomized actions occurring on randomly
selected files.
.RE
.TP
.B Single cacheline coherency scalability stressor
.RS 5
.TQ
.B \-\-flipflop N
start N workers where each worker creates two groups of threads of the same size
where each group is affined to a set of CPUs. A continuous bitmap that has enough
bits for each thread pair is exercised, each thread pair tries to flip/flop their
specific bit using cmpxchg (compare/exchange); one thread tries
to flip the bit from 0 to 1 and the other tries to flop the bit from 1 to 0.
This stressor makes threads compete on the same cacheline and measures the
total number of flip/flop operations and the distribution of successful flip/flops
among the threads (to see if thread pairs get starved in favour of others).
.TP
.B \-\-flipflop\-bits N
specifies number of bits in the bitmap (and hence number of flip/flop thread pairs).
.TP
.B \-\-flipflop\-taskset1 list
list of CPUs to affine the flip threads to. Refer to the \-\-taskset option description
for the syntax of the list argument.
.TP
.B \-\-flipflop\-taskset2 list
list of CPUs to affine the flop threads to. Refer to the \-\-taskset option description
for the syntax of the list argument.
.TP
.B \-\-flipflop\-ops N
stop after N bogo-ops, in this case a bogo-op is 100000 flip-flop operations.
.RE
.TP
.B BSD File locking (flock) stressor
.RS 5
.TQ
.B \-\-flock N
start N workers locking on a single file.
.TP
.B \-\-flock\-ops N
stop flock stress workers after N bogo flock operations.
.RE
.TP
.B Cache flushing stressor
.RS 5
.TQ
.B \-\-flush\-cache N
start N workers that flush the data and instruction cache (where possible).
Some architectures may not support cache flushing on either cache, in
which case these become no-ops.
.TP
.B \-\-flush\-cache\-ops N
stop after N cache flush iterations.
.RE
.TP
.B Fused Multiply/Add floating point operations (fma) stressor
.RS 5
.TQ
.B \-\-fma N
start N workers that exercise single and double precision floating point
multiplication and add operations on arrays of 512 floating point values.
More modern processors (Intel Haswell, AMD Bulldozer and Piledriver) and
modern C compilers these will be performed by fused-multiply-add (fma3)
opcodes. Operations used are:
.sp
.TS
expand;
l.
a \(eq (a \(mu b) \(pl c
a \(eq (b \(mu a) \(pl c
a \(eq (b \(mu c) \(pl a
a \(eq (a \(mu b) \(mi c
a \(eq (b \(mu a) \(mi c
a \(eq (b \(mu c) \(mi a
.TE
.TP
.B \-\-fma\-libc
use libc fma math functions if they are available. These use either the
libc FMA macros if defined, the  __builtin libc functions or the fma
libc functions. Generally these are slower than directly multiply/add
fused code generated by the compiler.
.TP
.B \-\-fma\-ops N
stop after N bogo-loops of the 3 above operations on 512 single and double
precision floating point numbers.
.RE
.TP
.B Process forking stressor
.RS 5
.TQ
.B \-f N, \-\-fork N
start N workers continually forking children that immediately exit.
.TP
.B \-\-fork\-max P
create P child processes and then wait for them to exit per iteration. The
default is just 1; higher values will create many temporary zombie processes
that are waiting to be reaped. One can potentially fill up the process
table using high values for \-\-fork\-max and \-\-fork.
.TP
.B \-\-fork\-ops N
stop fork stress workers after N bogo operations.
.TP
.B \-\-fork\-pageout
enable force paging-out of memory resident pages in fork stressor instances.
.TP
.B \-\-fork\-unmap
attempt to unmap unused non-memory resident shared library pages
to try and reduced anonymous vma copying. This is an ugly hack for
benchmarking reduced vma copying and not guaranteed to work. Linux only.
.TP
.B \-\-fork\-vm
enable detrimental performance virtual memory advice using madvise(2) on
all pages of the forked process. Where possible this will try to set
every page in the new process with using madvise(2) MADV_MERGEABLE,
MADV_WILLNEED, MADV_HUGEPAGE and MADV_RANDOM flags. Linux only.
.RE
.TP
.B Heavy process forking stressor
.RS 5
.TQ
.B \-\-forkheavy N
start N workers that fork child processes from a parent that has thousands
of allocated system resources. The fork becomes a heavyweight operations as
it has to duplicate the resource references of the parent. Each stressor
instance creates and reaps up to 4096 child processes that are created and
reaped in a first-in first-out manner.
.TP
.B \-\-forkheavy\-allocs N
attempt N resource allocation loops per stressor instance. Resources include
pipes, file descriptors, memory mappings, pthreads, timers, ptys, semaphores,
message queues and temporary files. These create heavyweight processes that
are more time expensive to fork from. Default is 16384.
.TP
.B \-\-forkheavy\-mlock
attempt to mlock(2) future allocated pages into memory causing more memory pressure. If
mlock(MCL_FUTURE) is implemented then this will stop new brk pages from being
swapped out.
.TP
.B \-\-forkheavy\-ops N
stop after N fork calls.
.TP
.B \-\-forkheavy\-procs N
attempt to fork N processes per stressor. The default is 4096 processes.
.RE
.TP
.B Floating point operations stressor
.RS 5
.TQ
.B \-\-fp N
start N workers that exercise addition, multiplication and division
operations on a range of floating point types. For each type, 8 floating
point values are operated upon 65536 times in a loop per bogo op.
.TP
.B \-\-fp\-method method
select the floating point method to use, available methods are:
.sp
.TS
lB2 lB
l lx.
Method	Description
all	iterate over all the following floating point methods:
float128add	128 bit floating point addition
ibm128add	IBM 128 bit floating point addition (powerpc)
float80add	80 bit floating point addition
float64add	64 bit floating point addition
float32add	32 bit binary32 floating point addition
floatadd	floating point addition
bf16add	bf16 floating point addition
doubleadd	double precision floating point addition
ldoubleadd	long double precision floating point addition
float128sub	128 bit floating point subtraction
ibm128sub	IBM 128 bit floating point subtraction (powerpc)
float80sub	80 bit floating point subtraction
float64sub	64 bit floating point subtraction
float32sub	32 bit binary32 floating point subtraction
floatsub	floating point subtraction
bf16sub	bf16 floating point subtraction
doublesub	double precision floating point subtraction
ldoublesub	long double precision floating point subtraction
float128mul	128 bit floating point multiplication
ibm128mul	IBM 128 bit floating point multiplication (powerpc)
float80mul	80 bit floating point multiplication
float64mul	64 bit floating point multiplication
float32mul	32 bit binary32 floating point multiplication
floatmul	floating point multiplication
bf16mul	bf16 floating point multiplication
doublemul	double precision floating point multiplication
ldoublemul	long double precision floating point multiplication
float128div	128 bit floating point division
ibm128div	IBM 128 bit floating point division (powerpc)
float80div	80 bit floating point division
float64div	64 bit floating point division
float32div	32 bit binary32 floating point division
floatdiv	floating point division
bf16div	bf16 floating point division
doublediv	double precision floating point division
ldoublediv	long double precision floating point division
.TE
.RS
.PP
Note that some of these floating point methods may not be available on some systems.
.RE
.TP
.B \-\-fp\-ops N
stop after N floating point bogo ops. Note that bogo-ops are counted for
just standard float, double and long double floating point types.
.RE
.TP
.B Floating point exception stressor
.RS 5
.TQ
.B \-\-fp\-error N
start N workers that generate floating point exceptions. Computations are
performed to force and check for the FE_DIVBYZERO, FE_INEXACT, FE_INVALID,
FE_OVERFLOW and FE_UNDERFLOW exceptions.  EDOM and ERANGE errors are also
checked.
.TP
.B \-\-fp\-error\-ops N
stop after N bogo floating point exceptions.
.RE
.TP
.B File punch and hole filling stressor
.RS 5
.TQ
.B \-\-fpunch N
start N workers that punch and fill holes in a 16 MB file using five
concurrent processes per stressor exercising on the same file. Where
available, this uses fallocate(2) FALLOC_FL_KEEP_SIZE,
FALLOC_FL_PUNCH_HOLE, FALLOC_FL_ZERO_RANGE, FALLOC_FL_COLLAPSE_RANGE
and FALLOC_FL_INSERT_RANGE to make and fill holes across the file
and breaks it into multiple extents.
.TP
.B \-\-fpunch\-bytes N
set maximum size of each file for each fpunch worker process, the
default is 16 MB. One can specify the size as % of free space on
the file system or in units of Bytes, KBytes, MBytes and GBytes
using the suffix b, k, m or g.
.TP
.B \-\-fpunch\-ops N
stop fpunch workers after N punch and fill bogo operations.
.RE
.TP
.B Fractal Stressor
.RS 5
.TQ
.B \-\-fractal N
start N workers that generate 2D fractals. By default a 1024 x 1024
point Mandelbrot set is computed with a maximum of 256 iterations
per point in the iterative compute loop. The fractal is computed row
by row with multiple rows shared amongst the N fractal stressor
instances. Double precision floating point values are used for the
points in the complex set of values. Naive computation is used with
no special algorithmic short-cuts or interpolation.
.TP
.B \-\-fractal\-iterations N
specify the maximum number of iterations for the quadratic map computation
of each point, default is 256 iterations.
.TP
.B \-\-fractal\-method [ julia | mandelbrot ]
select the method of fractal generation, Julia set or Mandelbrot set,
default is the Mandelbrot set.
.TP
.B \-\-fractal\-ops N
stop after N fractals have been generated.
.TP
.B \-\-fractal\-sizex N
set the maximum width of the fractal, default is 1024 points.
.TP
.B \-\-fractal\-sizey N
set the maximum height of the fractal, default is 1024 points.
.RE
.TP
.B File size limit stressor
.RS 5
.TQ
.B \-\-fsize N
start N workers that exercise file size limits (via setrlimit(2) RLIMIT_FSIZE)
with file sizes that are fixed, random and powers of 2. The files are
truncated and allocated to trigger SIGXFSZ signals.
.TP
.B \-\-fsize\-ops N
stop after N bogo file size test iterations.
.RE
.TP
.B File stats (fstat) stressor
.RS 5
.TQ
.B \-\-fstat N
start N workers fstat'ing files in a directory (default is /dev).
.TP
.B \-\-fstat\-dir directory
specify the directory to fstat to override the default of /dev.
All the files in the directory will be fstat'd repeatedly.
.TP
.B \-\-fstat\-ops N
stop fstat stress workers after N bogo fstat operations.
.RE
.TP
.B /dev/full stressor
.RS 5
.TQ
.B \-\-full N
start N workers that exercise /dev/full.  This attempts to write to
the device (which should always get error ENOSPC), to read from the device
(which should always return a buffer of zeros) and to seek randomly on the
device (which should always succeed).  (Linux only).
.TP
.B \-\-full\-ops N
stop the stress full workers after N bogo I/O operations.
.RE
.TP
.B Function argument passing stressor
.RS 5
.TQ
.B \-\-funccall N
start N workers that call functions of 1 through to 9 arguments. By default
all functions with a range of argument types are called, however, this can be changed
using the \-\-funccall\-method option. This exercises stack function argument passing
and re-ordering on the stack and in registers.
.TP
.B \-\-funccall\-ops N
stop the funccall workers after N bogo function call operations. Each bogo
operation is 1000 calls of functions of 1 through to 9 arguments of the chosen
argument type.
.TP
.B \-\-funccall\-method method
specify the method of funccall argument type to be used. The
default is all the types but can be one of bool, uint8, uint16, uint32, uint64,
uint128, float, double, longdouble, cfloat (complex float),
cdouble (complex double), clongdouble (complex long double), float16,
float32, float64, float80, float128, decimal32, decimal64 and decimal128.
Note that some of these types are only available with specific architectures
and compiler versions.
.RE
.TP
.B Function return stressor
.RS 5
.TQ
.B \-\-funcret N
start N workers that pass and return by value various small to large data
types.
.TP
.B \-\-funcret\-ops N
stop the funcret workers after N bogo function call operations.
.TP
.B \-\-funcret\-method method
specify the method of funcret argument type to be used. The
default is uint64_t but can be one of uint8 uint16 uint32 uint64 uint128
float double longdouble float80 float128 decimal32 decimal64 decimal128
uint8x32 uint8x128 uint64x128.
.RE
.TP
.B Fast mutex (futex) stressor
.RS 5
.TQ
.B \-\-futex N
start N workers that rapidly exercise the futex system call. Each worker has
two processes, a futex waiter and a futex waker. The waiter waits with a very
small timeout to stress the timeout and rapid polled futex waiting. This is a
Linux specific stress option.
.TP
.B \-\-futex\-ops N
stop futex workers after N bogo successful futex wait operations.
.RE
.TP
.B Fetching data from kernel stressor
.RS 5
.TQ
.B \-\-get N
start N workers that call system calls that fetch data from the kernel,
currently these are: getpid(2), getppid(2), getcwd(3), getgid(2),
getegid(2), getuid(2), getgroups(2), getpgrp(2), getpgid(2), getpriority(2),
getresgid(2), getresuid(2), getrlimit(2), prlimit(2), getrusage(2), getsid(2),
gettid(2), getcpu(2), gettimeofday(2), uname(2), adjtimex(2), sysfs(2). Some
of these system calls are OS specific.
.TP
.B \-\-get\-ops N
stop get workers after N bogo get operations.
.TP
.B \-\-get\-slow\-sync
attempt to synchronize system calls across the N get workers to try to
force forms of locking contention in the kernel on the more complex
cases. Each system call is exercised concurrently with the N workers
for 0.1 seconds at a time, so it takes a 3-4 seconds to work through
all the system calls.
.RE
.TP
.B Get directory entries stressor (Linux)
.RS 5
.TQ
.B \-\-getdent N
start N workers that recursively read directories /proc, /dev/, /tmp, /sys
and /run using getdents(2) and getdents64(2) (Linux only).
.TP
.B \-\-getdent\-ops N
stop getdent workers after N bogo getdent bogo operations.
.RE
.TP
.B Random data (getrandom) stressor
.RS 5
.TQ
.B \-\-getrandom N
start N workers that get 8192 random bytes from the /dev/urandom pool using
the getrandom(2) system call (Linux) or getentropy(2) (OpenBSD).
.TP
.B \-\-getrandom\-ops N
stop getrandom workers after N bogo get operations.
.RE
.TP
.B CPU pipeline and branch prediction stressor
.RS 5
.TQ
.B \-\-goto N
start N workers that perform 1024 forward branches (to next instruction) or
backward branches (to previous instruction) for each bogo operation loop.
By default, every 1024 branches the direction is randomly chosen to be
forward or backward.  This stressor exercises suboptimal pipelined execution
and branch prediction logic.
.TP
.B \-\-goto\-direction [ forward | backward | random ]
select the branching direction in the stressor loop, forward for forward only
branching, backward for a backward only branching, random for a random choice
of forward or random branching every 1024 branches.
.TP
.B \-\-goto\-ops N
stop goto workers after N bogo loops of 1024 branch instructions.
.RE
.TP
.B 2D GPU stressor
.RS 5
.TQ
.B \-\-gpu N
start N worker that exercise the GPU. This specifies a 2-D texture image
that allows the elements of an image array to be read by shaders,
and render primitives using an opengl context.
.TP
.B \-\-gpu\-devnode DEVNAME
specify the device node name of the GPU device, the default is /dev/dri/renderD128.
.TP
.B \-\-gpu\-frag N
specify shader core usage per pixel, this sets N loops in the fragment shader.
.TP
.B \-\-gpu\-ops N
stop gpu workers after N render loop operations.
.TP
.B \-\-gpu\-tex\-size N
specify upload texture N \(mu N, by default this value is 4096 \(mu 4096.
.TP
.B \-\-gpu\-xsize X
use a framebuffer size of X pixels. The default is 256 pixels.
.TP
.B \-\-gpu\-ysize Y
use a framebuffer size of Y pixels. The default is 256 pixels.
.TP
.B \-\-gpu\-upload N
specify upload texture N times per frame, the default value is 1.
.RE
.TP
.B Handle stressor
.RS 5
.TQ
.B \-\-handle N
start N workers that exercise the name_to_handle_at(2) and open_by_handle_at(2)
system calls. (Linux only).
.TP
.B \-\-handle\-ops N
stop after N handle bogo operations.
.RE
.TP
.B String hashing stressor
.RS 5
.TQ
.B \-\-hash N
start N workers that exercise various hashing functions. Random strings from
1 to 128 bytes are hashed and the hashing rate and chi squared is calculated
from the number of hashes performed over a period of time. The chi squared
value is the goodness-of-fit measure, it is the actual distribution of items
in hash buckets versus the expected distribution of items. Typically a chi
squared value close to 1.0 indicates a good hash distribution.
.TP
.B \-\-hash\-method method
specify the hashing method to use, by default all the hashing methods are
cycled through. Methods available are:
.sp
.TS
lB2 lB
l lx.
Method	Description
all	T{
cycle through all the hashing methods
T}
adler32	T{
Mark Adler checksum, a modification of the Fletcher checksum
T}
coffin	T{
xor and 5 bit rotate left hash
T}
coffin32	T{
xor and 5 bit rotate left hash with 32 bit fetch optimization
T}
crc32c	T{
compute CRC32C (Castagnoli CRC32) integer hash
T}
djb2a	T{
Dan Bernstein hash using the xor variant
T}
fnv1a	T{
FNV-1a Fowler-Noll-Vo hash using the xor then multiply variant
T}
jenkin	T{
Jenkin's integer hash
T}
kandr	T{
Kernighan and Richie's multiply by 31 and add hash from "The C Programming Language", 2nd Edition
T}
knuth	T{
Donald E. Knuth's hash from "The Art Of Computer Programming", Volume 3, chapter 6.4
T}
loselose	T{
Kernighan and Richie's simple hash from "The C Programming Language", 1st Edition
T}
mid5	T{
xor shift hash of the middle 5 characters of the string. Designed by Colin Ian King
T}
muladd32	T{
simple multiply and add hash using 32 bit math and xor folding of overflow
T}
muladd64	T{
simple multiply and add hash using 64 bit math and xor folding of overflow
T}
mulxror32	T{
32 bit multiply, xor and rotate right. Mangles 32 bits where possible. Designed by Colin Ian King
T}
mulxror64	T{
64 bit multiply, xor and rotate right. 64 Bit version of mulxror32
T}
murmur3_32	T{
Austin Appleby's Murmur3 hash, 32 bit variant
T}
nhash	T{
exim's nhash.
T}
pjw	T{
a non-cryptographic hash function created by Peter J. Weinberger of AT&T Bell Labs,
used in UNIX ELF object files
T}
sdbm	T{
sdbm hash as used in the SDBM database and GNU awk
T}
sedgwick	T{
simple hash from Robert Sedgwick's C programming book
T}
sobel	T{
Justin Sobel's bitwise shift hash
T}
x17	T{
multiply by 17 and add. The multiplication can be optimized down to a fast right shift by 4
and add on some architectures
T}
xor	T{
simple rotate shift and xor of values
T}
xorror32	T{
32 bit exclusive-or with right rotate hash, a fast string hash, designed by Colin Ian King
T}
xorror64	T{
64 bit version of xorror32
T}
xxhash	T{
the "Extremely fast" hash in non-streaming mode
T}
.TE
.TP
.B \-\-hash\-ops N
stop after N hashing rounds
.RE
.TP
.B File-system stressor
.RS 5
.TQ
.B \-d N, \-\-hdd N
start N workers continually writing, reading and removing temporary files. The
default mode is to stress test sequential writes and reads.  With
the \-\-aggressive option enabled without any \-\-hdd\-opts options the
hdd stressor will work through all the \-\-hdd\-opt options one by one to
cover a range of I/O options.
.TP
.B \-\-hdd\-bytes N
write N bytes for each hdd process, the default is 1 GB. One can specify the
size as % of free space on the file system or in units of Bytes, KBytes, MBytes
and GBytes using the suffix b, k, m or g.
.TP
.B \-\-hdd\-opts list
specify various stress test options as a comma separated list. Options are as
follows:
.sp
.TS
lB lB
l lx.
Option	Description
direct	T{
try to minimize cache effects of the I/O. File I/O writes are performed
directly from user space buffers and synchronous transfer is also attempted.
To guarantee synchronous I/O, also use the sync option.
T}
dsync	T{
ensure output has been transferred to underlying hardware and file metadata
has been updated (using the O_DSYNC open flag). This is equivalent to each
write(2) being followed by a call to fdatasync(2). See also the fdatasync
option.
T}
fadv\-dontneed	T{
advise kernel to expect the data will not be accessed in the near future.
T}
fadv\-noreuse	T{
advise kernel to expect the data to be accessed only once.
T}
fadv\-normal	T{
advise kernel there are no explicit access pattern for the data. This is the
default advice assumption.
T}
fadv\-rnd	T{
advise kernel to expect random access patterns for the data.
T}
fadv\-seq	T{
advise kernel to expect sequential access patterns for the data.
T}
fadv\-willneed	T{
advise kernel to expect the data to be accessed in the near future.
T}
fsync	T{
flush all modified in-core data after each write to the output device using an
explicit fsync(2) call.
T}
fdatasync	T{
similar to fsync, but do not flush the modified metadata unless metadata is
required for later data reads to be handled correctly. This uses an explicit
fdatasync(2) call.
T}
iovec	T{
use readv/writev multiple buffer I/Os rather than read/write. Instead of 1
read/write operation, the buffer is broken into an iovec of 16 buffers.
T}
noatime	T{
do not update the file last access timestamp, this can reduce metadata writes.
T}
sync	T{
ensure output has been transferred to underlying hardware (using the O_SYNC
open flag). This is equivalent to a each write(2) being followed by a call to
fsync(2). See also the fsync option.
T}
rd\-rnd	T{
read data randomly.
T}
rd\-seq	T{
read data sequentially.
T}
syncfs	T{
write all buffered modifications of file metadata and data on the filesystem
that contains the hdd worker files.
T}
utimes	T{
force update of file timestamp which may increase metadata writes.
T}
wr\-rnd	T{
write data randomly. The wr\-seq option cannot be used at the same time.
T}
wr\-seq	T{
write data sequentially. This is the default if no write modes are specified.
T}
.TE
.PP
Note that some of these options are mutually exclusive, for example, there can
be only one method of writing or reading.  Also, fadvise flags may be mutually
exclusive, for example fadv-willneed cannot be used with fadv-dontneed.
.TP
.B \-\-hdd\-ops N
stop hdd stress workers after N bogo operations.
.TP
.B \-\-hdd\-write\-size N
specify size of each write in bytes. Size can be from 1 byte to 4 MB.
.RE
.TP
.B BSD heapsort stressor
.RS 5
.TQ
.B \-\-heapsort N
start N workers that sort 32 bit integers using the BSD heapsort.
.TP
.B \-\-heapsort\-method [ heapsort\-libc | heapsort\-nonlibc ]
select either the libc implementation of heapsort or an optimized
implementation of heapsort. The default is the libc implementation if it
is available.
.TP
.B \-\-heapsort\-ops N
stop heapsort stress workers after N bogo heapsorts.
.TP
.B \-\-heapsort\-size N
specify number of 32 bit integers to sort, default is 262144 (256 \(mu 1024).
.RE
.TP
.B High resolution timer stressor
.RS 5
.TQ
.B \-\-hrtimers N
start N workers that exercise high resolution times at a high frequency. Each
stressor starts 32 processes that run with random timer intervals of 0..499999
nanoseconds. Running this stressor with appropriate privilege will run these
with the SCHED_RR policy.
.TP
.B \-\-hrtimers\-adjust
enable automatic timer rate adjustment to try to maximize the hrtimer frequency.
The signal rate is measured every 0.1 seconds and the hrtimer delay is adjusted
to try and set the optimal hrtimer delay to generate the highest hrtimer rates.
.TP
.B \-\-hrtimers\-ops N
stop hrtimers stressors after N timer event bogo operations
.RE
.TP
.B Hashtable searching (hsearch) stressor
.RS 5
.TQ
.B \-\-hsearch N
start N workers that search a 80% full hash table using hsearch(3). By default,
there are 8192 elements inserted into the hash table.  This is a useful method
to exercise access of memory and processor cache.
.TP
.B \-\-hsearch\-method [ hsearch\-libc | hsearch\-nonlibc ]
select either the libc implementation of hsearch or a slightly optimized non-libc
implementation of hsearch. The default is the libc implementation if it exists,
otherwise the non-libc version.
.TP
.B \-\-hsearch\-ops N
stop the hsearch workers after N bogo hsearch operations are completed.
.TP
.B \-\-hsearch\-size N
specify the number of hash entries to be inserted into the hash table. Size can
be from 1 K to 4 M.
.RE
.TP
.B Hyperbolic functions stressor
.RS 5
.TQ
.B \-\-hyperbolic N
start N workers that exercise sinh, cosh, and tanh libm hyperbolic
functions using float, double and long double floating point
variants. Each function is exercised 10000 times per bogo-operation.
.TP
.B \-\-hyperbolic\-method function
specify a hyperbolic stress function. By default, all the functions are exercised
sequentially, however one can specify just one function to be used if required.
Available options are as follows:
.sp
.TS
lB2 lB
l lx.
Method	Description
all	T{
iterate through all of the following hyperbolic functions
T}
cosh	T{
hyperbolic cosine (double precision)
T}
coshf	T{
hyperbolic cosine (float precision)
T}
coshl	T{
hyperbolic cosine (long double precision)
T}
sinh	T{
hyperbolic sine (double precision)
T}
sinhf	T{
hyperbolic sine (float precision)
T}
sinhl	T{
hyperbolic sine (long double precision)
T}
tanh	T{
hyperbolic tangent (double precision)
T}
tanhf	T{
hyperbolic tangent (float precision)
T}
tanhl 	T{
hyperbolic tangent (long double precision)
T}
.TE
.TP
.B \-\-hyperbolic\-ops N
stop after N bogo-operations.
.RE
.TP
.B CPU instruction cache load stressor
.RS 5
.TQ
.B \-\-icache N
start N workers that stress the instruction cache by forcing instruction cache
reloads.
.TP
.B \-\-icache\-ops N
stop the icache workers after N bogo icache operations are completed.
.RE
.TP
.B ICMP flooding stressor
.RS 5
.TQ
.B \-\-icmp\-flood N
start N workers that flood localhost with randomly sized ICMP ping packets.
This stressor requires the CAP_NET_RAW capbility.
.TP
.B \-\-icmp\-flood\-max\-size
use a maximum packet size of 65535 bytes instead of the default of 1000 bytes.
.TP
.B \-\-icmp\-flood\-ops N
stop icmp flood workers after N ICMP ping packets have been sent.
.RE
.TP
.B Idle page scan stressor (Linux)
.RS 5
.TQ
.B \-\-idle\-page N
start N workers that walks through every page exercising the Linux
/sys/kernel/mm/page_idle/bitmap interface. Requires CAP_SYS_RESOURCE
capability.
.TP
.B \-\-idle\-page\-ops N
stop after N bogo idle page operations.
.RE
.TP
.B Inode ioctl flags stressor
.RS 5
.TQ
.B \-\-inode\-flags N
start N workers that exercise inode flags using the FS_IOC_GETFLAGS and
FS_IOC_SETFLAGS ioctl(2) and inode attributes using file_getattr(2) and
file_getatt(2).  This attempts to apply all the available inode
flags onto a directory and file even if the underlying file system may not
support these flags (errors are just ignored). Each worker runs 4 threads
that exercise the flags on the same directory and file to try to force
races. This is a Linux only stressor, see ioctl_iflags(2) for more details.
.TP
.B \-\-inode\-flags\-ops N
stop the inode-flags workers after N ioctl flag setting attempts.
.RE
.TP
.B Inotify stressor
.RS 5
.TQ
.B \-\-inotify N
start N workers performing file system activities such as making/deleting
files/directories, moving files, etc. to stress exercise the various inotify
events (Linux only).
.TP
.B \-\-inotify\-ops N
stop inotify stress workers after N inotify bogo operations.
.RE
.TP
.B Insertion sort stressor
.RS 5
.TQ
.B \-\-insertionsort N
start N workers that sort 32 bit integers using insertion sort.
.TP
.B \-\-insertionsort\-ops N
stop insertionsort stress workers after N bogo insertion sorts.
.TP
.B \-\-insertionsort\-size N
specify number of 32 bit integers to sort, default is 16384 (16 \(mu 1024).
.RE
.TP
.B Integer Math Operations
.RS 5
.TQ
.B \-\-intmath N
start N workers that perform addition, subtraction, multiplication, division and modulo
math operations on 128, 64, 32, 16 and 8 bit signed integers.
.TP
.B \-\-intmath\-fast
when available use int_fast64_t, int_fast32_t, int_fast16_t and int_fast8_t types
instead of int64_t, int32_t, int16_t and int8_t types. Note that these may or may
not be faster than normal integer operations depending on the compiler.
.TP
.B \-\-intmath\-method method
select the integer math method to use, available methods are:
.sp
.TS
lB2 lB
l lx.
Method	Description
all	iterate over all the following integer methods:
add128	128 bit signed integer addition
add64	64 bit signed integer addition
add32	32 bit signed integer addition
add16	16 bit signed integer addition
add8	8 bit signed integer addition
sub128	128 bit signed integer subtraction
sub64	64 bit signed integer subtraction
sub32	32 bit signed integer subtraction
sub16	16 bit signed integer subtraction
sub8	8 bit signed integer subtraction
mul128	128 bit signed integer multiplication
mul64	64 bit signed integer multiplication
mul32	32 bit signed integer multiplication
mul16	16 bit signed integer multiplication
mul8	8 bit signed integer multiplication
div128	128 bit signed integer division
div64	64 bit signed integer division
div32	32 bit signed integer division
div16	16 bit signed integer division
div8	8 bit signed integer division
mod128	128 bit signed integer modulo
mod64	64 bit signed integer modulo
mod32	32 bit signed integer modulo
mod16	16 bit signed integer modulo
mod8	8 bit signed integer modulo
.TE
.sp
for the \-\-intmath\-fast option, the following methods are available:
.sp
.TS
lB2 lB
l lx.
Method	Description
all	iterate over all the following integer methods:
addfast64	fast 64 bit signed integer addition
addfast32	fast 32 bit signed integer addition
addfast16	fast 16 bit signed integer addition
addfast8	fast 8 bit signed integer addition
subfast64	fast 64 bit signed integer subtraction
subfast32	fast 32 bit signed integer subtraction
subfast16	fast 16 bit signed integer subtraction
subfast8	fast 8 bit signed integer subtraction
mulfast64	fast 64 bit signed integer multiplication
mulfast32	fast 32 bit signed integer multiplication
mulfast16	fast 16 bit signed integer multiplication
mulfast8	fast 8 bit signed integer multiplication
divfast64	fast 64 bit signed integer division
divfast32	fast 32 bit signed integer division
divfast16	fast 16 bit signed integer division
divfast8	fast 8 bit signed integer division
modfast64	fast 64 bit signed integer modulo
modfast32	fast 32 bit signed integer modulo
modfast16	fast 16 bit signed integer modulo
modfast8	fast 8 bit signed integer modulo
.TE
.TP
.B \-\-intmath\-ops N
stop intmath workers after N bogo integer math operations.
.RE
.TP
.B Data synchronization (sync) stressor
.RS 5
.TQ
.B \-i N, \-\-io N
start N workers continuously calling sync(2) to commit buffer cache to disk.
This can be used in conjunction with the \-\-hdd stressor. This is a legacy
stressor that is compatible with the original stress tool.
.TP
.B \-\-io\-ops N
stop io stress workers after N bogo operations.
.RE
.TP
.B IO mixing stressor
.RS 5
.TQ
.B \-\-iomix N
start N workers that perform a mix of sequential, random and memory mapped
read/write operations as well as random copy file read/writes, forced
sync'ing and (if run as root) cache dropping.  Multiple child processes
are spawned to all share a single file and perform different I/O operations
on the same file.
.TP
.B \-\-iomix\-bytes N
write N bytes for each iomix worker process, the default is 1 GB. One can
specify the size as % of free space on the file system or in units of Bytes,
KBytes, MBytes and GBytes using the suffix b, k, m or g.
.TP
.B \-\-iomix\-ops N
stop iomix stress workers after N bogo iomix I/O operations.
.RE
.TP
.B Ioport stressor (x86 Linux)
.RS 5
.TQ
.B \-\-ioport N
start N workers than perform bursts of 16 reads and 16 writes of ioport 0x80
(x86 Linux systems only).  I/O performed on x86 platforms on port 0x80 will
cause delays on the CPU performing the I/O.
.TP
.B \-\-ioport\-ops N
stop the ioport stressors after N bogo I/O operations
.TP
.B \-\-ioport\-opts [ in | out | inout ]
specify the io operation to be performed.  The default is both in and out.
specify if port reads in, port read writes out or reads and writes are
.TP
.B \-\-ioport\-port [ post | vga-dac-r | bochs-debug ]
select x86 I/O port to use, post (Power-On-Self-Test port 0x80), vga-dac-r (VGA DAC Red port 0x3c8)
or bochs-debug (Bochs debug port 0xe9)
.RE
.TP
.B IO scheduling class and priority stressor
.RS 5
.TQ
.B \-\-ioprio N
start N workers that exercise the ioprio_get(2) and ioprio_set(2) system calls
(Linux only).
.TP
.B \-\-ioprio\-ops N
stop after N io priority bogo operations.
.RE
.TP
.B Io-uring stressor
.RS 5
.TQ
.B \-\-io\-uring N
start N workers that perform various io-uring file operations using the
Linux io-uring interface.
.TP
.B \-\-io\-uring\-entries N
specify the number of io-uring ring entries.
.TP
.B \-\-io\-uring\-ops
stop after N rounds of io-uring operations.
.TP
.B \-\-io\-uring\-rand
randomize order of io-uring operations and file seek locations.
.RE
.TP
.B Ipsec multi-buffer cryptographic stressor
.RS 5
.TQ
.B \-\-ipsec\-mb N
start N workers that perform cryptographic processing using the highly
optimized Intel Multi-Buffer Crypto for IPsec library. Depending on the
features available, SSE, AVX, AVX and AVX512 CPU features will be used
on data encrypted by SHA, DES, CMAC, CTR, HMAC MD5, HMAC SHA1 and
HMAC SHA512 cryptographic routines. This is only available for x86-64
modern Intel CPUs.
.TP
.B \-\-ipsec\-mb\-feature [ sse | avx | avx2 | avx512 | noaesni ]
Just use the specified processor CPU feature. By default, all the available
features for the CPU are exercised.
.TP
.B \-\-ipsec\-mb\-jobs N
Process N multi-block rounds of cryptographic processing per iteration. The
default is 256.
.TP
.B \-\-ipsec\-mb\-method [ all | cmac | ctr | des | hmac\-md5 | hmac\-sha1 | hmac\-sha512 | sha ]
Select the ipsec-mb crypto/integrity method.
.TP
.B \-\-ipsec\-mb\-ops N
stop after N rounds of processing of data using the cryptographic
routines.
.RE
.TP
.B System interval timer stressor
.RS 5
.TQ
.B \-\-itimer N
start N workers that exercise the system interval timers. This sets up an
ITIMER_PROF itimer that generates a SIGPROF signal.  The default frequency for
the itimer is 1 MHz, however, the Linux kernel will set this to be no more that
the jiffy setting, hence high frequency SIGPROF signals are not normally
possible.  A busy loop spins on getitimer(2) calls to consume CPU and hence
decrement the itimer based on amount of time spent in CPU and system time.
.TP
.B \-\-itimer\-freq F
run itimer at F Hz; range from 1 to 1000000 Hz. Normally the highest frequency
is limited by the number of jiffy ticks per second, so running above 1000 Hz
is difficult to attain in practice.
.TP
.B \-\-itimer\-ops N
stop itimer stress workers after N bogo itimer SIGPROF signals.
.TP
.B \-\-itimer\-rand
select an interval timer frequency based around the interval timer
frequency \(+-12.5% random jitter. This tries to force more variability in
the timer interval to make the scheduling less predictable.
.RE
.TP
.B Jpeg compression stressor
.RS 5
.TQ
.B \-\-jpeg N
start N workers that use jpeg compression on a machine generated plasma
field image. The default image is a plasma field, however different image
types may be selected. The starting raster line is changed on each compression
iteration to cycle around the data.
.TP
.B \-\-jpeg\-height H
use a RGB sample image height of H pixels. The default is 512 pixels.
.TP
.B \-\-jpeg\-image [ brown | flat | gradient | noise | plasma | xstripes ]
select the source image type to be compressed. Available image types are:
.sp
.TS
lB2 lB
l lx.
Type	Description
brown	T{
brown noise, red and green values vary by a 3 bit value, blue values
vary by a 2 bit value.
T}
flat	T{
a single random colour for the entire image.
T}
gradient	T{
linear gradient of the red, green and blue components across the width
and height of the image.
T}
noise	T{
random white noise for red, green, blue values.
T}
plasma	T{
plasma field with smooth colour transitions and hard boundary edges.
T}
xstripes	T{
a random colour for each horizontal line.
T}
.TE
.TP
.B \-\-jpeg\-ops N
stop after N jpeg compression operations.
.TP
.B \-\-jpeg\-quality Q
use the compression quality Q. The range is 1..100 (1 lowest, 100 highest), with a
default of 95
.TP
.B \-\-jpeg\-width H
use a RGB sample image width of H pixels. The default is 512 pixels.
.RE
.TP
.B Judy array stressor
.RS 5
.TQ
.B \-\-judy N
start N workers that insert, search and delete 32 bit integers in a Judy
array using a predictable yet sparse array index. By default,
there are 131072 integers used in the Judy array.  This is a useful method
to exercise random access of memory and processor cache.
.TP
.B \-\-judy\-ops N
stop the judy workers after N bogo judy operations are completed.
.TP
.B \-\-judy\-size N
specify the size (number of 32 bit integers) in the Judy array to exercise.
Size can be from 1 K to 4 M 32 bit integers.
.RE
.TP
.B Kcmp stressor (Linux)
.RS 5
.TQ
.B \-\-kcmp N
start N workers that use kcmp(2) to compare parent and child processes to
determine if they share kernel resources. Supported only for Linux and
requires CAP_SYS_PTRACE capability.
.TP
.B \-\-kcmp\-ops N
stop kcmp workers after N bogo kcmp operations.
.RE
.TP
.B Kernel key management stressor
.RS 5
.TQ
.B \-\-key N
start N workers that create and manipulate keys using add_key(2) and
ketctl(2). As many keys are created as the per user limit allows and then the
following keyctl commands are exercised on each key: KEYCTL_SET_TIMEOUT,
KEYCTL_DESCRIBE, KEYCTL_UPDATE, KEYCTL_READ, KEYCTL_CLEAR and
KEYCTL_INVALIDATE.
.TP
.B \-\-key\-ops N
stop key workers after N bogo key operations.
.RE
.TP
.B Process signals stressor
.RS 5
.TQ
.B \-\-kill N
start N workers sending SIGUSR1 kill(2) signals to a SIG_IGN signal handler
in the stressor and SIGUSR1 kill signal to a child stressor with a SIGUSR1
handler. Most of the process time will end up in kernel space.
.TP
.B \-\-kill\-ops N
stop kill workers after N bogo kill operations.
.RE
.TP
.B Syslog stressor (Linux)
.RS 5
.TQ
.B \-\-klog N
start N workers exercising the kernel syslog(2) system call.  This will
attempt to read the kernel log with various sized read buffers. Linux only.
.TP
.B \-\-klog\-ops N
stop klog workers after N syslog operations.
.RE
.TP
.B KVM stressor
.RS 5
.TQ
.B \-\-kvm N
start N workers that create, run and destroy a minimal virtual machine. The
virtual machine reads, increments and writes to port 0x80 in a spin loop
and the stressor handles the I/O transactions. Currently for x86 and Linux only.
.TP
.B \-\-kvm\-ops N
stop kvm stressors after N virtual machines have been created, run and destroyed.
.RE
.TP
.B CPU L1 cache stressor
.RS 5
.TQ
.B \-\-l1cache N
start N workers that exercise the CPU level 1 cache with reads and writes. A cache
aligned buffer that is twice the level 1 cache size is read and then written
in level 1 cache set sized steps over each level 1 cache set. This is designed
to exercise cache block evictions. The bogo-op count measures the number of
million cache lines touched.  Where possible, the level 1 cache geometry is
determined from the kernel, however, this is not possible on some architectures
or kernels, so one may need to specify these manually. One can specify 3 out
of the 4 cache geometric parameters, these are as follows:
.TP
.B \-\-l1cache\-line\-size N
specify the level 1 cache line size (in bytes)
.TP
.B \-\-l1cache\-method [ forward | random | reverse ]
select the method of exercising a l1cache sized buffer. The default is a
forward scan, random picks random bytes to exercise, reverse scans in reverse.
.TP
.B \-\-l1cache\-mlock
attempt to mlock(2) the l1cache size buffer into memory to prevent it from being
swapped out.
.TP
.B \-\-l1cache\-ops N
specify the number of cache read/write bogo-op loops to run
.TP
.B \-\-l1cache\-sets N
specify the number of level 1 cache sets
.TP
.B \-\-l1cache\-size N
specify the level 1 cache size (in bytes)
.TP
.B \-\-l1cache\-ways N
specify the number of level 1 cache ways
.RE
.TP
.B Landlock stressor (Linux \(>= 5.13)
.RS 5
.TQ
.B \-\-landlock N
start N workers that exercise Linux 5.13 landlocking. A range of
landlock_create_ruleset(2) flags are exercised with a read only file rule
to see if a directory can be accessed and a read-write file create can
be blocked. Each ruleset attempt is exercised in a new child context and
this is the limiting factor on the speed of the stressor.
.TP
.B \-\-landlock\-ops N
stop the landlock stressors after N landlock ruleset bogo operations.
.RE
.TP
.B File lease stressor
.RS 5
.TQ
.B \-\-lease N
start N workers locking, unlocking and breaking leases via the fcntl(2)
F_SETLEASE operation. The parent processes continually lock and unlock a lease
on a file while a user selectable number of child processes open the file with
a non-blocking open to generate SIGIO lease breaking notifications to the
parent.  This stressor is only available if F_SETLEASE, F_WRLCK and F_UNLCK
support is provided by fcntl(2).
.TP
.B \-\-lease\-breakers N
start N lease breaker child processes per lease worker.  Normally one child is
plenty to force many SIGIO lease breaking notification signals to the parent,
however, this option allows one to specify more child processes if required.
.TP
.B \-\-lease\-ops N
stop lease workers after N bogo operations.
.RE
.TP
.B LED stressor (Linux)
.RS 5
.TQ
.B \-\-led N
start N workers that exercise the /sys/class/leds interfaces to
set LED brightness levels and the various trigger settings. This
needs to be run with root privilege to be able to write to these
settings successfully. Non-root privilege will ignore failed writes.
.TP
.B \-\-led\-ops N
stop after N interfaces are exercised.
.RE
.TP
.B Hardlink stressor
.RS 5
.TQ
.B \-\-link N
start N workers creating and removing hardlinks.
.TP
.B \-\-link\-ops N
stop link stress workers after N bogo operations.
.TP
.B \-\-link\-sync
sync dirty data and metadata to disk.
.RE
.TP
.B List data structures stressor
.RS 5
.TQ
.B \-\-list N
start N workers that exercise list data structures. The default is
to add, find and remove 5000 64 bit integers into circleq (doubly
linked circle queue), list (doubly linked list), slist (singly
linked list), slistt (singly linked list using tail), stailq (singly
linked tail queue) and tailq (doubly linked tail queue) lists. The
intention of this stressor is to exercise memory and cache with the
various list operations.
.TP
.B \-\-list\-method [ all | circleq | list | slist | stailq | tailq ]
specify the list to be used. By default, all the list methods are
used (the `all' option).
.TP
.B \-\-list\-ops N
stop list stressors after N bogo ops. A bogo op covers the addition,
finding and removing all the items into the list(s).
.TP
.B \-\-list\-size N
specify the size of the list, where N is the number of 64 bit integers
to be added into the list.
.RE
.TP
.B Last level of cache stressor
.RS 5
.TQ
.B \-\-llc\-affinity N
start N workers that exercise the last level of cache (LLC) by read/write
activity across a LLC sized buffer and then changing CPU affinity after
each round of read/writes. This can cause non-local memory stalls and
LLC read/write misses.
.TP
.B \-\-llc\-affinity\-clflush
where possible, flush cachelines after each cacheline write, x86 and ppc64 only.
.TP
.B \-\-llc\-affinity\-mlock
attempt to mlock(2) the LLC sized buffer into memory to prevent it from being
swapped out.
.TP
.B \-\-llc\-affinity\-numa
assign memory mapped pages to randomly selected NUMA nodes. This is disabled
for systems that do not support NUMA.
.TP
.B \-\-llc\-affinity\-ops N
stop after N rounds of LLC read/writes.
.TP
.B \-\-llc\-affinity\-size N
override the default LLC cache size setting to N bytes. One can specify the
in units of Bytes, KBytes, MBytes and GBytes using the suffix b, k, m or g.
.RE
.TP
.B Load average (loadavg) stressor
.RS 5
.TQ
.B \-\-loadavg N
start N workers that attempt to create thousands of pthreads that run
at the lowest nice priority to force very high load averages. Linux
systems will also perform some I/O writes as pending I/O is also
factored into system load accounting.
.TP
.B \-\-loadavg\-max N
set the maximum number of pthreads to create to N. N may be reduced
if there is as system limit on the number of pthreads that can be
created.
.TP
.B \-\-loadavg\-ops N
stop loadavg workers after N bogo scheduling yields by the pthreads
have been reached.
.RE
.TP
.B Lock and increment memory stressor (x86 and ARM)
.RS 5
.TQ
.B \-\-lockbus N
start N workers that rapidly lock and increment 64 bytes of randomly chosen
memory from a 16 MB mmap'd region (Intel x86 and ARM CPUs only).  This will
cause cacheline misses and stalling of CPUs. Pages are spread randomly across
NUMA nodes to exercise NUMA bus locking for NUMA systems.
.TP
.B \-\-lockbus\-nosplit
disable split locks that lock across cache line boundaries.
.TP
.B \-\-lockbus\-ops N
stop lockbus workers after N bogo operations.
.RE
.TP
.B POSIX lock (F_SETLK/F_GETLK) stressor
.RS 5
.TQ
.B \-\-locka N
start N workers that randomly lock and unlock regions of a file using the
POSIX advisory locking mechanism (see fcntl(2), F_SETLK, F_GETLK). Each
worker creates a 1024 KB file and attempts to hold a maximum of 1024
concurrent locks with a child process that also tries to hold 1024
concurrent locks. Old locks are unlocked in a first-in, first-out basis.
.TP
.B \-\-locka\-ops N
stop locka workers after N bogo locka operations.
.RE
.TP
.B POSIX lock (lockf) stressor
.RS 5
.TQ
.B \-\-lockf N
start N workers that randomly lock and unlock regions of a file using the
POSIX lockf(3) locking mechanism. Each worker creates a 64 KB file and
attempts to hold a maximum of 1024 concurrent locks with a child process
that also tries to hold 1024 concurrent locks. Old locks are unlocked in
a first-in, first-out basis.
.TP
.B \-\-lockf\-nonblock
instead of using blocking F_LOCK lockf(3) commands, use non-blocking F_TLOCK
commands and re-try if the lock failed.  This creates extra system call
overhead and CPU utilisation as the number of lockf workers increases and
should increase locking contention.
.TP
.B \-\-lockf\-ops N
stop lockf workers after N bogo lockf operations.
.RE
.TP
.B mixed file lock stressor (locka, lockf, lockofd)
.RS 5
.TQ
.B \-\-lockmix N
start N workers that randomly lock and unlock regions of a file using the
BSD flock(2), locka (advisory), POSIX lockf(3) and Linux open file lock (lockofd) locking
mechanisms.  Each worker creates a 1024 KB file and attempts to hold a
maximum of 1024 concurrent locks with a child process that also tries to
hold 1024 concurrent locks. Old locks are unlocked in a first-in,
first-out basis.
.TP
.B \-\-lockmix\-ops N
stop lockmix workers after N bogo lockmix operations.
.RE
.TP
.B Linux open file lock (ofd F_OFD_SETLK/F_OFD_GETLK) stressor
.RS 5
.TQ
.B \-\-lockofd N
start N workers that randomly lock and unlock regions of a file using the
Linux open file description locks (see fcntl(2), F_OFD_SETLK, F_OFD_GETLK).
Each worker creates a 1024 KB file and attempts to hold a maximum of 1024
concurrent locks with a child process that also tries to hold 1024
concurrent locks. Old locks are unlocked in a first-in, first-out basis.
.TP
.B \-\-lockofd\-ops N
stop lockofd workers after N bogo lockofd operations.
.RE
.TP
.B Logarithmic functions
.RS 5
.TQ
.B \-\-logmath N
start N workers that exercise various libm logarithmic functions with input values 1 to 10000.
Results are sanity checked to ensure no variation occurs after each round of 10000 computations.
.TP
.B \-\-logmath\-ops N
stop after N logarithmic bogo-operation loops.
.TP
.B \-\-logmath\-method method
specify a logarithmic function to exercise. Available logarithmic stress methods are described
as follows:
.sp
.TS
lB2 lB
l lx.
Method	Description
all	T{
iterate over all the below logarithmic functions methods
T}
clog	T{
double complex natural logarithm
T}
clogf	T{
float complex natural logarithm
T}
clogl	T{
long double complex natural logarithm
T}
log	T{
double natural logarithm
T}
logf	T{
float natural logarithm
T}
logl	T{
long double natural logarithm
T}
logb	T{
get exponent of a double
T}
logbf	T{
get exponent of a float
T}
logbl	T{
get exponent of a long double
T}
log10	T{
double base-10 logarithm
T}
log10f	T{
float base-10 logarithm
T}
log10l	T{
long double base-10 logarithm
T}
log2	T{
double base-2 logarithm
T}
log2f	T{
float base-2 logarithm
T}
log2l	T{
long double base-2 logarithm
T}
.TE
.RE
.TP
.B Long jump (longjmp) stressor
.RS 5
.TQ
.B \-\-longjmp N
start N workers that exercise setjmp(3)/longjmp(3) by rapid looping on
longjmp calls.
.TP
.B \-\-longjmp\-ops N
stop longjmp stress workers after N bogo longjmp operations (1 bogo op is 1000
longjmp calls).
.RE
.TP
.B Loopback stressor (Linux)
.RS 5
.TQ
.B \-\-loop N
start N workers that exercise the loopback control device. This creates 2 MB
loopback devices, expands them to 4 MB, performs some loopback status information
get and set operations and then destroys them. Linux only and requires
CAP_SYS_ADMIN capability.
.TP
.B \-\-loop\-ops N
stop after N bogo loopback creation/deletion operations.
.RE
.TP
.B Linear search stressor
.RS 5
.TQ
.B \-\-lsearch N
start N workers that linear search a unsorted array of 32 bit integers using
lsearch(3). By default, there are 8192 elements in the array.  This is a
useful method to exercise sequential access of memory and processor cache.
.TP
.B \-\-lsearch\-method [ lsearch\-libc | lsearch\-nonlibc | lsearch\-sentinel ]
select either the libc implementation of lsearch or a slightly optimized non-libc
implementation of lsearch or a lsearch that uses the search key as the end of array
sentinel to remove an index compare per loop. The default is the libc implementation
if it exists, otherwise the non-libc version.
.TP
.B \-\-lsearch\-ops N
stop the lsearch workers after N bogo lsearch operations are completed.
.TP
.B \-\-lsearch\-size N
specify the size (number of 32 bit integers) in the array to lsearch. Size can
be from 1 K to 4 M.
.RE
.TP
.B Linux Security Modules system call stressor
.RS 5
.TQ
.B \-\-lsm N
start N workers that exercise the LSM system calls lsm_list_modules(2) and
lsm_get_self_attr(2), (Linux only).  Each bogo\-op loop fetches a list of
available security modules and fetching LSM attributes as well as some
invalid LSM system calls to exercise error handling.
.TP
.B \-\-lsm\-ops N
stop after N loops of fetching security modules lists and fetching LSM attributes.
.RE
.TP
.B Madvise stressor
.RS 5
.TQ
.B \-\-madvise N
start N workers that apply random madvise(2) advise settings on pages of
a 4 MB file backed shared memory mapping.
.TP
.B \-\-madvise\-hwpoison
enable MADV_HWPOISON page poisoning (if available, only when run as root). This
will page poison a few pages and will cause kernel error messages to be
reported.
.TP
.B \-\-madvise\-ops N
stop madvise stressors after N bogo madvise operations.
.RE
.TP
.B Memory allocation stressor
.RS 5
.TQ
.B \-\-malloc N
start N workers continuously calling malloc(3), calloc(3), realloc(3),
posix_memalign(3), aligned_alloc(3), memalign(3) and free(3). By
default, up to 65536 allocations can be active at any point, but
this can be altered with the \-\-malloc\-max option.  Allocation,
reallocation and freeing are chosen at random; 50% of the time memory
is allocation (via one of malloc, calloc or realloc, posix_memalign,
aligned_alloc, memalign) and 50% of the time allocations are free'd.
Allocation sizes are also random, with the maximum allocation size controlled
by the \-\-malloc\-bytes option, the default size being 64 K.  The worker is
re-started if it is killed by the out of memory (OOM) killer.
.TP
.B \-\-malloc\-bytes N
maximum per allocation/reallocation size. Allocations are randomly selected
from 1 to N bytes. One can specify the size as % of total available memory
or in units of Bytes, KBytes, MBytes and GBytes using the suffix b, k, m or
g.  Large allocation sizes cause the memory allocator to use mmap(2) rather
than expanding the heap using brk(2).
.TP
.B \-\-malloc\-max N
maximum number of active allocations allowed. Allocations are chosen at random
and placed in an allocation slot. Because about 50%/50% split between
allocation and freeing, typically half of the allocation slots are in use at
any one time.
.TP
.B \-\-malloc\-mlock
attempt to mlock(2) the allocations into memory to prevent them from being
swapped out.
.TP
.B \-\-malloc\-ops N
stop after N malloc bogo operations. One bogo operations relates to a
successful malloc(3), calloc(3), realloc(3), posix_memalign(3),
aligned_alloc(3) or memalign(3) call.
.TP
.B \-\-malloc\-pthreads N
specify number of malloc stressing concurrent pthreads to run. The default is
0 (just one main process, no pthreads). This option will do nothing if pthreads
are not supported.
.TP
.B \-\-malloc\-thresh N
specify the threshold where malloc uses mmap(2) instead of sbrk(2) to allocate
more memory. This is only available on systems that provide the GNU C
mallopt(3) tuning function.
.TP
.B \-\-malloc\-touch
touch every allocated page to force pages to be populated in memory. This will
increase the memory pressure and exercise the virtual memory harder. By default
the malloc stressor will madvise pages into memory or use mincore to check for
non-resident memory pages and try to force them into memory; this option
aggressively forces pages to be memory resident.
.TP
.B \-\-malloc\-trim
periodically trim memory allocation by attempting to release free memory from
the heap every 65536 allocation iterations. This can be a time consuming
operation. It is only available with libc malloc implementations that
support malloc_trim(3).
.TP
.B \-\-malloc\-zerofree
zero allocated memory before free'ing. This can be useful in touching broken
allocations and triggering failures. Also useful for forcing extra
cache/memory writes.
.RE
.TP
.B 2D Matrix stressor
.RS 5
.TQ
.B \-\-matrix N
start N workers that perform various matrix operations on floating point
values. Testing on 64 bit x86 hardware shows that this provides a good
mix of memory, cache and floating point operations and is an excellent way
to make a CPU run hot.

By default, this will exercise all the matrix stress methods one by
one on a 128 \(mu 128 element matrix. One can specify a specific matrix
stress method with the \-\-matrix\-method option.
.TP
.B \-\-matrix\-method method
specify a matrix stress method. Available matrix stress methods are described
as follows:
.sp
.TS
lB2 lB
l lx.
Method	Description
all	T{
iterate over all the below matrix stress methods
T}
add	T{
add two N \(mu N matrices
T}
copy	T{
copy one N \(mu N matrix to another
T}
div	T{
divide an N \(mu N matrix by a scalar
T}
frobenius	T{
Frobenius product of two N \(mu N matrices
T}
hadamard	T{
Hadamard product of two N \(mu N matrices
T}
identity	T{
create an N \(mu N identity matrix
T}
mean	T{
arithmetic mean of two N \(mu N matrices
T}
mult	T{
multiply an N \(mu N matrix by a scalar
T}
negate	T{
negate an N \(mu N matrix
T}
prod	T{
product of two N \(mu N matrices
T}
sub	T{
subtract one N \(mu N matrix from another N \(mu N matrix
T}
square	T{
multiply an N \(mu N matrix by itself
T}
trans	T{
transpose an N \(mu N matrix
T}
zero	T{
zero an N \(mu N matrix
T}
.TE
.TP
.B \-\-matrix\-ops N
stop matrix stress workers after N bogo operations.
.TP
.B \-\-matrix\-size N
specify the N \(mu N size of the matrices.  Smaller values result in a
floating point compute throughput bound stressor, where as large values result
in a cache and/or memory bandwidth bound stressor.
.TP
.B \-\-matrix\-yx
perform matrix operations in order y by x rather than the default x by y. This
is suboptimal ordering compared to the default and will perform more data
cache stalls.
.RE
.TP
.B 3D Matrix stressor
.RS 5
.TQ
.B \-\-matrix\-3d N
start N workers that perform various 3D matrix operations on floating point
values. Testing on 64 bit x86 hardware shows that this provides a good
mix of memory, cache and floating point operations and is an excellent way
to make a CPU run hot.

By default, this will exercise all the 3D matrix stress methods one by
one on a 128 \(mu 128 \(mu 128 element matrix. One can specify a specific
3D matrix stress method with the \-\-matrix\-3d\-method option.
.TP
.B \-\-matrix\-3d\-method method
specify a 3D matrix stress method. Available 3D matrix stress methods are described
as follows:
.sp
.TS
lB2 lB
l lx.
Method	Description
all	T{
iterate over all the below matrix stress methods
T}
add	T{
add two N \(mu N \(mu N matrices
T}
copy	T{
copy one N \(mu N \(mu N matrix to another
T}
div	T{
divide an N \(mu N \(mu N matrix by a scalar
T}
frobenius	T{
Frobenius product of two N \(mu N \(mu N matrices
T}
hadamard	T{
Hadamard product of two N \(mu N \(mu N matrices
T}
identity	T{
create an N \(mu N \(mu N identity matrix
T}
mean	T{
arithmetic mean of two N \(mu N \(mu N matrices
T}
mult	T{
multiply an N \(mu N \(mu N matrix by a scalar
T}
negate	T{
negate an N \(mu N \(mu N matrix
T}
sub	T{
subtract one N \(mu N \(mu N matrix from another N \(mu N \(mu N matrix
T}
trans	T{
transpose an N \(mu N \(mu N matrix
T}
zero	T{
zero an N \(mu N \(mu N matrix
T}
.TE
.TP
.B \-\-matrix\-3d\-ops N
stop the 3D matrix stress workers after N bogo operations.
.TP
.B \-\-matrix\-3d\-size N
specify the N \(mu N \(mu N size of the matrices.  Smaller values result in a
floating point compute throughput bound stressor, where as large values result
in a cache and/or memory bandwidth bound stressor.
.TP
.B \-\-matrix\-3d\-zyx
perform matrix operations in order z by y by x rather than the default
x by y by z. This is suboptimal ordering compared to the default and will
perform more data cache stalls.
.RE
.TP
.B Memory contention stressor
.RS 5
.TQ
.B \-\-mcontend N
start N workers that produce memory contention read/write patterns. Each
stressor runs with 5 threads that read and write to two different mappings
of the same underlying physical page. Various caching operations are also
exercised to cause sub-optimal memory access patterns.  The threads also
randomly change CPU affinity to exercise CPU and memory migration stress.
.TP
.B \-\-mcontend\-numa
assign memory mapped pages to randomly selected NUMA nodes. This is disabled
for systems that do not support NUMA.
.TP
.B \-\-mcontend\-ops N
stop mcontend stressors after N bogo read/write operations.
.RE
.TP
.B Memory barrier stressor (Linux)
.RS 5
.TQ
.B \-\-membarrier N
start N workers that exercise the membarrier(2) system call (Linux only).
.TP
.B \-\-membarrier\-ops N
stop membarrier stress workers after N bogo membarrier operations.
.RE
.TP
.B Memory copy (memcpy) stressor
.RS 5
.TQ
.B \-\-memcpy N
start N workers that copies data to and from a buffer using
memcpy(3) and then move the data in the buffer with memmove(3) with 3
different alignments. This will exercise the data cache and memory copying.
.TP
.B \-\-memcpy\-method [ all | libc | builtin | naive | naive_o0 .. naive_o3 ]
specify a memcpy copying method. Available memcpy methods are described
as follows:
.sp
.TS
lB2 lB
l lx.
Method	Description
all	T{
use libc, builtin and na\[:i]ve methods
T}
libc	T{
use libc memcpy and memmove functions, this is the default
T}
builtin	T{
use the compiler built in optimized memcpy and memmove functions
T}
naive	T{
use na\[:i]ve byte by byte copying and memory moving build with default
compiler optimization flags
T}
naive_o0	T{
use unoptimized na\[:i]ve byte by byte copying and memory moving
T}
naive_o1	T{
use unoptimized na\[:i]ve byte by byte copying and memory moving with -O1
optimization
T}
naive_o2	T{
use optimized na\[:i]ve byte by byte copying and memory moving build with -O2
optimization and where possible use CPU specific optimizations
T}
naive_o3	T{
use optimized na\[:i]ve byte by byte copying and memory moving build with -O3
optimization and where possible use CPU specific optimizations
T}
.TE
.TP
.B \-\-memcpy\-ops N
stop memcpy stress workers after N bogo memcpy operations.
.RE
.TP
.B Anonymous file (memfd) stressor
.RS 5
.TQ
.B \-\-memfd N
start N workers that create allocations of 1024 pages using memfd_create(2)
and ftruncate(2) for allocation and mmap(2) to map the allocation into the
process address space.  (Linux only).
.TP
.B \-\-memfd\-bytes N
allocate N bytes per memfd stress worker, the default is 256 MB. One can specify
the size in as % of total available memory or in units of Bytes, KBytes, MBytes
and GBytes using the suffix b, k, m or g.
.TP
.B \-\-memfd\-fds N
create N memfd file descriptors, the default is 256. One can select 8 to 4096
memfd file descriptions with this option.
.TP
.B \-\-memfd\-madvise
enable random madvise page advice on memfd memory mapped regions to add
a little more VM exercising.
.TP
.B \-\-memfd\-mlock
attempt to mlock(2) mmap'd pages into memory causing more memory pressure by
preventing pages from swapped out.
.TP
.B \-\-memfd\-numa
assign memory mapped pages to randomly selected NUMA nodes. This is disabled
for systems that do not support NUMA.
.TP
.B \-\-memfd\-ops N
stop after N memfd-create(2) bogo operations.
.TP
.B \-\-memfd\-zap\-pte
exercise zapping page-table-entries to try to reproduce a Linux kernel bug
that was fixed by commit 5abfd71d936a8aefd9f9ccd299dea7a164a5d455 "mm: don't
skip swap entry even if zap_details specified". This will slow the stressor
down significantly and hence is an opt-in memfd stressor option.
.RE
.TP
.B Memory hotplug stressor (Linux)
.RS 5
.TQ
.B \-\-memhotplug N
start N workers that offline and online memory hotplug regions. Linux only
and requires CAP_SYS_ADMIN capabilities.
.TP
.B \-\-memhotplug\-mmap
enable random 1 K to 1 MB memory mapping/unmappings before each offline event.
.TP
.B \-\-memhotplug\-ops N
stop memhotplug stressors after N memory offline and online bogo operations.
.RE
.TP
.B Memory read/write stressor
.RS 5
.TQ
.B \-\-memrate N
start N workers that exercise a buffer with 1024, 512, 256, 128, 64, 32, 16 and
8 bit reads and writes. 1024, 512 and 256 reads and writes are available with
compilers that support integer vectors.  x86-64 cpus that support uncached
(non-temporal "nt") writes also exercise 128, 64 and 32 writes providing
higher write rates than the normal cached writes. x86-64 also exercises repeated
string stores using 64, 32, 16 and 8 bit writes.  CPUs that support prefetching
reads also exercise 64 prefetched "pf" reads.
This memory stressor allows one to also specify the maximum read
and write rates. The stressors will run at maximum speed if no read or
write rates are specified.
.TP
.B \-\-memrate\-bytes N
specify the size of the memory buffer being exercised. The default size
is 256 MB. One can specify the size in units of Bytes, KBytes, MBytes and
GBytes using the suffix b, k, m or g, or cache sizes with L1, L2, L3 or
LLC (lower level cache size).
.TP
.B \-\-memrate\-flush
flush cache between each memory exercising test to remove caching benefits in
memory rate metrics.
.TP
.B \-\-memrate\-method
specify a memrate stress method, some methods are available to specific architectures
or toolchains that support them. Available memrate stress methods are described
as follows:
.sp
.TS
lB2 lB
l lx.
Method	Description
all	iterate over all the below memrate methods
read128pf	read 128 bits per read using prefetching
read64pf	read 64 bits per read using prefetching
read1024	read a vector of 1024 bits per read
read512	read a vector of 512 bits per read
read256	read a vector of 256 bits per read
read128	read 128 bits per read
read64	read 64 bits per read
read32	read 32 bits per read
read16	read 16 bits per read
read8	read 8 bits per read
write64stoq	write 64 bits per write with x86 rep stoq
write32stow	write 32 bits per write with x86 rep stow
write16stod	write 16 bits per write with x86 rep stod
write8stob	write 8 bits per write with x86 rep stob
write64ds	write 64 bits per write with x86 movdiri
write128nt	write 128 bits per write using non-temporal store
write64nt	write 64 bits per write using non-temporal store
write32nt	write 32 bits per write using non-temporal store
write1024	write a vector of 1024 bits per write
write512	write a vector of 512 bits per write
write256	write a vector of 256 bits per write
write128	write 128 bits per write
write64	write 64 bits per write
write32	write 32 bits per write
write16	write 16 bits per write
write8	write 8 bits per write
memset	write using libc memset
.TE
.TP
.B \-\-memrate\-ops N
stop after N bogo memrate operations.
.TP
.B \-\-memrate\-rd\-mbs N
specify the maximum allowed read rate in MB/sec. The actual read rate
is dependent on scheduling jitter and memory accesses from other running
processes. Setting this to zero will disable reads.
.TP
.B \-\-memrate\-wr\-mbs N
specify the maximum allowed read rate in MB/sec. The actual write rate
is dependent on scheduling jitter and memory accesses from other running
processes. Setting this to zero will disable writes.
.RE
.TP
.B Memory thrash stressor
.RS 5
.TQ
.B \-\-memthrash N
start N workers that thrash and exercise a 16 MB buffer in various ways to
try and trip thermal overrun.  Each stressor will start 1 or more threads.
The number of threads is chosen so that there will be at least 1 thread
per CPU. Note that the optimal choice for N is a value that divides into
the number of CPUs.
.TP
.B \-\-memthrash\-method method
specify a memthrash stress method. Available memthrash stress methods are described
as follows:
.sp
.TS
lB2 lB
l lx.
Method	Description
all	T{
iterate over all the below memthrash methods
T}
chunk1	T{
memset 1 byte chunks of random data into random locations
T}
chunk8	T{
memset 8 byte chunks of random data into random locations
T}
chunk64	T{
memset 64 byte chunks of random data into random locations
T}
chunk256	T{
memset 256 byte chunks of random data into random locations
T}
chunkpage	T{
memset page size chunks of random data into random locations
T}
copy128	T{
copy 128 byte chunks from chunk N \(pl 1 to chunk N with streaming
reads and writes with 128 bit memory accesses where possible.
T}
flip	T{
flip (invert) all bits in random locations
T}
flush	T{
flush cache line in random locations
T}
lock	T{
lock randomly choosing locations (Intel x86 and ARM CPUs only)
T}
matrix	T{
treat memory as a 2 \(mu 2 matrix and swap random elements
T}
memmove	T{
copy all the data in buffer to the next memory location
T}
memset	T{
memset the memory with random data
T}
memset64	T{
memset the memory with a random 64 bit value in 64 byte chunks using
non-temporal stores if possible or normal stores as a fallback
T}
memsetstosd	T{
memset the memory using x86 32 bit rep stosd instruction (x86 only)
T}
mfence	T{
stores with write serialization
T}
numa	T{
memory bind pages across numa nodes
T}
prefetch	T{
prefetch data at random memory locations
T}
random	T{
randomly run any of the memthrash methods except for `random' and `all'
T}
reverse	T{
swap 8 bit values from start to end and work towards the middle
T}
spinread	T{
spin loop read the same random location 2\[ua]19 times
T}
spinwrite	T{
spin loop write the same random location 2\[ua]19 times
T}
swap	T{
step through memory swapping bytes in steps of 65 and 129 byte strides
T}
swap64	T{
work through memory swapping adjacent 64 byte chunks
T}
swapfwdrev	T{
swap 64 bit values from start to end and work towards the middle and then
from end to start and work towards the middle.
T}
tlb	T{
work through memory in sub-optimial strides of prime multiples of the cache
line size with reads and then writes to cause Translation Lookaside Buffer
(TLB) misses.
T}
.TE
.TP
.B \-\-memthrash\-ops N
stop after N memthrash bogo operations.
.RE
.TP
.B BSD mergesort stressor
.RS 5
.TQ
.B -\-mergesort N
start N workers that sort 32 bit integers using the BSD mergesort(3).
.TP
.B \-\-mergesort\-method [ mergesort\-libc | mergesort\-nonlibc ]
select either the libc implementation of mergesort or an unoptimized
implementation of mergesort. The default is the libc implementation if it
is available.
.TP
.B \-\-mergesort\-ops N
stop mergesort stress workers after N bogo mergesorts.
.TP
.B \-\-mergesort\-size N
specify number of 32 bit integers to sort, default is 262144 (256 \(mu 1024).
.RE
.TP
.B File metadata mix
.RS 5
.TQ
.B \-\-metamix N
start N workers that generate a file metadata mix of operations. Each stressor
runs 16 concurrent processes that each exercise a file's metadata with sequences
of open, 256 lseeks and writes, fdatasync, close, fsync and then stat, open,
256 lseeks, reads, occasional file memory mapping, close, unlink and lstat.
.TP
.B \-\-metamix\-bytes N
set the size of metamix files, the default is 1 MB. One can specify the size
as % of free space on the file system or in units of Bytes, KBytes, MBytes and
GBytes using the suffix b, k, m or g.
.TP
.B -\-metamix\-ops N
stop the metamix stressor after N bogo metafile operations.
.RE
.TP
.B Resident memory (mincore) stressor
.RS 5
.TQ
.B \-\-mincore N
start N workers that walk through all of memory 1 page at a time checking if
the page mapped and also is resident in memory using mincore(2). It also
maps and unmaps a page to check if the page is mapped or not using mincore(2).
.TP
.B \-\-mincore\-ops N
stop after N mincore bogo operations. One mincore bogo op is equivalent to a
300 mincore(2) calls.
.TP
.B \-\-mincore\-random
instead of walking through pages sequentially, select pages at random. The
chosen address is iterated over by shifting it right one place and checked by
mincore until the address is less or equal to the page size.
.RE
.TP
.B Minimum sleep time in nanosleep stressor
.RS 5
.TQ
.B \-\-min\-nanosleep N
start M workers that exercise nanosecond sleeps using powers of two nanosecond
sleep delays. Once all the instances have completed, the minimum, maximum and mean
sleep times are reported for the sleep delays across all the min-nanosleep stressor
instances.
.TP
.B \-\-min\-nanosleep\-ops N
stop after N rounds of measurements across all the sleeps are completed.
.TP
.B \-\-min\-nanosleep\-max N
set the maximum nanosleep delay to use. If this is not a power of two then the
previous power of two nanosecond delay time is used, e.g. specifying 10000 will
select 8192 nanoseconds.
.TP
.B \-\-min\-nanosleep\-sched [ batch | deadline | ext | fifo | idle | other | rr ]
select scheduling policy. Note that deadline, fifo and rr require root privilege.
.RE
.TP
.B Misaligned read/write stressor
.RS 5
.TQ
.B \-\-misaligned N
start N workers that perform misaligned read and writes. By default, this
will exercise 128 bit misaligned read and writes in 8 \(mu 16 bits, 4 \(mu 32 bits,
2 \(mu 64 bits and 1 \(mu 128 bits at the start of a page boundary, at the end
of a page boundary and over a cache boundary. Misaligned read and writes
operate at 1 byte offset from the natural alignment of the data
type. On some architectures this can cause SIGBUS, SIGILL or SIGSEGV, these are
handled and the misaligned stressor method causing the error is disabled.
.TP
.B \-\-misaligned\-method method
Available misaligned stress methods are described as follows:
.sp
.TS
lB2 lB
l lx.
Method	Description
all	iterate over all the following misaligned methods
int16rd	8 \(mu 16 bit integer reads
int16wr	8 \(mu 16 bit integer writes
int16inc	8 \(mu 16 bit integer increments
int16atomic	8 \(mu 16 bit atomic integer increments
int32rd	4 \(mu 32 bit integer reads
int32wr	4 \(mu 32 bit integer writes
int32wtnt	4 \(mu 32 bit non-temporal stores (x86 only)
int32inc	4 \(mu 32 bit integer increments
int32atomic	4 \(mu 32 bit atomic integer increments
int64rd	2 \(mu 64 bit integer reads
int64wr	2 \(mu 64 bit integer writes
int64wrds	4 \(mu 64 bit direct stores (x86 only)
int64wtnt	4 \(mu 64 bit non-temporal stores (x86 only)
int64inc	2 \(mu 64 bit integer increments
int64atomic	2 \(mu 64 bit atomic integer increments
int128rd	1 \(mu 128 bit integer reads
int128wr	1 \(mu 128 bit integer writes
int128inc	1 \(mu 128 bit integer increments
int128atomic	1 \(mu 128 bit atomic integer increments
.TE
.PP
Note that some of these options (128 bit integer and/or atomic operations) may
not be available on some systems.
.TP
.B \-\-misaligned\-ops N
stop after N misaligned bogo operation. A misaligned bogo op is equivalent
to 65536 \(mu 128 bit reads or writes.
.RE
.TP
.B Mknod/unlink stressor
.RS 5
.TQ
.B \-\-mknod N
start N workers that create and remove fifos, empty files and named sockets
using mknod(2) and unlink(2).
.TP
.B \-\-mknod\-ops N
stop directory thrash workers after N bogo mknod operations.
.RE
.TP
.B Memory mapped pages lock/unlock stressor
.RS 5
.TQ
.B \-\-mlock N
start N workers that lock and unlock memory mapped pages using mlock(2),
munlock(2), mlockall(2) and munlockall(2). This is achieved by the mapping of
three contiguous pages and then locking the second page, hence ensuring
non-contiguous pages are locked . This is then repeated until the maximum
allowed mlocks or a maximum of 262144 mappings are made.  Next, all future
mappings are mlocked and the worker attempts to map 262144 pages, then all
pages are munlocked and the pages are unmapped.
.TP
.B \-\-mlock\-ops N
stop after N mlock bogo operations.
.RE
.TP
.B Many child memory mapped page lock/unlock process stressor
.RS 5
.TQ
.B \-\-mlockmany N
start N workers that fork off a default of 1024 child processes in total;
each child will attempt to anonymously mmap(2) and mlock(2) the maximum allowed
mlockable memory size.  The stress test attempts to avoid swapping by
tracking low memory and swap allocations (but some swapping may occur). Once
either the maximum number of child process is reached or all mlockable in-core
memory is locked then child processes are killed and the stress test is
repeated.
.TP
.B \-\-mlockmany\-ops N
stop after N mlockmany (mmap and mlock) operations.
.TP
.B \-\-mlockmany\-procs N
set the number of child processes to create per stressor. The default is to
start a maximum of 1024 child processes in total across all the stressors. This
option allows the setting of N child processes per stressor.
.RE
.TP
.B Memory mapping (mmap/munmap) stressor
.RS 5
.TQ
.B \-\-mmap N
start N workers continuously calling mmap(2)/munmap(2).  The initial mapping
is a large chunk (size specified by \-\-mmap\-bytes) followed by pseudo-random
4 K unmappings, then pseudo-random 4 K mappings, and then linear 4 K unmappings.
Note that this can cause systems to trip the kernel OOM killer on Linux
systems if not enough physical memory and swap is not available.  The
MAP_POPULATE option is used to populate pages into memory on systems that
support this.  By default, anonymous mappings are used, however, the
\-\-mmap\-file and \-\-mmap\-async options allow one to perform file based
mappings if desired.
.RS
.PP
Note that since stress\-ng 0.17.05 the \-\-mmap\-madvise, \-\-mmap\-mergeable,
\-\-mmap\-mprotect, \-\-mmap\-slow\-munmap and \-\-mmap\-write\-check options
should be used to enable the pre-0.17.05 mmap stressor behaviour.
.RE
.TP
.B \-\-mmap\-async
enable file based memory mapping and use asynchronous msync'ing on each page,
see \-\-mmap\-file.
.TP
.B \-\-mmap\-bytes N
allocate N bytes in total for all the mmap stressor instances, the default is
256 MB. One can specify the size as % of total available memory or in units of
Bytes, KBytes, MBytes and GBytes using the suffix b, k, m or g.
.TP
.B \-\-mmap\-file
enable file based memory mapping and by default use synchronous msync'ing on
each page.
.TP
.B \-\-mmap\-madvise
enable randomized madvise(2) settings on pages.
.TP
.B \-\-mmap\-mergeable
mark pages as mergeable via madvise(2) where possible.
.TP
.B \-\-mmap\-mlock
attempt to mlock(2) mmap'd pages into memory causing more memory pressure by
preventing pages from swapped out.
.TP
.B \-\-mmap\-mmap2
use mmap2(2) for 4 K page aligned offsets if mmap2 is available, otherwise fall back
to mmap.
.TP
.B \-\-mmap\-mprotect
change protection settings on each page of memory.  Each time a page or a
group of pages are mapped or remapped then this option will make the pages
read-only, write-only, exec-only, and read-write.
.TP
.B \-\-mmap\-numa
assign memory mapped pages to randomly selected NUMA nodes. This is disabled
for systems that do not support NUMA.
.TP
.B \-\-mmap\-odirect
enable file based memory mapping and use O_DIRECT direct I/O.
.TP
.B \-\-mmap\-ops N
stop mmap stress workers after N bogo operations.
.TP
.B \-\-mmap\-osync
enable file based memory mapping and used O_SYNC synchronous I/O
integrity completion.
.TP
.B \-\-mmap\-slow\-munmap
enable page-by-page memory unmapping rather than attempting to memory unmap
contiguous pages in one large unmapping. This can cause lock contention when
running with many concurrent mmap stressors and will slow down the stressor.
.TP
.B \-\-mmap\-stressful
enable \-\-mmap\-file, \-\-mmap\-madvise, \-\-mmap\-mergeable,
\-\-mmap\-mlock, \-\-mmap\-mprotect, \-\-mmap\-odirect,
\-\-mmap\-slow\-munmap
.TP
.B \-\-mmap\-write\-check
write into each page a unique 64 bit check value for all pages and
then read the value for a sanity check. This will force newly memory mapped
pages to be faulted-in which slows down mmap bogo-op rate. This can also
cause lock contention on page allocation and page unmapping on systems
with many CPU threads and with cgroup memory accounting.
.RE
.TP
.B Random memory map/unmap stressor
.RS 5
.TQ
.B \-\-mmapaddr N
start N workers that memory map pages at a random memory location that is
not already mapped.  On 64 bit machines the random address is randomly
chosen 32 bit or 64 bit address. If the mapping works a second page is
memory mapped from the first mapped address. The stressor exercises
mmap/munmap, mincore and segfault handling.
.TP
.B \-\-mmapaddr\-mlock
attempt to mlock(2) mmap'd pages into memory causing more memory pressure by
preventing pages from swapped out.
.TP
.B \-\-mmapaddr\-ops N
stop after N random address mmap bogo operations.
.RE
.TP
.B Memory map Copy-on-Write and unmap stressor
.RS 5
.TQ
.B \-\-mmapcow N
start N workers that exercise page allocation, modification (forcing copy-on-write)
and page unmapping. Regions of memory from 1 page to the maximum mappable size
are allocated. Each page in the regions are then modified, cache flushed (where
possible) and unmapped. This stressor produces a high page fault rate. For each
region mapped there are 6 different randomized strategies taken to exercise each page:
.sp
.TS
lx.
Sequential page modify and unmap
Sequential page modify and unmap (even pages, then odd pages)
Prime size page strides, page modify and unmap
Reverse sequential page modify and unmap
Reverse sequential page modify and unmap (even pages, then odd pages)
Single random page modify and unmap all pages
Randomly selected page modify and modify
.TE
.TP
.B \-\-mmapcow\-fork
fork child process to exercise pages in parallel with parent to exercise page
handling harder.
.TP
.B \-\-mmapcow\-free
after each page is modified and before each page is unmapped use madvise(2) MADV_FREE
(if it is available) to indicate the page is free
.TP
.B \-\-mmapcow\-mlock
attempt to mlock(2) each modified page, this can increase the number of page
faults. Only available with the mlock2 system call.
.TP
.B \-\-mmapcow\-numa
assign memory mapped pages to randomly selected NUMA nodes. This is disabled
for systems that do not support NUMA.
.TP
.B \-\-mmapcow\-ops N
stop after N pages are modified  and unmapped
.RE
.TP
.B Forked memory map stressor
.RS 5
.TQ
.B \-\-mmapfork N
start N workers that each fork off 32 child processes, each of which tries to
allocate some of the free memory left in the system (and trying to avoid
any swapping).  The child processes then hint that the allocation will be
needed with madvise(2) and then memset it to zero and hint that it is no longer
needed with madvise before exiting.  This produces significant amounts of VM
activity, a lot of cache misses and with minimal swapping.
.TP
.B \-\-mmapfork\-bytes N
specify the size of memory mapped fork region size. One can specify the size
in units of Bytes, KBytes, MBytes and GBytes using the suffix b, k, m or g.
.TP
.B \-\-mmapfork\-ops N
stop after N mmapfork bogo operations.
.RE
.TP
.B Memory map files stressor
.RS 5
.TQ
.B \-\-mmapfiles N
start N workers that attempt to memory map and then unmap up to 512 \(mu 1024
files into memory. The stressor will traverse /lib, /lib32, /lib64, /boot,
/bin, /etc, /sbin, /usr, /var, /sys and /proc and attempt to memory map files
in these directories. Note that mapping bogo-ops rate will depend on the speed of
access to files on these file systems.
.TP
.B \-\-mmapfiles\-numa
assign memory mapped pages to randomly selected NUMA nodes. This is disabled
for systems that do not support NUMA.
.TP
.B \-\-mmapfiles\-ops N
stop after N memory map/unmap operations.
.TP
.B \-\-mmapfiles\-populate
The default is to perform a memory mapping and not fault any pages into
physical memory. This option uses MAP_POPULATE when available and will also
read the first byte in each page to ensure pages are faulted into memory
to force memory population from file.
.TP
.B \-\-mmapfiles\-shared
The default is for private memory mapped files, however, with this option
will use shared memory mappings.
.RE
.TP
.B Fixed address memory map stressor
.RS 5
.TQ
.B \-\-mmapfixed N
start N workers that perform fixed address allocations from the top virtual
address down to 128 K.  The allocated sizes are from 1 page to 8 pages and
various random mmap flags are used MAP_SHARED/MAP_PRIVATE, MAP_LOCKED,
MAP_NORESERVE, MAP_POPULATE. If successfully map'd then the allocation
is remap'd first to a large range of addresses based on a random start
and finally an address that is several pages higher in memory. Mappings
and remappings are madvised with random madvise options to further exercise
the mappings.
.TP
.B \-\-mmapfixed\-mlock
attempt to mlock(2) mmap'd pages into memory causing more memory pressure by
preventing pages from swapped out.
.TP
.B \-\-mmapfixed\-numa
assign memory mapped pages to randomly selected NUMA nodes. This is disabled
for systems that do not support NUMA.
.TP
.B \-\-mmapfixed\-ops N
stop after N mmapfixed memory mapping bogo operations.
.RE
.TP
.B Huge page memory mapping stressor
.RS 5
.TQ
.B \-\-mmaphuge N
start N workers that attempt to mmap a set of huge pages and large huge
page sized mappings. Successful mappings are madvised with MADV_NOHUGEPAGE
and MADV_HUGEPAGE settings and then 1/64th of the normal small page size pages
are touched. Finally, an attempt to unmap a small page size page at the
end of the mapping is made (these may fail on huge pages) before the set
of pages are unmapped. By default 8192 mappings are attempted per round
of mappings or until swapping is detected.
.TP
.B \-\-mmaphuge\-file
attempt to mmap on a 16 MB temporary file and random 4 K offsets. If this fails,
anonymous mappings are used instead.
.TP
.B \-\-mmaphuge\-mlock
attempt to mlock(2) mmap'd huge pages into memory causing more memory pressure by
preventing pages from swapped out.
.TP
.B \-\-mmaphuge\-mmaps N
set the number of huge page mappings to attempt in each round of mappings. The
default is 8192 mappings.
.TP
.B \-\-mmaphuge\-numa
assign memory mapped pages to randomly selected NUMA nodes. This is disabled
for systems that do not support NUMA.
.TP
.B \-\-mmaphuge\-ops N
stop after N mmaphuge bogo operations
.RE
.TP
.B Maximum memory mapping per process stressor
.RS 5
.TQ
.B \-\-mmapmany N
start N workers that attempt to create the maximum allowed per-process memory
mappings. This is achieved by mapping 3 contiguous pages and then unmapping the
middle page hence splitting the mapping into two. This is then repeated until
the maximum allowed mappings or a maximum of 262144 mappings are made.
.TP
.B \-\-mmapmany\-mlock
attempt to mlock(2) mmap'd huge pages into memory causing more memory pressure by
preventing pages from swapped out.
.TP
.B \-\-mmapmany\-numa
assign memory mapped pages to randomly selected NUMA nodes. This is disabled
for systems that do not support NUMA.
.TP
.B \-\-mmapmany\-ops N
stop after N mmapmany bogo operations
.RE
.TP
.B Memory map random mapping operations
.RS 5
.TQ
.B \-\-mmaprandom N
start N workers that exercise a random mix of memory map related system
calls on randonmly sized mappings. The mappings are either
anonymous mapped or file mapped (on a small file or on a memfd file where
available). This exercises mmap(2) (random options and flags), munmap(2),
mlock(2), munlock(2), madvise(2), posix_madvise(3), mincore(2), mremap(2),
msync(2), mprotect(2), remap_file_pages(2), memory read, memory write and
cache flushing. Where possible, randomized options are used to generate a
mix of mostly valid (and some invalid) memory mapping operations. Metrics
are reported for all successful system calls and memory operations.
.TP
.B \-\-mmaprandom\-ops N
stop after N random memory mapping bogo-operations. Generally, 1 bogo-op is
one memory related system call (except for read/write/cache operations).
.TP
.B \-\-mmaprandom\-mappings N
select maximum number of memory mappings, the default is 1024,
range 1 to 65536.
.TP
.B \-\-mmaprandom\-maxpages N
select maximum number of pages to be memory mapped, the default is 8, range
2 to 1024. The pages mapped are randomly chosen from 1 to maxpages.
.TP
.B \-\-mmaprandom\-numa
assign randomly chosen memory mapped pages to randomly selected NUMA nodes.
This is disabled for systems that do not support NUMA.
.RE
.TP
.B Memory map torture stressor
.RS 5
.TQ
.B \-\-mmaptorture N
start N workers that exercise memory mapping operations on a shared file.
Mappings of various random sizes are tortured with calls to madvise(2),
mremap(2), mprotect(2), msync(2), mlock(2), munlock(2), mseal(2) and
mincore(2) while the underlying file is modified by writes, truncation and
hole punching. Mapped data is read and written and sync'd back to file. For
NUMA systems, pages are randomly placed across NUMA nodes. All this activity
causes cache misses, exercises the TLB and causes IPI interrupts between CPUs.
.TP
.B \-\-mmaptorture\-bytes N
allocate N bytes in total for all the mmaptorture stressor instances, the default is
256 MB. One can specify the size as % of total available memory or in units of
Bytes, KBytes, MBytes and GBytes using the suffix b, k, m or g.
.TP
.B \-\-mmaptorture\-msync N
memory mapped pages are msync'd various times per bogo-operation, this option
specifies the percentage amount of the pages per msync operation are msync'd. The
default is 10%. Specifying zero will disabled msync'ing.
.TP
.B \-\-mmaptorture\-ops N
stop after N iterations of memory mapping torture operations.
.RE
.TP
.B Kernel module loading stressor (Linux)
.RS 5
.TQ
.B \-\-module N
start N workers that use finit_module() to load the module specified
or the hello test module, if is available. There are different ways
to test loading modules. Using modprobe calls in a loop, using the kernel
kernel module autoloader, and this stress\-ng module stressor. To stress tests
modprobe we can simply run the userspace modprobe program in a loop. To stress
test the kernel module autoloader we can stress tests using the upstream
kernel tools/testing/selftests/kmod/kmod.sh. This ends up calling modprobe
in the end, and it has its own caps built-in to self protect the kernel from
too many requests at the same time. The userspace modprobe call will also
prevent calls if the same module exists already. The stress\-ng modules
stressor is designed to help stress test the finit_module() system call
even if the module is already loaded, testing races that are
otherwise hard to reproduce.
.TP
.B \-\-module\-name NAME
NAME of the module to use, for example: test_module, xfs, ext4. By default
test_module is used so CONFIG_TEST_LKM must be enabled in the kernel.
The module dependencies must be loaded prior to running these stressor
tests, as this stresses running finit_module() not using modprobe.
.TP
.B \-\-module\-no\-modver
ignore module modversions when using finit_module().
.TP
.B \-\-module\-no\-vermag
ignore module versions when using finit_module().
.TP
.B \-\-module\-no\-unload
do not unload the module right after loading it with finit_module().
.TP
.B \-\-module\-ops N
stop after N module load/unload cycles
.RE
.TP
.B Monte Carlo computations of \(*p and e and various integrals
.RS 5
.TQ
.B \-\-monte\-carlo N
start N stressors that compute \(*p and e (Euler's number) using Monte Carlo computational
experiments with various random number generators.
.TP
.B \-\-monte\-carlo\-method [ all | e | exp | pi | sin | sqrt | squircle ]
specify the computation to perform, options are as follows:
.sp
.TS
lB2 lB
l lx.
Method	Description
all	T{
use all monte carlo computation methods
T}
e	T{
compute Euler's constant e
T}
exp	T{
integrate exp(x \[ua] 2) for x \(eq 0..1
T}
pi	T{
compute \(*p from the area of a circle
T}
sin	T{
integrate sin(x) for x \(eq 0..\(*p
T}
sqrt	T{
integrate sqrt(1 \(pl x \[ua] 4) for x \(eq 0..1
T}
squircle	T{
area of a unit squircle x \[ua] 4 \(pl y \[ua] 4 \(eq 1
T}
.TE
.TP
.B \-\-monte\-carlo\-ops N
stop after Monte Carlo computation experiments
.TP
.B \-\-monte\-carlo\-rand [ all | drand48 | getrandom | lcg | pcg32 | mwc64 | random | xorshift ]
specify the random number generator to use, options are as follows:
.sp
.TS
lB2 lB
l lx.
Method	Description
all	T{
use all the random number generators
T}
arc4	T{
use the libc cryptographically-secure pseudorandom arc4random(3) number generator.
T}
drand48	T{
use the libc linear congruential algorithm drand48(3) using 48-bit integer arithmetic.
T}
getrandom	T{
use the getrandom(2) system call for random values.
T}
lcg	T{
use a 32 bit Paker-Miller Linear Congruential Generator, with a division optimization.
T}
pcg32	T{
use a 32 bit O'Neill Permuted Congruential Generator.
T}
mwc64	T{
use the 64 bit stress\-ng Multiply With Carry random number generator.
T}
random	T{
use the libc random(3) Non-linear Additive Feedback random number generator.
T}
xorshift	T{
use a 32 bit Marsaglia shift-register random number generator.
T}
.TE
.TP
.B \-\-monte\-carlo\-samples N
specify the number of random number samples to use to compute \(*p or e, default is 100000.
.RE
.TP
.B Multi-precision floating operations (mpfr) stressor
.RS 5
.TQ
.B \-\-mpfr N
start N workers that exercise multi-precision floating point operations using
the GNU Multi-Precision Floating Point Reliable library (mpfr). Operations computed
are as follows:
.sp
.TS
lB2 lB
l lx.
Method	Description
apery	T{
calculate Apery's constant \[*z](3); the sum of 1/(n \[ua] 3).
T}
cosine	T{
compute cos(\(*h) for \(*h \(eq 0 to 2\(*p in 100 steps.
T}
euler	T{
compute e using n \[eq] (1 \(pl (1 \[di] n)) \[ua] n.
T}
exp	T{
compute 1000 exponentials.
T}
log	T{
computer 1000 natural logarithms.
T}
omega	T{
compute the omega constant defined by \(*We\[ua]\(*W \(eq 1 using efficient
iteration of \(*W\dn\(pl1\u \(eq (1 \(pl \(*Wn) / (1 \(pl e\[ua]\(*Wn).
T}
phi	T{
compute the Golden Ratio \(*f using series.
T}
sine	T{
compute sin(\(*h) for \(*h \(eq 0 to 2\(*p in 100 steps.
T}
nsqrt	T{
compute square root using Newton-Raphson.
T}
.TE
.TP
.B \-\-mpfr\-ops N
stop workers after N iterations of various multi-precision floating point
operations.
.TP
.B \-\-mpfr\-precision N
specify the precision in binary digits of the floating point operations. The
default is 1000 bits, the allowed range is 32 to 1000000 (very slow).
.RE
.TP
.B Memory protection stressor
.RS 5
.TQ
.B \-\-mprotect N
start N workers that exercise changing page protection settings and access
memory after each change. 8 processes per worker contend with each other
changing page protection settings on a shared memory region of just a few pages
to cause TLB flushes. A read and write to the pages can cause segmentation
faults and these are handled by the stressor. All combinations of page
protection settings are exercised including invalid combinations.
.TP
.B \-\-mprotect\-ops N
stop after N mprotect calls.
.RE
.TP
.B POSIX message queue stressor (Linux)
.RS 5
.TQ
.B \-\-mq N
start N sender and receiver processes that continually send and receive
messages using POSIX message queues. (Linux only).
.TP
.B \-\-mq\-ops N
stop after N bogo POSIX message send operations completed.
.TP
.B \-\-mq\-size N
specify size of POSIX message queue. The default size is 10 messages and most
Linux systems this is the maximum allowed size for normal users. If the given
size is greater than the allowed message queue size then a warning is issued
and the maximum allowed size is used instead.
.RE
.TP
.B Memory remap stressor (Linux)
.RS 5
.TQ
.B \-\-mremap N
start N workers continuously calling mmap(2), mremap(2) and munmap(2).  The
initial anonymous mapping is a large chunk (size specified by
\-\-mremap\-bytes) and then iteratively halved in size by remapping all the
way down to a page size and then back up to the original size.  This worker
is only available for Linux.
.TP
.B \-\-mremap\-bytes N
initially allocate N bytes per remap stress worker, the default is 256 MB. One
can specify the size in units of Bytes, KBytes, MBytes and GBytes using the
suffix b, k, m or g.
.TP
.B \-\-mremap\-mlock
attempt to mlock(2) remap'd pages into memory causing more memory pressure by
preventing pages from swapped out.
.TP
.B \-\-mreamp\-numa
assign memory mapped pages to randomly selected NUMA nodes. This is disabled
for systems that do not support NUMA.
.TP
.B \-\-mremap\-ops N
stop mremap stress workers after N bogo operations.
.RE
.TP
.B Memory Sealing
.RS 5
.TQ
.B \-\-mseal N
start N memory sealing stressors that exercise madvise(2), mremap(2), mprotect(2)
and mseal(2) operations on two pages of of memory mapped anonymous private
memory. Linux 6.10+ kernels only.
.TP
.B \-\-mseal\-ops N
stop after N msealed memory operations.
.RE
.TP
.B System V message IPC stressor
.RS 5
.TQ
.B \-\-msg N
start N sender and receiver processes that continually send and receive
messages using System V message IPC.
.TP
.B \-\-msg\-bytes N
specify the size of the message being sent and received. Range 4 to 8192 bytes,
default is 4 bytes.
.TP
.B \-\-msg\-ops N
stop after N bogo message send operations completed.
.TP
.B \-\-msg\-types N
select the quality of message types (mtype) to use. By default, msgsnd sends
messages with a mtype of 1, this option allows one to send messages types
in the range 1..N to exercise the message queue receive ordering. This will
also impact throughput performance.
.RE
.TP
.B Synchronize file with memory map (msync) stressor
.RS 5
.TQ
.B \-\-msync N
start N stressors that msync data from a file backed memory mapping from
memory back to the file and msync modified data from the file back to the
mapped memory. This exercises the msync(2) MS_SYNC and MS_INVALIDATE sync
operations.
.TP
.B \-\-msync\-bytes N
allocate N bytes for the memory mapped file, the default is 256 MB. One
can specify the size as % of total available memory or in units of Bytes,
KBytes, MBytes and GBytes using the suffix b, k, m or g.
.TP
.B \-\-msync\-ops N
stop after N msync bogo operations completed.
.RE
.TP
.B Synchronize file with memory map (msync) coherency stressor
.RS 5
.TQ
.B \-\-msyncmany N
start N stressors that memory map up to 32768 pages on the same page of
a temporary file, change the first 32 bits in a page and msync the data back
to the file.  The other 32767 pages are examined to see if the 32 bit
check value is msync'd back to these pages.
.TP
.B \-\-msyncmany\-ops N
stop after N msync calls in the msyncmany stressors are completed.
.RE
.TP
.B ISO C mtx (mutex) stressor
.RS 5
.TQ
.B \-\-mtx N
start N stressors that exercise ISO C mutex locking and unlocking.
.TP
.B \-\-mtx\-ops N
stop after N bogo mutex lock/unlock operations.
.TP
.B \-\-mtx\-procs N
By default 2 threads are used for locking/unlocking on a single mutex. This option
allows the default to be changed to 2 to 64 concurrent threads.
.RE
.TP
.B Unmapping shared non-executable memory stressor (Linux)
.RS 5
.TQ
.B \-\-munmap N
start N stressors that exercise unmapping of shared non-executable mapped
regions of child processes (Linux only). The unmappings map shared memory regions page
by page with a prime sized stride that creates many temporary mapping holes.
One the unmappings are complete the child will exit and a new one is started.
Note that this may trigger segmentation faults in the child process, these
are handled where possible by forcing the child process to call _exit(2).
.TP
.B \-\-munmap\-ops N
stop after N page unmappings.
.RE
.TP
.B Pthread mutex stressor
.RS 5
.TQ
.B \-\-mutex N
start N stressors that exercise pthread mutex locking and unlocking. If run
with enough privilege then the FIFO scheduler is used and a random priority between
0 and 80% of the maximum FIFO priority level is selected for the locking operation.
The minimum FIFO priority level is selected for the critical mutex section and
unlocking operation to exercise random inverted priority scheduling.
.TP
.B \-\-mutex\-affinity
enable random CPU affinity changing between mutex lock and unlock.
.TP
.B \-\-mutex\-ops N
stop after N bogo mutex lock/unlock operations.
.TP
.B \-\-mutex\-procs N
By default 2 threads are used for locking/unlocking on a single mutex. This option
allows the default to be changed to 2 to 64 concurrent threads.
.RE
.TP
.B High resolution and scheduler stressor via nanosleep calls
.RS 5
.TQ
.B \-\-nanosleep N
start N workers that each run pthreads that call nanosleep(2) with random
delays from 1 to 2\[ua]18 nanoseconds. This should exercise the high resolution
timers and scheduler.
.TP
.B \-\-nanosleep\-method [ all | cstate | random | ns | us | ms ]
select the nanosleep sleep duration method.  By default, cstate residency durations
(if they exist) and random durations are used.  This option allows one to select one of the
three methods:
.sp
.TS
lB2 lB
l lx.
Method	Description
all	T{
use cstate and random nanosecond durations.
T}
cstate	T{
use cstate nanosecond durations. It is recommended to also use \-\-nanosleep\-threads 1
to exercise less conconcurrent nanosleeps to allow CPUs to drop into deep C states.
T}
random	T{
use random nanosecond durations between 1 and 2\[ua]18 nanoseconds.
T}
ns	T{
use 1ns (nanosecond) nanosleeps
T}
us	T{
use 1\(*ms (microsecond) nanosleeps
T}
ms	T{
use 1ms (millisecond) nanosleeps
T}
.TE
.TP
.B \-\-nanosleep\-ops N
stop the nanosleep stressor after N bogo nanosleep operations.
.TP
.B \-\-nanosleep\-threads N
specify the number of concurrent pthreads to run per stressor. The default is 8
and the allowed range is 1 to 1024.
.RE
.TP
.B Network device ioctl stressor
.RS 5
.TQ
.B \-\-netdev N
start N workers that exercise various netdevice ioctl(2) commands across
all the available network devices. The ioctls exercised by this stressor
are as follows: SIOCGIFCONF, SIOCGIFINDEX, SIOCGIFNAME, SIOCGIFFLAGS,
SIOCGIFADDR, SIOCGIFNETMASK, SIOCGIFMETRIC, SIOCGIFMTU, SIOCGIFHWADDR,
SIOCGIFMAP and SIOCGIFTXQLEN. See netdevice(7) for more details of these
ioctl commands.
.TP
.B \-\-netdev\-ops N
stop after N netdev bogo operations completed.
.RE
.TP
.B Netlink proc stressor (Linux)
.RS 5
.TQ
.B \-\-netlink\-proc N
start N workers that spawn child processes and monitor fork/exec/exit
process events via the proc netlink connector. Each event received is counted
as a bogo op. This stressor can only be run on Linux and requires
CAP_NET_ADMIN capability.
.TP
.B \-\-netlink\-proc\-ops N
stop the proc netlink connector stressors after N bogo ops.
.RE
.TP
.B Netlink task stressor (Linux)
.RS 5
.TQ
.B \-\-netlink\-task N
start N workers that collect task statistics via the netlink taskstats
interface.  This stressor can only be run on Linux and requires
CAP_NET_ADMIN capability.
.TP
.B \-\-netlink\-task\-ops N
stop the taskstats netlink connector stressors after N bogo ops.
.RE
.TP
.B Nice stressor
.RS 5
.TQ
.B \-\-nice N
start N cpu consuming workers that exercise the available nice levels. Each
iteration forks off a child process that runs through the all the nice levels
running a busy loop for 0.1 seconds per level and then exits.
.TP
.B \-\-nice\-ops N
stop after N nice bogo nice loops
.RE
.TP
.B NO-OP CPU instruction stressor
.RS 5
.TQ
.B \-\-nop N
start N workers that consume cpu cycles issuing no-op instructions. This
stressor is available if the assembler supports the "nop" instruction.
.TP
.B \-\-nop\-instr INSTR
use alternative nop instruction INSTR. For x86 CPUs INSTR can be one
of nop, pause, nop2 (2 byte nop) through to nop15 (15 byte nop) and
fnop. For ARM CPUs, INSTR can be one of nop or yield. For PPC64 CPUs,
INSTR can be one of nop, mdoio, mdoom or yield. For S390 CPUs, INSTR
can be one of nop or nopr. For other processors, INSTR
is only nop. The random INSTR option selects a random mix of the
available nop instructions. If the chosen INSTR generates an SIGILL
signal, then the stressor falls back to the vanilla nop instruction.
.TP
.B \-\-nop\-ops N
stop nop workers after N no-op bogo operations. Each bogo-operation is
equivalent to 256 loops of 256 no-op instructions.
.RE
.TP
.B /dev/null stressor
.RS 5
.TQ
.B \-\-null N
start N workers that exercise /dev/null with write(2), lseek(2), ioctl(2),
fcntl(2), fallocate(2) and fdatasync(2) calls. For just /dev/null write
benchmarking use the \-\-null\-write option.
.TP
.B \-\-null\-ops N
stop null stress workers after N /dev/null bogo operations.
.TP
.B \-\-null\-write
just write to /dev/null with 4 K writes with no additional exercising on /dev/null.
.RE
.TP
.B Migrate memory pages over NUMA nodes stressor
.RS 5
.TQ
.B \-\-numa N
start N workers that migrate stressors and a 4 MB memory mapped buffer around
all the available NUMA nodes.  This uses migrate_pages(2) to move the stressors
and mbind(2) and move_pages(2) to move the pages of the mapped buffer. After
each move, the buffer is written to force activity over the bus which results
cache misses.  This test will only run on hardware with NUMA enabled.

.TP
.B \-\-numa\-bytes N
specify the total number bytes to be exercised by all the workers, the given
size is divided by the number of workers and rounded to the nearest page
size. The default is 4 MB per worker. One can specify the size as % of total
available memory or in units of Bytes, KBytes, MBytes and GBytes using the
suffix b, k, m or g.
.TP
.B \-\-numa\-ops N
stop NUMA stress workers after N bogo NUMA operations.
.TP
.B \-\-numa\-shuffle\-addr
shuffle page order for the address list when calling move_pages(2)
.TP
.B \-\-numa\-shuffle\-node
shuffle node order for the address list when calling move_pages(2)
.RE
.TP
.B Large Pipe stressor
.RS 5
.TQ
.B \-\-oom\-pipe N
start N workers that create as many pipes as allowed and exercise expanding
and shrinking the pipes from the largest pipe size down to a page size. Data
is written into the pipes and read out again to fill the pipe buffers. With
the \-\-aggressive mode enabled the data is not read out when the pipes are
shrunk, causing the kernel to OOM processes aggressively.  Running many
instances of this stressor will force kernel to OOM processes due to the
many large pipe buffer allocations.
.TP
.B \-\-oom\-pipe\-ops N
stop after N bogo pipe expand/shrink operations.
.RE
.TP
.B Illegal instructions stressors
.RS 5
.TQ
.B \-\-opcode N
start N workers that fork off children that execute randomly generated
executable code.  This will generate issues such as illegal instructions,
bus errors, segmentation faults, traps, floating point errors that are
handled gracefully by the stressor.
.TP
.B \-\-opcode\-method [ inc | mixed | random | text ]
select the opcode generation method.  By default, random bytes are used to
generate the executable code. This option allows one to select one of the
three methods:
.sp
.TS
lB2 lB
l lx.
Method	Description
inc	T{
use incrementing 32 bit opcode patterns from 0x00000000 to 0xfffffff inclusive.
T}
mixed	T{
use a mix of incrementing 32 bit opcode patterns and random 32 bit opcode patterns that
are also inverted, encoded with gray encoding and bit reversed.
T}
random	T{
generate opcodes using random bytes from a mwc random generator.
T}
text	T{
copies random chunks of code from the stress\-ng text segment and randomly flips
single bits in a random choice of 1/8th of the code.
T}
.TE
.TP
.B \-\-opcode\-ops N
stop after N attempts to execute illegal code.
.RE
.TP
.B Opening file (open) stressor
.RS 5
.TQ
.B \-o N, \-\-open N
start N workers that perform open(2) and then close(2) operations on
/dev/zero. The maximum opens at one time is system defined, so the test will
run up to this maximum, or 65536 open file descriptors, which ever comes first.
.TP
.B \-\-open\-fd
run a child process that scans /proc/$PID/fd and attempts to open the files
that the stressor has opened. This exercises racing open/close operations
on the proc interface.
.TP
.B \-\-open\-max N
try to open a maximum of N files (or up to the maximum per-process open file system
limit). The value can be the number of files or a percentage of the
maximum per-process open file system limit.
.TP
.B \-\-open\-ops N
stop the open stress workers after N bogo open operations.
.RE
.TP
.B Page table and TLB stressor
.RS 5
.TQ
.B \-\-pagemove N
start N workers that mmap a memory region (default 4 MB) and then shuffle pages
to the virtual address of the previous page. Each page shuffle uses 3 mremap operations
to move a page. This exercises page tables and Translation Lookaside Buffer (TLB)
flushing.
.TP
.B \-\-pagemove\-bytes
specify the size of the memory mapped region to be exercised. One can
specify the size as % of total available memory or in units of Bytes, KBytes,
MBytes and GBytes using the suffix b, k, m or g.
.TP
.B \-\-pagemove\-mlock
attempt to mlock(2) mmap'd and mremap'd pages into memory causing more memory pressure by
preventing pages from swapped out.
.TP
.B \-\-pagemove\-numa
assign memory mapped pages to randomly selected NUMA nodes. This is disabled
for systems that do not support NUMA.
.TP
.B \-\-pagemove\-ops N
stop after N pagemove shuffling operations, where suffling all the pages in
the mmap'd region is equivalent to 1 bogo-operation.
.RE
.TP
.B Memory page swapping stressor
.RS 5
.TQ
.B \-\-pageswap N
start N workers that exercise page swap in and swap out. Pages are allocated
and paged out using madvise(2) MADV_PAGEOUT. One the maximum per process number
of mmaps are reached or 65536 pages are allocated the pages are read to
page them back in and unmapped in reverse mapping order.
.TP
.B \-\-pageswap\-ops N
stop after N page allocation bogo operations.
.RE
.TP
.B PCI sysfs stressor (Linux)
.RS 5
.TQ
.B \-\-pci N
exercise PCI sysfs by running N workers that read data (and mmap/unmap
PCI config or PCI resource files). Linux only. Running as root will allow
config and resource mmappings to be read and exercises PCI I/O mapping.
.TP
.B \-\-pci\-dev xxxx:xx:xx.x
specify a PCI device to exercise rather than exercise all PCI devices. The
device is specified using the PCI device name xxxx:xx:xx.x where x is a
hexadecimal digit.
.TP
.B \-\-pci\-ops N
stop pci stress workers after N PCI subdirectory exercising operations.
.TP
.B \-\-pci\-ops\-rate N
specify the PCI bogo-ops per second rate. This is useful for PCI bandwidth
limiting and on x86 systems this may reduce uncore transactions.
.RE
.TP
.B Personality stressor
.RS 5
.TQ
.B \-\-personality N
start N workers that attempt to set personality and get all the available
personality types (process execution domain types) via the personality(2)
system call. (Linux only).
.TP
.B \-\-personality\-ops N
stop personality stress workers after N bogo personality operations.
.RE
.TP
.B Mutex using Peterson algorithm stressor
.RS 5
.TQ
.B \-\-peterson N
start N workers that exercises mutex exclusion between two processes using
shared memory with the Peterson Algorithm. Where possible this uses memory fencing
and falls back to using GCC __sync_synchronize if they are not available. The
stressors contain simple mutex and memory coherency sanity checks.
.TP
.B \-\-peterson\-ops N
stop peterson workers after N mutex operations.
.RE
.TP
.B Page mmap stressor
.RS 5
.TQ
.B \-\-physpage N
start N workers that use /proc/self/pagemap and /proc/kpagecount to determine
the physical page and page count of a virtual mapped page and a page that is
shared among all the stressors. Linux only and requires the CAP_SYS_ADMIN
capabilities.
.TP
.B \-\-physpage\-mtrr
enable setting various memory type rage register (MTRR) types on physical
pages (Linux and x86 only).
.TP
.B \-\-physpage\-ops N
stop physpage stress workers after N bogo physical address lookups.
.RE
.TP
.B Physical page mmap stressor (using /dev/mem)
.RS 5
.TQ
.B \-\-physmmap N
start N workers that try to mmap available System RAM (as specified by /proc/iomem)
using /dev/mem and randomized private or shared pages. This requires CAP_SYS_ADMIN
capabilities to fully read /proc/iomem and mmap onto /dev/mem. Note systems may
be fully locked down and mmapping onto /dev/mem is impossible.
.TP
.B \-\-physmmap\-ops N
stop physmmap stress workers after N bogo mmap attempts.
.TP
.B \-\-physmmap\-read
perform 64 bit reads of all the data in each mmap'd page.
.RE
.TP
.B Process signals (pidfd_send_signal) stressor
.RS 5
.TQ
.B \-\-pidfd N
start N workers that exercise signal sending via the pidfd_send_signal(2) system call.
This stressor creates child processes and checks if they exist and can be
stopped, restarted and killed using the pidfd_send_signal(2) system call.
.TP
.B \-\-pidfd\-ops N
stop pidfd stress workers after N child processes have been created, tested
and killed with pidfd_send_signal.
.RE
.TP
.B Localhost ICMP (ping) stressor
.RS 5
.TQ
.B \-\-ping\-sock N
start N workers that send small randomized ICMP messages to the localhost
across a range of ports (1024..65535) using a "ping" socket with an AF_INET
domain, a SOCK_DGRAM socket type and an IPPROTO_ICMP protocol.
.TP
.B \-\-ping\-sock\-ops N
stop the ping\-sock stress workers after N ICMP messages are sent.
.RE
.TP
.B Large pipe stressor
.RS 5
.TQ
.B \-p N, \-\-pipe N
start N workers that perform large pipe writes and reads to exercise pipe I/O.
This exercises memory write and reads as well as context switching.  Each
worker has two processes, a reader and a writer.
.TP
.B \-\-pipe\-data\-size N
specifies the size in bytes of each write to the pipe (range from 4 bytes
to 4096 bytes). Setting a small data size will cause more writes to be
buffered in the pipe, hence reducing the context switch rate between the
pipe writer and pipe reader processes. Default size is the page size.
.TP
.B \-\-pipe\-ops N
stop pipe stress workers after N bogo pipe write operations.
.TP
.B \-\-pipe\-vmsplice
use vmsplice(2) to splice data pages to/from pipe. Requires pipe packet
mode using O_DIRECT and buffer twice the size of the pipe to ensure verification
data sequences.
.TP
.B \-\-pipe\-size N
specifies the size of the pipe in bytes (for systems that support the
F_SETPIPE_SZ fcntl() command). Setting a small pipe size will cause the pipe
to fill and block more frequently, hence increasing the context switch rate
between the pipe writer and the pipe reader processes. As of version 0.15.11 the
default size is 4096 bytes.
.RE
.TP
.B Shared pipe stressor
.RS 5
.TQ
.B \-\-pipeherd N
start N workers that pass a 64 bit token counter to/from 100 child processes
over a shared pipe. This forces a high context switch rate and can trigger
a "thundering herd" of wakeups on processes that are blocked on pipe waits.
.TP
.B \-\-pipeherd\-ops N
stop pipe stress workers after N bogo pipe write operations.
.TP
.B \-\-pipeherd\-yield
force a scheduling yield after each write, this increases the context
switch rate.
.RE
.TP
.B Memory protection key mechanism stressor (Linux)
.RS 5
.TQ
.B \-\-pkey N
start N workers that change memory protection using a protection key pkey(2) and
the pkey_mprotect(2) call (Linux only). This will try to allocate a pkey and
use this for the page protection, however, if this fails then the special
pkey -1 will be used (and the kernel will use the normal mprotect mechanism
instead).  Various page protection mixes of read/write/exec/none will
be cycled through on randomly chosen pre-allocated pages.
.TP
.B \-\-pkey\-ops N
stop after N pkey_mprotect page protection cycles.
.RE
.TP
.B Stress-ng plugin stressor
.RS 5
.TQ
.B \-\-plugin N
start N workers that run user provided stressor functions loaded from a shared
library. The shared library can contain one or more stressor functions prefixed
with stress_ in their name. By default the plugin stressor will find all functions
prefixed with stress_ in their name and exercise these one by one in a round\-robin
loop, but a specific stressor can be selected using the \-\-plugin\-method option.
The stressor function takes no parameters and returns 0 for success and non-zero
for failure (and will terminate the plugin stressor). Each time a stressor function
is executed the bogo-op counter is incremented by one. The following example
performs 10000 nop instructions per bogo-op:
.PP
.in +10n
.EX
int stress_example(void)
{
        int i;

        for (i = 0; i < 10000; i++) {
                __asm__ __volatile__("nop");
        }
        return 0;  /* Success */
}
.EE
.in
.RS
.PP
and compile the source into a shared library as, for example:
.RE
.PP
.in +10n
.EX
gcc \-fpic \-shared \-o example.so example.c
.EE
.in
.RS
.PP
and run as using:
.PP
.RE
.PP
.in +10n
.EX
stress\-ng \-\-plugin 1 \-\-plugin-so ./example.so
.EE
.in
.TP
.B \-\-plugin\-method function
run a specific stressor function, specify the name without the leading stress_ prefix.
.TP
.B \-\-plugin\-ops N
stop after N iterations of the user provided stressor function(s).
.TP
.B \-\-plugin\-so name
specify the shared library containing the user provided stressor function(s).
.RE
.TP
.B Polling stressor
.RS 5
.TQ
.B \-P N, \-\-poll N
start N workers that perform zero timeout polling via the poll(2), ppoll(2),
select(2), pselect(2) and sleep(3) calls. This wastes system and user time
doing nothing.
.TP
.B \-\-poll\-fds N
specify the number of file descriptors to poll/ppoll/select/pselect on.
The maximum number for select/pselect is limited by FD_SETSIZE and the
upper maximum is also limited by the maximum number of pipe open descriptors
allowed.
.TP
.B \-\-poll\-ops N
stop poll stress workers after N bogo poll operations.
.TP
.B \-\-poll\-random\-us N
use a random timeout of N microseconds for ppoll(2) and pselect(2) calls instead
of the default of 20000 microseconds.
.RE
.TP
.B Power maths functions
.RS 5
.TQ
.B \-\-powmath N
start N workers that exercise various libm power functions with input values 0
to 1 in steps of 0.001; the results are sanity checked to ensure no variation
occurs after each round of 10000 computations.
.TP
.B \-\-powmath\-ops N
stop after N power function bogo-operation loops.
.TP
.B \-\-powmath\-method method
specify a power function to exercise. Available power function stress methods are described
as follows:
.sp
.TS
lB2 lB
l lx.
Method	Description
all	T{
iterate over all the below power functions methods
T}
cpow	T{
complex double power function
T}
cpowf	T{
complex float power function
T}
cpowl	T{
complex long double power function
T}
csqrt	T{
complex double square root function (1/2 power)
T}
csqrtf	T{
complex float square root function (1/2 power)
T}
csqrtl	T{
complex long double square root function (1/2 power)
T}
cbrt	T{
double cube root function (1/3 power)
T}
cbrtf	T{
float cube root function (1/3 power)
T}
cbrtl	T{
long double cube root function (1/3 power)
T}
hypot	T{
double Euclidean distance function (hypotenuse)
T}
hypotf	T{
float Euclidean distance function (hypotenuse)
T}
hypotl	T{
long double Euclidean distance function (hypotenuse)
T}
pow	T{
double power function
T}
powf	T{
float power function
T}
powl	T{
long double power function
T}
sqrt	T{
double square root function (1/2 power)
T}
sqrtf	T{
float square root function (1/2 power)
T}
sqrtl	T{
long double square root function (1/2 power)
T}
.TE
.RE
.TP
.B Prctl stressor
.RS 5
.TQ
.B \-\-prctl N
start N workers that exercise the majority of the prctl(2) system call
options. Each batch of prctl calls is performed inside a new child process
to ensure the limit of prctl is contained inside a new process every time.
Some prctl options are architecture specific, however, this stressor will
exercise these even if they are not implemented.
.TP
.B \-\-prctl\-ops N
stop prctl workers after N batches of prctl calls
.RE
.TP
.B L3 cache prefetching stressor
.RS 5
.TQ
.B \-\-prefetch N
start N workers that benchmark prefetch and non-prefetch reads of a L3
cache sized buffer. The buffer is read with loops of 8 \(mu 64 bit reads
per iteration. In the prefetch cases, data is prefetched ahead of the
current read position by various sized offsets, from 64 bytes to 8 K
to find the best memory read throughput. The stressor reports the
non-prefetch read rate and the best prefetched read rate. It also reports
the prefetch offset and an estimate of the amount of time between the
prefetch issue and the actual memory read operation. These statistics
will vary from run-to-run due to system noise and CPU frequency scaling.
.TP
.B \-\-prefetch\-l3\-size N
specify the size of the l3 cache
.TP
.B \-\-prefetch\-method N
select the prefetching method. Available methods are:
.sp
.TS
lB2 lB
l lx.
Method	Description
builtin	T{
Use the __builtin_prefetch(3) function for prefetching. This is the default.
T}
builtinl0	T{
Use the __builtin_prefetch(3) function for prefetching, with a locality 0 hint.
T}
builtinl3	T{
Use the __builtin_prefetch(3) function for prefetching, with a locality 3 hint.
T}
dcbt	T{
Use the ppc64 dcbt instruction to fetch data into the L1 cache (ppc64 only).
T}
dcbtst	T{
Use the ppc64 dcbtst instruction to fetch data into the L1 cache (ppc64 only).
T}
prefetcht0	T{
Use the x86 prefetcht0 instruction to prefetch data into all levels of the
cache hierarchy (x86 only).
T}
prefetcht1	T{
Use the x86 prefetcht1 instruction (temporal data with respect to first level
cache) to prefetch data into level 2 cache and higher (x86 only).
T}
prefetcht2	T{
Use the x86 prefetcht2 instruction (temporal data with respect to second level
cache) to prefetch data into level 2 cache and higher (x86 only).
T}
prefetchnta	T{
Use the x86 prefetchnta instruction (non-temporal data with respect to all
cache levels) into a location close to the processor, minimizing cache
pollution (x86 only).
T}
prfm_pldl1keep	T{
Use the aarch64 prfm instruction with pld1keep operation (retained or temporal
prefetch, allocated in the cache normally) to prefetch data into level 1 of the
cache hierarchy (aarch64 only).
T}
prfm_pldl2keep	T{
Use the aarch64 prfm instruction with pld1keep operation (retained or temporal
prefetch, allocated in the cache normally) to prefetch data into level 2 of the
cache hierarchy (aarch64 only).
T}
prfm_pldl3keep	T{
Use the aarch64 prfm instruction with pld1keep operation (retained or temporal
prefetch, allocated in the cache normally) to prefetch data into level 3 of the
cache hierarchy (aarch64 only).
T}
prfm_pldl1strm	T{
Use the aarch64 prfm instruction with pld1strm operation (streaming or
non-temporal prefetch, for data that is used only once) to prefetch data into
level 1 of the cache hierarchy (aarch64 only).
T}
prfm_pldl2strm	T{
Use the aarch64 prfm instruction with pld1strm operation (streaming or
non-temporal prefetch, for data that is used only once) to prefetch data into
level 2 of the cache hierarchy (aarch64 only).
T}
prfm_pldl3strm	T{
Use the aarch64 prfm instruction with pld1strm operation (streaming or
non-temporal prefetch, for data that is used only once) to prefetch data into
level 3 of the cache hierarchy (aarch64 only).
T}
.TE
.TP
.B \-\-prefetch\-ops N
stop prefetch stressors after N benchmark operations
.RE
.TP
.B Search for prime numbers using large integers
.RS 5
.TQ
.B \-\-prime N
start N workers that find prime numbers using the GNU Multiple Precision
Arithmetic Library for large integers. The GMP mpz_nextprime function is
used to find primes and it uses a probabilistic algorithm to identify
primes, but there is a extremely small chance that the values found are
non-prime. The search becomes computationally more expensive over time
to find larger and larger primes, hence the bogo-op rate will reduce over
time.
.TP
.B \-\-prime\-method [ factorial | inc | pwr2 | pwr10 ]
selects the method of calculating the next value from where to start searching
primes and hence how large the primes get. The default is inc, the methods to
start searching for primes are described as follows.
.sp
.TS
lB2 lB
l lx.
Method	Description
factorial	T{
start of search based on factorial expansion. This grows rapidly.
T}
inc	T{
start of search based on increments by 2. This grows very slowly.
T}
pwr2	T{
start of search based on powers of 2. Grows relatively quickly.
T}
pwr10	T{
start of search based on powers of 10. Grows by 1 digit per iteration and
grows quickly.
T}
.TE
.TP
.B \-\-prime\-ops N
stop after finding N prime numbers.
.TP
.B \-\-prime\-progress
show the number of primes found and length of largest prime found. This is displayed
either every 60 seconds or more than 60 seconds if it takes longer to find
the next prime.
.TP
.B \-\-prime\-start N
start the prime search from value N. The value may be expressed as an integer value
or as a floating point value (e.g. 1e200 to express a very large starting value).
.RE
.TP
.B Priority inversion stressor
.RS 5
.TQ
.B \-\-prio\-inv N
start N workers that exercise mutex lock priority inversion scheduling.
Three child process run with low, medium and high FIFO scheduling priorities.
The processes with low and high priorities share a mutex lock that both
try to lock and unlock, aiming to make the low priority process block the
high priority process. Meanwhile the middle priority process will run
in priority over the low priority process, causing the high priority
process to become unrunnable.
.TP
.B \-\-prio\-inv\-ops N
stop after N bogo lock/unlock operations.
.TP
.B \-\-prio\-inv\-type [ inherit | none | protect ]
select the mutex lock priority inversion type, described as follows:
.sp
.TS
lB2 lB
l lx.
Type	Description
inherit	T{
The priority of the process owning the mutex lock is run with highest
priority of any other process waiting on the lock to avoid priority
inversion deadlock.
T}
none	T{
The priority of the process owning the mutex lock is
not affected by its mutex ownership. This may lead to the high priority
process to become unrunnable on a single thread system.
T}
protect	T{
The priority of the process owning the mutex lock is given the
priority of the mutex (in this stress test case, the maximum priority)
during the lock ownership.
T}
.TE
.TP
.B \-\-prio\-inv\-policy [ batch | ext | idle | fifo | other | rr ]
select the scheduling policy. "Normal" policies (batch, ext, idle and other)
can be selected as an unprivileged user, however "Real Time" policies
(fifo and rr) can only be selected with the appropriate privilege.
By default "fifo" is selected but it will fall back to "other" for
unprivileged users.
.RE
.TP
.B Privileged CPU instructions stressor
.RS 5
.TQ
.B \-\-priv\-instr N
start N workers that exercise various architecture specific privileged
instructions that cannot be executed by userspace programs. These
instructions will be trapped and processed by SIGSEGV or SIGILL signal
handlers.
.TP
.B \-\-priv\-instr\-ops N
stop priv\-instr stressors after N rounds of executing privileged instructions.
.RE
.TP
.B /proc stressor
.RS 5
.TQ
.B \-\-procfs N
start N workers that read files from /proc and recursively read files from
/proc/self (Linux only).
.TP
.B \-\-procfs\-ops N
stop procfs reading after N bogo read operations. Note, since the number of
entries may vary between kernels, this bogo ops metric is probably very
misleading.
.RE
.TP
.B pwrite/pread lseek I/O stressor
.RS 5
.TQ
.B \-\-pseek N
start N workers that exercise pwrite(2) and pread(2) with lseek(2) positioning tests.
Each worker has 4 sub-processes that perform repeated pwrite and pread
operations using the same shared file descriptor. Two of the processes
are started using pthreads (if available), another two processes are started
with fork(2). Using pwrite and pread should perform I/O without
altering the shared file descriptor file offset. The main worker process
performs I/O using lseek(2)/write(2) and lseek(2)/read(2) calls that change the
file offset; lseeks are sanity checked to see if they are being altered by pwrite
and pread calls.
.TP
.B \-\-pseek\-io\-size N
specify size of each write/read I/O operation in bytes. Size can be from 1 byte to 1 MB.
.TP
.B \-\-pseek\-ops N
stop after N writes by the main worker process.
.TP
.B \-\-pseek\-rand
normally each sub-process writes to a fix file offset, using this option
will randomize the offset on each write/read cycle.
.RE
.TP
.B Pthread stressor
.RS 5
.TQ
.B \-\-pthread N
start N workers that iteratively creates and terminates multiple pthreads
(the default is 1024 pthreads per worker). In each iteration, each newly
created pthread waits until the worker has created all the pthreads and then
they all terminate together.
.TP
.B \-\-pthread\-max N
create N pthreads per worker. If the product of the number of pthreads by the
number of workers is greater than the soft limit of allowed pthreads then the
maximum is re-adjusted down to the maximum allowed.
.TP
.B \-\-pthread\-ops N
stop pthread workers after N bogo pthread create operations.
.RE
.TP
.B Ptrace stressor
.RS 5
.TQ
.B \-\-ptrace N
start N workers that fork and trace system calls of a child process using
ptrace(2).
.TP
.B \-\-ptrace\-ops N
stop ptracer workers after N bogo system calls are traced.
.RE
.TP
.B Pointer Chasing stressor
.RS 5
.TQ
.B \-\-ptr\-chase N
start N workers that chase memory pointers around page sized nodes of pointers.
By default each stressor instance allocates 4096 pages of nodes, each node
is an array of pointers that are randomly set to point to other node pages.
The stressors follow randomly chosen pointers from each node, chasing around
the entire node space. This exercises pointer fetching, pointer dereferencing
and is a cache-read exercising stressor. The nodes are allocated with 50%
of pages from the heap and 50% from mmap'd memory.
.TP
.B \-\-ptr\-chase\-ops N
stop after N pointer chases
.TP
.B \-\-ptr\-chase\-pages N
select number of pages to allocate for the nodes.
.RE
.TP
.B Pseudo-terminals (pty) stressor
.RS 5
.TQ
.B \-\-pty N
start N workers that repeatedly attempt to open pseudoterminals and
perform various pty ioctl(2) calls upon the ptys before closing them.
.TP
.B \-\-pty\-max N
try to open a maximum of N pseudoterminals, the default is 65536. The allowed
range of this setting is 8..65536.
.TP
.B \-\-pty\-ops N
stop pty workers after N pty bogo operations.
.RE
.TP
.B Qsort stressor
.RS 5
.TQ
.B \-Q, \-\-qsort N
start N workers that sort 32 bit integers using qsort(3).
.TP
.B \-\-qsort\-method [ qsort\-libc | qsort\-bm ]
select either the libc implementation of qsort or the J. L. Bentley and M. D. McIlroy
implementation of qsort. The default is the libc implementation.
.TP
.B \-\-qsort\-ops N
stop qsort stress workers after N bogo qsorts.
.TP
.B \-\-qsort\-size N
specify number of 32 bit integers to sort, default is 262144 (256 \(mu 1024).
.RE
.TP
.B Quota stressor
.RS 5
.TQ
.B \-\-quota N
start N workers that exercise the Q_GETQUOTA, Q_GETFMT, Q_GETINFO, Q_GETSTATS
and Q_SYNC quotactl(2) commands on all the available mounted block based file
systems. Requires CAP_SYS_ADMIN capability to run.
.TP
.B \-\-\quota\-ops N
stop quota stress workers after N bogo quotactl operations.
.RE
.TP
.B Process scheduler stressor
.RS 5
.TQ
.B \-\-race\-sched N
start N workers that exercise rapid changing CPU affinity child processes
both from the controlling stressor and by the child processes. Child
processes are created and terminated rapidly with the aim to create
race conditions where affinity changing occurs during process run states.
.TP
.B \-\-race\-sched\-method [ all | next | prev | rand | randinc | syncnext | syncprev ]
Select the method moving a process to a specific CPU.  Available methods are
described as follows:
.sp
.TS
lB2 lB
l lx.
Method	Description
all	T{
iterate over all the race\-sched methods as listed below:
T}
next	T{
move a process to the next CPU, wrap around to zero when maximum CPU
is reached.
T}
prev	T{
move a process to the previous CPU, wrap around to the maximum CPU when
the first CPU is reached.
T}
rand	T{
move a process to any randomly chosen CPU.
T}
randinc	T{
move a process to the current CPU \(pl a randomly chosen value 1..4, modulo
the number of CPUs.
T}
syncnext	T{
move synchronously all the race-sched stressor processes to the next CPU
every second; this loads just 1 CPU at a time in a round\-robin method.
T}
syncprev	T{
move synchronously all the race-sched stressor processes to the previous CPU
every second; this loads just 1 CPU at a time in a round\-robin method.
T}
.TE
.TP
.B \-\-race\-sched\-ops N
stop after N process creation bogo-operations.
.RE
.TP
.B Radixsort stressor
.RS 5
.TQ
.B \-\-radixsort N
start N workers that sort random 8 byte strings using radixsort(3)
.TP
.B \-\-radixsort\-method [ radixsort\-libc | radixsort\-nonlibc ]
select either the libc implementation of radixsort or an optimized
implementation of radixsort. The default is the libc implementation if it
is available.
.TP
.B \-\-radixsort\-ops N
stop radixsort stress workers after N bogo radixsorts.
.TP
.B \-\-radixsort\-size N
specify number of strings to sort, default is 262144 (256 \(mu 1024).
.RE
.TP
.B Memory filesystem stressor
.RS 5
.TQ
.B \-\-ramfs N
start N workers mounting a memory based file system using ramfs and
tmpfs (Linux only). This alternates between mounting and umounting a
ramfs or tmpfs file system using the traditional mount(2) and
umount(2) system call as well as the newer Linux 5.2 fsopen(2),
fsmount(2), fsconfig(2) and move_mount(2) system calls if they
are available. The default ram file system size is 2 MB.
.TP
.B \-\-ramfs\-fill
fill ramfs with zero'd data using fallocate(2) if it is available or
multiple calls to write(2) if not.
.TP
.B \-\-ramfs\-ops N
stop after N ramfs mount operations.
.TP
.B \-\-ramfs\-size N
set the ramfs size (must be multiples of the page size).
.RE
.TP
.B Raw device stressor
.RS 5
.TQ
.B \-\-rawdev N
start N workers that read the underlying raw drive device using direct
IO reads. The device (with minor number 0) that stores the current working
directory is the raw device to be read by the stressor.  The read size is
exactly the size of the underlying device block size.  By default, this
stressor will exercise all the of the rawdev methods (see the
\-\-rawdev\-method option). This is a Linux only stressor and requires
root privilege to be able to read the raw device.
.TP
.B \-\-rawdev\-method method
Available rawdev stress methods are described as follows:
.sp
.TS
lB2 lB
l lx.
Method	Description
all	T{
iterate over all the rawdev stress methods as listed below:
T}
sweep	T{
repeatedly read across the raw device from the 0th block to the end block in steps
of the number of blocks on the device / 128 and back to the start again.
T}
wiggle	T{
repeatedly read across the raw device in 128 evenly steps with each step reading
1024 blocks backwards from each step.
T}
ends	T{
repeatedly read the first and last 128 start and end blocks of the raw device
alternating from start of the device to the end of the device.
T}
random	T{
repeatedly read 256 random blocks
T}
burst	T{
repeatedly read 256 sequential blocks starting from a random block on the raw device.
T}
.TE
.TP
.B \-\-rawdev\-ops N
stop the rawdev stress workers after N raw device read bogo operations.
.RE
.TP
.B Random list stressor
.RS 5
.TQ
.B \-\-randlist N
start N workers that creates a list of objects in randomized memory order and traverses
the list setting and reading the objects. This is designed to exerise memory and cache
thrashing. Normally the objects are allocated on the heap, however for objects of page
size or larger there is a 1 in 16 chance of objects being allocated using shared
anonymous memory mapping to mix up the address spaces of the allocations to create more
TLB thrashing.
.TP
.B \-\-randist\-compact
Allocate all the list objects using one large heap allocation and divide this up
for all the list objects. This removes the overhead of the heap keeping track of
each list object, hence uses less memory.
.TP
.B \-\-randlist\-items N
Allocate N items on the list. By default, 100000 items are allocated.
.TP
.B \-\-randlist\-ops N
stop randlist workers after N list traversals
.TP
.B \-\-randlist\-size N
Allocate each item to be N bytes in size. By default, the size is 64 bytes of
data payload plus the list handling pointer overhead.
.RE
.TP
.B Localhost raw socket stressor
.RS 5
.TQ
.B \-\-rawsock N
start N workers that send and receive packet data using raw sockets on the
localhost. Requires CAP_NET_RAW to run.
.TP
.B \-\-rawsock\-ops N
stop rawsock workers after N packets are received.
.TP
.B \-\-rawsock\-port P
start at socket port P. For N rawsock worker processes, ports P to P \(mi 1 are
used.
.RE
.TP
.B Localhost ethernet raw packets stressor
.RS 5
.TQ
.B \-\-rawpkt N
start N workers that sends and receives ethernet packets
using raw packets on the localhost via the loopback device. Requires
CAP_NET_RAW to run.
.TP
.B \-\-rawpkt\-ops N
stop rawpkt workers after N packets from the sender process are received.
.TP
.B \-\-rawpkt\-port N
start at port P. For N rawpkt worker processes, ports P to (P \(mu 4) \(mi 1
are used. The default starting port is port 14000.
.TP
.B \-\-rawpkt\-rxring N
setup raw packets with RX ring with N number of blocks, this selects TPACKET_V. N must
be one of 1, 2, 4, 8 or 16.
.RE
.TP
.B Localhost raw UDP packet stressor
.RS 5
.TQ
.B \-\-rawudp N
start N workers that send and receive UDP packets using raw sockets on the
localhost. Requires CAP_NET_RAW to run.
.TP
.B \-\-rawudp\-if NAME
use network interface NAME. If the interface NAME does not exist, is not
up or does not support the domain then the loopback (lo) interface is used as the default.
.TP
.B \-\-rawudp\-ops N
stop rawudp workers after N packets are received.
.TP
.B \-\-rawudp\-port N
start at port P. For N rawudp worker processes, ports P to (P \(mu 4) - 1
are used. The default starting port is port 13000.
.RE
.TP
.B Random number generator stressor
.RS 5
.TQ
.B \-\-rdrand N
start N workers that read a random number from an on-chip random number generator
This uses the rdrand instruction on Intel x86 processors or the darn instruction
on PowerPC processors.
.TP
.B \-\-rdrand\-ops N
stop rdrand stress workers after N bogo rdrand operations (1 bogo op \(eq 2048
random bits successfully read).
.TP
.B \-\-rdrand\-seed
use rdseed instead of rdrand (x86 only).
.RE
.TP
.B Read-ahead stressor
.RS 5
.TQ
.B \-\-readahead N
start N workers that randomly seek and perform 4096 byte read/write I/O
operations on a file with readahead(2). The default file size is 64 MB.  Readaheads
and reads are batched into 16 readaheads and then 16 reads.
.TP
.B \-\-readahead\-bytes N
set the size of readahead file, the default is 1 GB. One can specify the size
as % of free space on the file system or in units of Bytes, KBytes, MBytes and
GBytes using the suffix b, k, m or g.
.TP
.B \-\-readahead\-ops N
stop readahead stress workers after N bogo read operations.
.RE
.TP
.B Reboot stressor
.RS 5
.TQ
.B \-\-reboot N
start N workers that exercise the reboot(2) system call. When possible, it
will create a process in a PID namespace and perform a reboot power off command
that should shutdown the process.  Also, the stressor exercises invalid
reboot magic values and invalid reboots when there are insufficient privileges
that will not actually reboot the system.
.TP
.B \-\-reboot\-ops N
stop the reboot stress workers after N bogo reboot cycles.
.RE
.TP
.B POSIX regular expressions stressor
.RS 5
.TQ
.B \-\-regex N
start N workers that compile various POSIX regular expressions and execute
them against a set of text strings. This exercises the regex C library
with a range of various simple and complex regex expressions.
.TP
.B \-\-regex\-ops N
stop after N regex compilations.
.RE
.TP
.B CPU registers stressor
.RS 5
.TQ
.B \-\-regs N
start N workers that shuffle data around the CPU registers exercising register
move instructions.  Each bogo-op represents 1000 calls of a shuffling function
that shuffles the registers 32 times. Only implemented for the GCC compiler
since this requires register annotations and optimization level 0 to compile
appropriately.
.TP
.B \-\-regs\-ops N
stop regs stressors after N bogo operations.
.RE
.TP
.B Memory page reordering stressor
.RS 5
.TQ
.B \-\-remap N
start N workers that map 512 pages and re-order these pages using the
deprecated system call remap_file_pages(2). Several page re-orderings are
exercised: forward, reverse, random and many pages to 1 page.
.TP
.B \-\-remap\-mlock
attempt to mlock(2) mmap'd huge pages into memory causing more memory pressure by
preventing pages from swapped out.
.TP
.B \-\-remap\-ops N
stop after N remapping bogo operations.
.TP
.B \-\-remap\-pages N
specify number of pages to remap, must be a power of 2, default is 512 pages.
.RE
.TP
.B Renaming file stressor
.RS 5
.TQ
.B \-R N, \-\-rename N
start N workers that each create a file and then repeatedly rename it.
.TP
.B \-\-rename\-ops N
stop rename stress workers after N bogo rename operations.
.RE
.TP
.B Process rescheduling stressor
.RS 5
.TQ
.B \-\-resched N
start N workers that exercise process rescheduling. Each stressor spawns
a child process for each of the positive nice levels and iterates over the
nice levels from 0 to the lowest priority level (highest nice value). For
each of the nice levels 1024 iterations over 3 non-real time scheduling
polices SCHED_OTHER, SCHED_BATCH and SCHED_IDLE are set and a sched_yield(2)
occurs to force heavy rescheduling activity.  When the -v verbose option
is used the distribution of the number of yields across the nice levels is
printed for the first stressor out of the N stressors.
.TP
.B \-\-resched\-ops N
stop after N rescheduling sched_yield calls.
.RE
.TP
.B System resources stressor
.RS 5
.TQ
.B \-\-resources N
start N workers that consume various system resources. Each worker will spawn
1024 child processes that iterate 1024 times consuming shared memory, heap,
stack, temporary files and various file descriptors (eventfds, memoryfds,
userfaultfds, pipes and sockets).
.TP
.B \-\-resources\-mlock
attempt to mlock(2) mmap'd pages into memory causing more memory pressure by
preventing pages from swapped out.
.TP
.B \-\-resources\-ops N
stop after N resource child forks.
.RE
.TP
.B Writing temporary files in reverse position stressor
.RS 5
.TQ
.B \-\-revio N
start N workers continually writing in reverse position order to temporary
files. The default mode is to stress test reverse position ordered writes
with randomly sized sparse holes between each write.  With
the \-\-aggressive option enabled without any \-\-revio\-opts options the
revio stressor will work through all the \-\-revio\-opt options one by one to
cover a range of I/O options.
.TP
.B \-\-revio\-bytes N
write N bytes for each revio process, the default is 1 GB. One can specify the
size as % of free space on the file system or in units of Bytes, KBytes, MBytes
and GBytes using the suffix b, k, m or g.
.TP
.B \-\-revio\-opts list
specify various stress test options as a comma separated list. Options are the
same as \-\-hdd\-opts but without the iovec option and with a readahead option
to force a readahead action over the entire file once it has been completely
written.
.TP
.B \-\-revio\-ops N
stop revio stress workers after N bogo operations.
.TP
.B \-\-revio\-write\-size N
specify size of each write in bytes. Size can be from 1 byte to 4 MB.
.RE
.TP
.B Ring pipes stressor
.RS 5
.TQ
.B \-\-ring\-pipe N
start N workers that move data around a ring of pipes using poll to detect
when data is ready to copy. By default, 256 pipes are used with two
4096 byte items of data being copied around the ring of pipes. Data is
copied using read and write system calls. If the splice system call is
available then one can use splice to use more efficient in-kernel data
passing instead of buffer copying.
.TP
.B \-\-ring\-pipe\-num N
specify the number of pipes to use. Ranges from 4 to 262144, default is 256.
.TP
.B \-\-ring\-pipe\-ops N
stop after N pipe data transfers.
.TP
.B \-\-ring\-pipe\-size N
specify the size of data being copied in bytes. Ranges from 1 to 4096, default
is 4096.
.TP
.B \-\-ring\-pipe\-splice
enable splice to move data between pipes (only if splice() is available).
.RE
.TP
.B Rlimit stressor
.RS 5
.TQ
.B \-\-rlimit N
start N workers that exceed CPU and file size resource imits, generating
SIGXCPU and SIGXFSZ signals.
.TP
.B \-\-rlimit\-ops N
stop after N bogo resource limited SIGXCPU and SIGXFSZ signals have been caught.
.RE
.TP
.B VM reverse-mapping stressor
.RS 5
.TQ
.B \-\-rmap N
start N workers that exercise the VM reverse-mapping. This creates 16 processes
per worker that write/read multiple file-backed memory mappings. There are 64
lots of 4 page mappings made onto the file, with each mapping overlapping the
previous by 3 pages and at least 1 page of non-mapped memory between each
of the mappings. Data is synchronously msync'd to the file 1 in every
256 iterations in a random manner.
.TP
.B \-\-rmap\-ops N
stop after N bogo rmap memory writes/reads.
.RE
.TP
.B 1 bit rotation stressor
.RS 5
.TQ
.B \-\-rotate N
start N workers that exercise 1 bit rotates left and right of unsigned integer
variables.  The default will rotate four 8, 16, 32, 64 (and if supported 128) bit
values 10000 times in a loop per bogo-op.
.TP
.B \-\-rotate\-method method
specify the method of rotation to use. The `all' method uses all the methods
and is the default.
.sp
.TS
lB2 lB
l lx.
Method	Description
all	exercise with all the rotate stressor methods (see below):
rol8	8 bit unsigned rotate left by 1 bit
ror8	8 bit unsigned rotate right by 1 bit
rol16	16 bit unsigned rotate left by 1 bit
ror16	16 bit unsigned rotate right by 1 bit
rol32	32 bit unsigned rotate left by 1 bit
ror32	32 bit unsigned rotate right by 1 bit
rol64	64 bit unsigned rotate left by 1 bit
ror64	64 bit unsigned rotate right by 1 bit
rol128	128 bit unsigned rotate left by 1 bit
ror128	128 bit unsigned rotate right by 1 bit
.TE
.TP
.B \-\-rotate\-ops N
stop after N bogo rotate operations.
.RE
.TP
.B Restartable sequences (rseq) stressor (Linux)
.RS 5
.TQ
.B \-\-rseq N
start N workers that exercise restartable sequences via the rseq(2) system
call.  This loops over a long duration critical section that is likely to
be interrupted.  A rseq abort handler keeps count of the number of
interruptions and a SIGSEGV handler also tracks any failed rseq aborts that
can occur if there is a mismatch in a rseq check signature. Linux only.
.TP
.B \-\-rseq\-ops N
stop after N bogo rseq operations. Each bogo rseq operation is equivalent
to 10000 iterations over a long duration rseq handled critical section.
.RE
.TP
.B Real-time clock stressor
.RS 5
.TQ
.B \-\-rtc N
start N workers that exercise the real time clock (RTC) interfaces via /dev/rtc
and /sys/class/rtc/rtc0. No destructive writes (modifications) are performed on
the RTC. This is a Linux only stressor.
.TP
.B \-\-rtc\-ops N
stop after N bogo RTC interface accesses.
.RE
.TP
.B Fast process rescheduling stressor
.RS 5
.TQ
.B \-\-schedmix N
start N workers that each start child processes that repeatedly select random
a scheduling policy and then executes a short duration randomly chosen time
consuming activity. This exercises rapid re-scheduling of processes and
generates a large amount of scheduling timer interrupts.
.TP
.B \-\-schedmix\-ops N
stop after N scheduling mixed operations.
.TP
.B \-\-schedmix\-procs N
specify the number of chid processes to run for each stressor instance, range
from 1 to 64, default is 16.
.RE
.TP
.B Scheduling policy stressor
.RS 5
.TQ
.B \-\-schedpolicy N
start N workers that set the worker to various available scheduling
policies out of SCHED_OTHER, SCHED_BATCH, SCHED_IDLE, SCHED_FIFO,
SCHED_RR, SCHED_DEADLINE and SCHED_EXT. For the real time scheduling
policies a random sched priority is selected between the minimum and
maximum scheduling priority settings.
.TP
.B \-\-schedpolicy\-ops N
stop after N bogo scheduling policy changes.
.TP
.B \-\-schedpolicy\-rand
Select scheduling policy randomly so that the new policy is always different
to the previous policy. The default is to work through the scheduling policies
sequentially.
.RE
.TP
.B Stream control transmission protocol (SCTP) stressor
.RS 5
.TQ
.B \-\-sctp N
start N workers that perform network sctp stress activity using the Stream
Control Transmission Protocol (SCTP).  This involves client/server processes
performing rapid connect, send/receives and disconnects on the local host.
.TP
.B \-\-sctp\-domain D
specify the domain to use, the default is ipv4. Currently ipv4 and ipv6
are supported.
.TP
.B \-\-sctp\-if NAME
use network interface NAME. If the interface NAME does not exist, is not
up or does not support the domain then the loopback (lo) interface is used as the default.
.TP
.B \-\-sctp\-ops N
stop sctp workers after N bogo operations.
.TP
.B \-\-sctp\-port P
start at sctp port P. For N sctp worker processes, ports P to (P \(mu 4) \(mi 1
are used for ipv4, ipv6 domains and ports P to P \(mi 1 are used for the unix
domain.
.TP
.B \-\-sctp\-sched [ fc | fcfs | prio | rr | wfq ]
specify SCTP scheduler, one of fc (fair capacity), fcfs (first come first
served, the default), prio (priority), rr (round\-robin) or wfq (weighted fair
queueing)
.RE
.TP
.B File sealing (SEAL) stressor (Linux)
.RS 5
.TQ
.B \-\-seal N
start N workers that exercise the fcntl(2) SEAL commands on a small anonymous
file created using memfd_create(2).  After each SEAL command is issued the
stressor also sanity checks if the seal operation has sealed the file correctly.
(Linux only).
.TP
.B \-\-seal\-ops N
stop after N bogo seal operations.
.RE
.TP
.B Secure computing stressor
.RS 5
.TQ
.B \-\-seccomp N
start N workers that exercise Secure Computing system call filtering. Each
worker creates child processes that write a short message to /dev/null and then
exits. 2% of the child processes have a seccomp filter that disallows
the write system call and hence it is killed by seccomp with a SIGSYS.  Note
that this stressor can generate many audit log messages each time the child is
killed.  Requires CAP_SYS_ADMIN to run.
.TP
.B \-\-seccomp\-ops N
stop seccomp stress workers after N seccomp filter tests.
.RE
.TP
.B Secret memory stressor (Linux \(>= 5.11)
.RS 5
.TQ
.B \-\-secretmem N
start N workers that mmap pages using file mapping off a memfd_secret(2) file
descriptor. Each stress loop iteration will expand the mappable region by 3
pages using ftruncate and mmap and touches the pages. The pages are then
fragmented by unmapping the middle page and then umapping the first and
last pages. This tries to force page fragmentation and also trigger out of
memory (OOM) kills of the stressor when the secret memory is exhausted.
Note this is a Linux 5.11+ only stressor and the kernel needs to be booted
with "secretmem=" option to allocate a secret memory reservation.
.TP
.B \-\-secretmem\-ops N
stop secretmem stress workers after N stress loop iterations.
.RE
.TP
.B IO seek stressor
.RS 5
.TQ
.B \-\-seek N
start N workers that randomly seeks and performs 512 byte read/write I/O
operations on a file. The default file size is 16 GB.
.TP
.B \-\-seek\-ops N
stop seek stress workers after N bogo seek operations.
.TP
.B \-\-seek\-punch
punch randomly located 8 K holes into the file to cause more extents to force
a more demanding seek stressor, (Linux only).
.TP
.B \-\-seek\-size N
specify the size of the file in bytes. Small file sizes allow the I/O to occur
in the cache, causing greater CPU load. Large file sizes force more I/O
operations to drive causing more wait time and more I/O on the drive. One can
specify the size in units of Bytes, KBytes, MBytes and GBytes using the suffix
b, k, m or g.
.RE
.TP
.B POSIX semaphore stressor
.RS 5
.TQ
.B \-\-sem N
start N workers that perform POSIX semaphore wait and post operations. By
default, a parent and 4 children are started per worker to provide some
contention on the semaphore. This stresses fast semaphore operations and
produces rapid context switching.
.TP
.B \-\-sem\-ops N
stop semaphore stress workers after N bogo semaphore operations.
.TP
.B \-\-sem\-procs N
start N child workers per worker to provide contention on the semaphore, the
default is 4 and a maximum of 64 are allowed.
.TP
.B \-\-sem\-shared
share the semaphore across all sem stressor instances. Normally each semaphore
stressor shares a semaphore with its child processes, this option produces
more locking contention and less throughput by sharing a semaphore across
all semaphore stressor processes.
.RE
.TP
.B System V semaphore stressor
.RS 5
.TQ
.B \-\-sem\-sysv N
start N workers that perform System V semaphore wait and post operations. By
default, a parent and 4 children are started per worker to provide some
contention on the semaphore. This stresses fast semaphore operations and
produces rapid context switching.
.TP
.B \-\-sem\-sysv\-ops N
stop semaphore stress workers after N bogo System V semaphore operations.
.TP
.B \-\-sem\-sysv\-procs N
start N child processes per worker to provide contention on the System V
semaphore, the default is 4 and a maximum of 64 are allowed.
.TP
.B \-\-sem\-sysv\-setall
sets the semval values for all the semaphores in the child's semaphore set.
This depends on the semctl SETALL op being defined and GETALL succeeding
and is an opt-in option as it will affect the semaphore being exercised.
.RE
.TP
.B Sendfile stressor
.RS 5
.TQ
.B \-\-sendfile N
start N workers that send an empty file to /dev/null using the sendfile(2)
call. This operation spends nearly all the time in the kernel.  The default
sendfile size is 4 MB.  The sendfile options are for Linux only.
.TP
.B \-\-sendfile\-ops N
stop sendfile workers after N sendfile bogo operations.
.TP
.B \-\-sendfile\-size S
specify the size to be copied with each sendfile call. The default size is
4 MB. One can specify the size in units of Bytes, KBytes, MBytes and GBytes
using the suffix b, k, m or g.
.RE
.TP
.B Sessions stressor
.RS 5
.TQ
.B \-\-session N
start N workers that create child and grandchild processes that set and
get their session ids. 25% of the grandchild processes are not waited for
by the child to create orphaned sessions that need to be reaped by init.
.TP
.B \-\-session\-ops N
stop session workers after N child processes are spawned and reaped.
.RE
.TP
.B Setting data in the Kernel stressor
.RS 5
.TQ
.B \-\-set N
start N workers that call system calls that try to set data in the kernel,
currently these are: setgid(2), sethostname(2), setpgid(2), setpgrp(2),
setuid(2), setgroups(2), setreuid(2), setregid(2), setresuid(2), setresgid(2)
and setrlimit(2).  Some of these system calls are OS specific.
.TP
.B \-\-set\-ops N
stop set workers after N bogo set operations.
.RE
.TP
.B Shellsort stressor
.RS 5
.TQ
.B \-\-shellsort N
start N workers that sort 32 bit integers using shellsort(3).
.TP
.B \-\-shellsort\-ops N
stop shellsort stress workers after N bogo shellsorts.
.TP
.B \-\-shellsort\-size N
specify number of 32 bit integers to sort, default is 262144 (256 \(mu 1024).
.RE
.TP
.B POSIX shared memory stressor
.RS 5
.TQ
.B \-\-shm N
start N workers that open and allocate shared memory objects using the POSIX
shared memory interfaces.  By default, the test will repeatedly create and
destroy 32 shared memory objects, each of which is 8 MB in size.
.TP
.B \-\-shm\-bytes N
specify the size of the POSIX shared memory objects to be created. One can
specify the size as % of total available memory or in units of Bytes, KBytes,
MBytes and GBytes using the suffix b, k, m or g.
.TP
.B \-\-shm\-mlock
attempt to mlock(2) shared memory objects into memory causing more memory pressure by
preventing pages from swapped out.
.TP
.B \-\-shm\-objs N
specify the number of shared memory objects to be created.
.TP
.B \-\-shm\-ops N
stop after N POSIX shared memory create and destroy bogo operations are
complete.
.RE
.TP
.B System V shared memory stressor
.RS 5
.TQ
.TP
.B \-\-shm\-sysv N
start N workers that allocate shared memory using the System V shared memory
interface.  By default, the test will repeatedly create and destroy 8 shared
memory segments, each of which is 8 MB in size.
.TP
.B \-\-shm\-sysv\-bytes N
specify the size of the shared memory segment to be created. One can specify
the size as % of total available memory or in units of Bytes, KBytes, MBytes
and GBytes using the suffix b, k, m or g.
.TP
.B \-\-shm\-sysv\-mlock
attempt to mlock(2) shared memory segment into memory causing more memory pressure by
preventing pages from swapped out.
.TP
.B \-\-shm\-sysv\-ops N
stop after N shared memory create and destroy bogo operations are complete.
.TP
.B \-\-shm\-sysv\-segs N
specify the number of shared memory segments to be created. The default is
8 segments.
.RE
.TP
.B SIGABRT stressor
.RS 5
.TQ
.B \-\-sigabrt N
start N workers that create children that are killed by SIGABRT signals or
by calling abort(3).
.TP
.B \-\-sigabrt\-ops N
stop the sigabrt workers after N SIGABRT signals are successfully handled.
.RE
.TP
.B SIGBUS stressor
.RS 5
.TQ
.B \-\-sigbus N
start N workers that rapidly create and catch bus errors generated
via misaligned access and accessing a file backed memory mapping that
does not have file storage to back the page being accessed.
.TP
.B \-\-sigbus\-ops N
stop sigbus stress workers after N bogo bus errors.
.RE
.TP
.B SIGCHLD stressor
.RS 5
.TQ
.B \-\-sigchld N
start N workers that create children to generate SIGCHLD signals. This exercises
children that exit (CLD_EXITED), get killed (CLD_KILLED), get stopped
(CLD_STOPPED) or continued (CLD_CONTINUED).
.TP
.B \-\-sigchld\-ops N
stop the sigchld workers after N SIGCHLD signals are successfully handled.
.RE
.TP
.B SIGFD stressor (Linux)
.RS 5
.TQ
.B \-\-sigfd N
start N workers that generate SIGRT signals and are handled by reads by a child
process using a file descriptor set up using signalfd(2).  (Linux only). This
will generate a heavy context switch load when all CPUs are fully loaded.
.TP
.B \-\-sigfd\-ops
stop sigfd workers after N bogo SIGUSR1 signals are sent.
.RE
.TP
.B SIGFPE stressor
.RS 5
.TQ
.B \-\-sigfpe N
start N workers that rapidly cause division by zero SIGFPE faults.
.TP
.B \-\-sigfpe\-ops N
stop sigfpe stress workers after N bogo SIGFPE faults.
.RE
.TP
.B SIGHUP stressor
.RS 5
.TQ
.B \-\-sighup N
start N workers that generate SIGHUP signals using raise(2) and by killing
a group leader process with a child process indirectly receiving SIGHUP when it loses
the group leader.
.TP
.B \-\-sighup\-ops N
stop sighup stressor workers after N SIGHUP signals
.RE
.TP
.B SIGILL stressor
.RS 5
.TQ
.B \-\-sigill N
start N workers that execute illegal instructions to generate SIGILL
signals.
.TP
.B \-\-sigill\-ops N
stop sigill stressor workers after N SIGILL signals
.RE
.TP
.B SIGIO stressor
.RS 5
.TQ
.B \-\-sigio N
start N workers that read data from a child process via a pipe and generate
SIGIO signals. This exercises asynchronous I/O via SIGIO.
.TP
.B \-\-sigio\-ops N
stop sigio stress workers after handling N SIGIO signals.
.RE
.TP
.B System signals stressor
.RS 5
.TQ
.B \-\-signal N
start N workers that exercise the signal system call three different signal
handlers, SIG_IGN (ignore), a SIGCHLD handler and SIG_DFL (default action).
For the SIGCHLD handler, the stressor sends itself a SIGCHLD signal and checks
if it has been handled. For other handlers, the stressor checks that the
SIGCHLD handler has not been called.  This stress test calls the signal system
call directly when possible and will try to avoid the C library attempt to
replace signal with the more modern sigaction system call.
.TP
.B \-\-signal\-ops N
stop signal stress workers after N rounds of signal handler setting.
.RE
.TP
.B Nested signal handling stressor
.RS 5
.TQ
.B \-\-signest N
start N workers that exercise nested signal handling. A signal is raised and
inside the signal handler a different signal is raised, working through a
list of signals to exercise. An alternative signal stack is used that is
large enough to handle all the nested signal calls.  The \-v option will
log the approximate size of the stack required and the average stack size
per nested call.
.TP
.B \-\-signest\-ops N
stop after handling N nested signals.
.RE
.TP
.B Pending signals stressor
.RS 5
.TQ
.B \-\-sigpending N
start N workers that check if SIGUSR1 signals are pending. This stressor masks
SIGUSR1, generates a SIGUSR1 signal and uses sigpending(2) to see if the signal
is pending. Then it unmasks the signal and checks if the signal is no longer
pending.
.TP
.B \-\-sigpending\-ops N
stop sigpending stress workers after N bogo sigpending pending/unpending checks.
.RE
.TP
.B SIGPIPE stressor
.RS 5
.TQ
.B \-\-sigpipe N
start N workers that repeatedly spawn off child process that exits before a
parent can complete a pipe write, causing a SIGPIPE signal.  The child
process is either spawned using clone(2) if it is available or use the slower
fork(2) instead.
.TP
.B \-\-sigpipe\-ops N
stop N workers after N SIGPIPE signals have been caught and handled.
.RE
.TP
.B Signal queueing stressor
.RS 5
.TQ
.B \-\-sigq N
start N workers that rapidly send SIGUSR1 signals using sigqueue(3) to child
processes that wait for the signal via sigwaitinfo(2).
.TP
.B \-\-sigq\-ops N
stop sigq stress workers after N bogo signal send operations.
.RE
.TP
.B Real-time signals stressor
.RS 5
.TQ
.B \-\-sigrt N
start N workers that each create child processes to handle SIGRTMIN to
SIGRMAX real time signals. The parent sends each child process a RT signal
via siqueue(2) and the child process waits for this via sigwaitinfo(2).
When the child receives the signal it then sends a RT signal to one of the
other child processes also via sigqueue(2).
.TP
.B \-\-sigrt\-ops N
stop sigrt stress workers after N bogo sigqueue signal send operations.
.RE
.TP
.B SIGSEGV stressor
.RS 5
.TQ
.B \-\-sigsegv N
start N workers that rapidly create and catch segmentation faults generated
via illegal memory access, illegal vdso system calls, illegal port reads,
illegal interrupts or access to x86 time stamp counter.
.TP
.B \-\-sigsegv\-ops N
stop sigsegv stress workers after N bogo segmentation faults.
.RE
.TP
.B Waiting for process signals stressor
.RS 5
.TQ
.B \-\-sigsuspend N
start N workers that each spawn off 4 child processes that wait for a SIGUSR1
signal from the parent using sigsuspend(2). The parent sends SIGUSR1 signals
to each child in rapid succession.  Each sigsuspend wakeup is counted as one
bogo operation.
.TP
.B \-\-sigsuspend\-ops N
stop sigsuspend stress workers after N bogo sigsuspend wakeups.
.RE
.TP
.B SIGTRAP stressor
.RS 5
.TQ
.B \-\-sigtrap N
start N workers that exercise the SIGTRAP signal. For systems that support
SIGTRAP, the signal is generated using raise(SIGTRAP). Only x86 Linux systems
the SIGTRAP is also generated by an int 3 instruction.
.TP
.B \-\-sigtrap\-ops N
stop sigtrap stress workers after N SIGTRAP signals have been handled.
.RE
.TP
.B SIGURG stressor
.RS 5
.TQ
.B \-\-sigurg N
start workers that exercise the SIGURG signal by sending out-of-band data
over a TCP/IP IPv4 socket stream.
.TP
.B \-\-sigurg\-ops N
stop sigurg stressor workers after N SIGURG signals have been handled.
.RE
.TP
.B SIGVTARLM stressor
.RS 5
.TQ
.B \-\-sigvtalrm N
start N workers that exercise the SIGVTALRM signal using an ITIMER_VIRTUAL
itimer and a busy loop that consumes CPU time calling getitimer for the
ITIMER_VIRTUAL timer.
.TP
.B \-\-sigvtalrm\-ops N
stop sigvtalrm stress workers after N SIGVTALRM signals have been handled.
.RE
.TP
.B SIGXCPU stressor
.RS 5
.TQ
.B \-\-sigxcpu N
start N workers that exercise the SIGXCPU stressor. A busy loop generates
SIGXCPU signals by setting a 0 second run time limit followed by a sched_yield(2)
call.
.TP
.B \-\-sigxcpu\-ops N
stop sigsxcpu stress workers after N bogo SIGXCPU signal attempts.
.RE
.TP
.B SIGXFSZ stressor
.RS 5
.TQ
.B \-\-sigxfsz N
start N workers that exercise the SIGXFSZ stressor. A random 32 bit file
size limit is set and data is written outside this size limit to generate
a SIGXFSZ signal.
.TP
.B \-\-sigxfsz\-ops N
stop sigsxfsz stress workers after N bogo SIGXFSZ signal attempts.
.RE
.TP
.B Random memory and processor cache line stressor via a skiplist
.RS 5
.TQ
.B \-\-skiplist N
start N workers that store and then search for integers using a skiplist.
By default, 65536 integers are added and searched.  This is a useful method
to exercise random access of memory and processor cache.
.TP
.B \-\-skiplist\-ops N
stop the skiplist worker after N skiplist store and search cycles are completed.
.TP
.B \-\-skiplist\-size N
specify the size (number of integers) to store and search in the skiplist. Size can
be from 1 K to 4 M.
.RE
.TP
.B Time interrupts and context switches stressor
.RS 5
.TQ
.B \-\-sleep N
start N workers that spawn off multiple threads that each perform multiple
sleeps of ranges 1us to 0.1s.  This creates multiple context switches and
timer interrupts.
.TP
.B \-\-sleep\-max P
start P threads per worker. The default is 1024, the maximum allowed is
30000.
.TP
.B \-\-sleep\-ops N
stop after N sleep bogo operations.
.RE
.TP
.B System management interrupts (SMI) stressor
.RS 5
.TQ
.B \-\-smi N
start N workers that attempt to generate system management interrupts (SMIs)
into the x86 ring -2 system management mode (SMM) by exercising the advanced
power management (APM) port 0xb2. This requires the \-\-pathological option and
root privilege and is only implemented on x86 Linux platforms. This probably
does not work in a virtualized environment.  The stressor will attempt to
determine the time stolen by SMIs with some na\[:i]ve benchmarking.
.TP
.B \-\-smi\-ops N
stop after N attempts to trigger the SMI.
.RE
.TP
.B Network socket stressor
.RS 5
.TQ
.B \-S N, \-\-sock N
start N workers that perform various socket stress activity. This involves a
pair of client/server processes performing rapid connect, send and receives
and disconnects on the local host.
.TP
.B \-\-sock\-domain D
specify the domain to use, the default is ipv4. Currently ipv4, ipv6 and unix
are supported.
.TP
.B \-\-sock\-if NAME
use network interface NAME. If the interface NAME does not exist, is not
up or does not support the domain then the loopback (lo) interface is used as the default.
.TP
.B \-\-sock\-msgs N
send N messages per connect, send/receive, disconnect iteration. The default is 1000
messages. If N is too small then the rate is throttled back by the overhead of
socket connect and disconnect (on Linux, one needs to increase /proc/sys/net/netfilter/nf_conntrack_max
to allow more connections).
.TP
.B \-\-sock\-nodelay
This disables the TCP Nagle algorithm, so data segments are always sent
as soon as possible.  This stops data from being buffered before being
transmitted, hence resulting in poorer network utilisation and more context
switches between the sender and receiver.
.TP
.B \-\-sock\-ops N
stop socket stress workers after N bogo operations.
.TP
.B \-\-sock\-opts [ random | send | sendmsg | sendmmsg ]
by default, messages are sent using send(2). This option allows one to specify
the sending method using send(2), sendmsg(2), sendmmsg(2) or a random selection
of one of these 3 on each iteration.  Note that sendmmsg is only available for
Linux systems that support this system call.
.TP
.B \-\-sock\-port P
start at socket port P. For N socket worker processes, ports P to P \(mi 1 are
used.
.TP
.B \-\-sock\-protocol P
Use the specified protocol P, default is tcp. Options are tcp and mptcp (if
supported by the operating system).
.TP
.B \-\-sock\-type [ stream | seqpacket ]
specify the socket type to use. The default type is stream. seqpacket currently
only works for the unix socket domain.
.TP
.B \-\-sock\-zerocopy
enable zerocopy for send and recv calls if the MSG_ZEROCOPY is supported.
.RE
.TP
.B Socket abusing stressor
.RS 5
.TQ
.B \-\-sockabuse N
start N workers that abuse a socket file descriptor with various file based
system that don't normally act on sockets. The kernel should handle these
illegal and unexpected calls gracefully.
.TP
.B \-\-sockabuse\-ops N
stop after N iterations of the socket abusing stressor loop.
.TP
.B \-\-sockabuse\-port P
start at socket port P. For N sockabuse worker processes, ports P to P \(mi 1 are
used.
.RE
.TP
.B Socket diagnostic stressor (Linux)
.RS 5
.TQ
.B \-\-sockdiag N
start N workers that exercise the Linux sock_diag netlink socket diagnostics
(Linux only).  This currently requests diagnostics using UDIAG_SHOW_NAME,
UDIAG_SHOW_VFS, UDIAG_SHOW_PEER, UDIAG_SHOW_ICONS, UDIAG_SHOW_RQLEN and
UDIAG_SHOW_MEMINFO for the AF_UNIX family of socket connections.
.TP
.B \-\-sockdiag\-ops N
stop after receiving N sock_diag diagnostic messages.
.RE
.TP
.B Socket file descriptor stressor
.RS 5
.TQ
.B \-\-sockfd N
start N workers that pass file descriptors over a UNIX domain socket using the
CMSG(3) ancillary data mechanism. For each worker, pair of client/server
processes are created, the server opens as many file descriptors on /dev/null
as possible and passing these over the socket to a client that reads these from
the CMSG data and immediately closes the files.
.TP
.B \-\-sockfd\-ops N
stop sockfd stress workers after N bogo operations.
.TP
.B \-\-sockfd\-port P
start at socket port P. For N socket worker processes, ports P to P \(mi 1 are
used.
.TP
.B \-\-sockfd\-reuse
reuse the file descriptor by passing it back from the receiver to the
sender and re-sending it again rather than opening /dev/null each time.
.RE
.TP
.B Opening network socket stressor
.RS 5
.TQ
.B \-\-sockmany N
start N workers that use a client process to attempt to open as many as 100000
TCP/IP socket connections to a server on port 10000.
.TP
.B \-\-sockmany\-if NAME
use network interface NAME. If the interface NAME does not exist, is not
up or does not support the domain then the loopback (lo) interface is used as the default.
.TP
.B \-\-sockmany\-ops N
stop after N connections.
.TP
.B \-\-sockmany\-port P
start at socket port P. For N sockmany worker processes, ports P to P \(mi 1 are
used.
.RE
.TP
.B Socket I/O stressor
.RS 5
.TQ
.B \-\-sockpair N
start N workers that perform socket pair I/O read/writes. This involves a pair
of client/server processes performing randomly sized socket I/O operations.
.TP
.B \-\-sockpair\-ops N
stop socket pair stress workers after N bogo operations.
.RE
.TP
.B Softlockup stressor
.RS 5
.TQ
.B \-\-softlockup N
start N workers that flip between with the "real-time" SCHED_FIO and SCHED_RR
scheduling policies at the highest priority to force softlockups. This can
only be run with CAP_SYS_NICE capability and for best results the number of
stressors should be at least the number of online CPUs. Once running, this is
practically impossible to stop and it will force softlockup issues and may
trigger watchdog timeout reboots.
.TP
.B \-\-softlockup\-ops N
stop softlockup stress workers after N bogo scheduler policy changes.
.RE
.TP
.B Sparse matrix stressor
.RS 5
.TQ
.B \-\-sparsematrix N
start N workers that exercise 3 different sparse matrix implementations
based on hashing, Judy array (for 64 bit systems), 2-d circular linked-lists,
memory mapped 2-d matrix (non-sparse), quick hashing (on preallocated nodes)
and red-black tree.
The sparse matrix is populated with values, random values potentially
non-existing values are read, known existing values are read and known
existing values are marked as zero. This default 500 \(mu 500 sparse matrix
is used and 5000 items are put into the sparse matrix making it 2% utilized.
.TP
.B \-\-sparsematrix\-items N
populate the sparse matrix with N items. If N is greater than the number
of elements in the sparse matrix than N will be capped to create at 100%
full sparse matrix.
.TP
.B \-\-sparsematrix\-method [ all | hash | hashjudy | judy | list | mmap | qhash | rb ]
specify the type of sparse matrix implementation to use. The `all' method
uses all the methods and is the default.
.sp
.TS
lB2 lB
l lx.
Method	Description
all	T{
exercise with all the sparsematrix stressor methods (see below):
T}
hash	T{
use a hash table and allocate nodes on the heap for each unique value at a (x, y)
matrix position.
T}
hashjudy	T{
use a hash table for x coordinates and a Judy array for y coordinates for values
at a (x, y) matrix position.
T}
judy	T{
use a Judy array with a unique 1-to-1 mapping of (x, y) matrix position into
the array.
T}
list	T{
use a circular linked-list for sparse y positions each with circular linked-lists for
sparse x positions for the (x, y) matrix coordinates.
T}
mmap	T{
use a non-sparse mmap the entire 2-d matrix space. Only (x, y) matrix positions that
are referenced will get physically mapped. Note that large sparse matrices cannot be mmap'd
due to lack of virtual address limitations, and too many referenced pages can trigger
the out of memory killer on Linux.
T}
qhash	T{
use a hash table with pre-allocated nodes for each unique value. This is a quick hash
table implementation, nodes are not allocated each time with calloc and are allocated
from a pre-allocated pool leading to quicker hash table performance than the hash method.
T}
rb	T{
use a red-black balanced tree using one tree node for each unique value at a (x, y)
matrix position.
T}
splay	T{
use a splay tree using one tree node for each unique value at a (x, y) matrix
position.
T}
.TE
.TP
.B \-\-sparsematrix\-ops N
stop after N sparsematrix test iterations.
.TP
.B \-\-sparsematrix\-size N
use a N \(mu N sized sparse matrix
.RE
.TP
.B POSIX process spawn (posix_spawn) stressor (Linux)
.RS 5
.TQ
.B \-\-spawn N
start N workers continually spawn children using posix_spawn(3) that exec
stress\-ng and then exit almost immediately. Currently Linux only.
.TP
.B \-\-spawn\-ops N
stop spawn stress workers after N bogo spawns.
.RE
.TP
.B Spinmem stressor
.RS 5
.TQ
.B \-\-spinmem N
start N workers that use a shared memory page to keep two processes synchronized
using busy spin loops. One process is a writer that increments a value in memory slot 0
and spin waits for the data to appear in memory slot 1. The other process spin waits
for the data to change in slot 0 and copies the changed value into memory slot 1.
The stressor benchmarks the time for the transactions to occur between both
processes. Note that the optimal number of stressors is half the number of online
CPUs in a system. By default 32 bit write/reads are used.
.TP
.B \-\-spinmem\-affinity
move spinmem stressor processes to randomly selected CPUs every million spinmem transactions.
.TP
.B \-\-spinmem\-method [ 8bit | 16bit | 32bit | 64bit | 128bit ]
select the size of the memory write/reads, the default is 32 bit. 128 bit read/writes
may not be supported by some toolchains.
.TP
.B \-\-spinmem\-numa
assign shared memory page to randomly selected NUMA nodes. This is disabled
for systems that do not support NUMA.
.TP
.B \-\-spinmem\-ops N
stop after N spinmem bogo operations. A bogo operation is 1000 transactions betewen
the two spinmem processes.
.TP
.B \-\-spinmem\-yield
force scheduling yields after each spinmem read/write operation
.RE
.TP
.B Splice stressor (Linux)
.RS 5
.TQ
.B \-\-splice N
move data from /dev/zero to /dev/null through a pipe without any copying
between kernel address space and user address space using splice(2). This is
only available for Linux.
.TP
.B \-\-splice\-bytes N
transfer N bytes per splice call, the default is 64 K. One can specify the size
as % of total available memory or in units of Bytes, KBytes, MBytes and GBytes
using the suffix b, k, m or g.
.TP
.B \-\-splice\-ops N
stop after N bogo splice operations.
.RE
.TP
.B Stack stressor
.RS 5
.TQ
.B \-\-stack N
start N workers that rapidly cause and catch stack overflows by use of
large recursive stack allocations.  Much like the brk stressor, this can eat
up pages rapidly and may trigger the kernel OOM killer on the process,
however, the killed stressor is respawned again by a monitoring parent
process.
.TP
.B \-\-stack\-fill
the default action is to touch the lowest page on each stack allocation. This
option touches all the pages by filling the new stack allocation with zeros
which forces physical pages to be allocated and hence is more aggressive.
.TP
.B \-\-stack\-mlock
attempt to mlock(2) stack pages into memory causing more memory pressure by
preventing pages from swapped out.
.TP
.B \-\-stack\-ops N
stop stack stress workers after N bogo stack overflows.
.TP
.B \-\-stack\-pageout
force stack pages out to swap (available when madvise(2) supports MADV_PAGEOUT).
.TP
.B \-\-stack\-unmap
unmap a single page in the middle of a large buffer allocated on the stack on each
stack allocation. This forces the stack mapping into multiple separate
allocation mappings.
.RE
.TP
.B Dirty page and stack exception stressor
.RS 5
.TQ
.B \-\-stackmmap N
start N workers that use a 2 MB stack that is memory mapped onto a temporary
file. A recursive function works down the stack and flushes dirty stack pages
back to the memory mapped file using msync(2) until the end of the stack is
reached (stack overflow). This exercises dirty page and stack exception handling.
.TP
.B \-\-stackmmap\-ops N
stop workers after N stack overflows have occurred.
.RE
.TP
.B Statmount and listmount system call stressor
.RS 5
.TQ
.B \-\-statmount N
start N workers that find mounts on / via listmount and get mount information
on the mount IDs using statmount. (Linux only).
.TP
.B \-\-statmount\-ops N
stop workers after iterating on mounts N times.
.RE
.TP
.B Libc string functions stressor
.RS 5
.TQ
.B \-\-str N
start N workers that exercise various libc string functions on random strings.
.TP
.B \-\-str\-method strfunc
select a specific libc string function to stress. Available string functions to
stress are: all, index, rindex, strcasecmp, strcat, strchr, strcoll, strcmp,
strcpy, strlen, strncasecmp, strncat, strncmp, strrchr and strxfrm.  See
string(3) for more information on these string functions.  The `all' method is
the default and will exercise all the string methods.
.TP
.B \-\-str\-ops N
stop after N bogo string operations.
.RE
.TP
.B STREAM memory stressor
.RS 5
.TQ
.B \-\-stream N
start N workers exercising a memory bandwidth stressor very loosely based on the
STREAM "Sustainable Memory Bandwidth in High Performance Computers" benchmarking
tool by John D. McCalpin, Ph.D. This stressor allocates buffers that are at
least 4 times the size of the CPU L2 cache and continually performs rounds of
following computations on large arrays of double precision floating point numbers:
.sp
.TS
lB2 lB
l lx.
Operation	Description
copy	T{
c[i] \(eq a[i]
T}
scale	T{
b[i] \(eq scalar \(mu c[i]
T}
add	T{
c[i] \(eq a[i] \(pl b[i]
T}
triad	T{
a[i] \(eq b[i] \(pl (c[i] \(mu scalar)
T}
.TE
.RS
.PP
Since this is loosely based on a variant of the STREAM benchmark code,
DO NOT submit results based on this as it is intended to in stress\-ng just
to stress memory and compute and NOT intended for STREAM accurate
tuned or non-tuned benchmarking whatsoever. Use the official STREAM
benchmarking tool if you desire accurate and standardised STREAM benchmarks.
.PP
The stressor calculates the memory read rate, memory write rate and floating
point operations rate. These will differ from the maximum theoretical
read/write/compute rates because of loop overheads and the use of volatile
pointers to ensure the compiler does not optimize out stores.
.RE
.TP
.B \-\-stream\-index N
specify number of stream indices used to index into the data arrays a, b and
c.  This adds indirection into the data lookup by using randomly shuffled
indexing into the three data arrays. Level 0 (no indexing) is the default,
and 3 is where all 3 arrays are indexed via 3 different randomly shuffled
indexes. The higher the index setting the more impact this has on L1, L2
and L3 caching and hence forces higher memory read/write latencies.
.TP
.B \-\-stream\-l3\-size N
Specify the CPU Level 3 cache size in bytes.  One can specify the size in
units of Bytes, KBytes, MBytes and GBytes using the suffix b, k, m or g.
If the L3 cache size is not provided, then stress\-ng will attempt to
determine the cache size, and failing this, will default the size to 4 MB.
.TP
.B \-\-stream\-mlock
attempt to mlock(2) the stream buffers into memory to prevent them from being
swapped out.
.TP
.B \-\-stream\-madvise [ collapse | hugepage | nohugepage | normal ]
Specify the madvise(2) options used on the memory mapped buffer used in the
stream stressor. Non-linux systems will only have the `normal' madvise
advice. The default is `normal'.
.TP
.B \-\-stream\-ops N
stop after N stream bogo operations, where a bogo operation is one round
of copy, scale, add and triad operations.
.TP
.B \-\-stream\-prefetch
compilers such as gcc have optimization options to insert prefetching
into memory fetch loops that may improve read performance. This option
enables this optimization, however, it may lead to degraded performance
if the compiler does not insert the prefetching in the correct places.
Best to enable this for the default \-\-stream\-index 0 setting.
.RE
.TP
.B Swap partitions stressor (Linux)
.RS 5
.TQ
.B \-\-swap N
start N workers that add and remove small randomly sizes swap partitions
(Linux only).  Note that if too many swap partitions are added then the
stressors may exit with exit code 3 (not enough resources).  Requires
CAP_SYS_ADMIN to run.
.TP
.B \-\-swap\-ops N
stop the swap workers after N swapon/swapoff iterations.
.TP
.B \-\-swap\-self
attempt to swap out pages of the stressor.
.RE
.TP
.B Context switching between mutually tied processes stressor
.RS 5
.TQ
.B \-s N, \-\-switch N
start N workers that force context switching between two mutually
blocking/unblocking tied processes. By default message passing over
a pipe is used, but different methods are available.
.TP
.B \-\-switch\-freq F
run the context switching at the frequency of F context switches per
second. Note that the specified switch rate may not be achieved
because of CPU speed and memory bandwidth limitations.
.TP
.B \-\-switch\-method [ mq | pipe | sem\-sysv ]
select the preferred context switch block/run synchronization method, these
are as follows:
.sp
.TS
lB2 lB
l lx.
Method	Description
mq	T{
use posix message queue with a 1 item size. Messages are passed between
a sender and receiver process.
T}
pipe	T{
single character messages are passed down a single character
sized pipe between a sender and receiver process.
T}
sem\-sysv	T{
a SYSV semaphore is used to block/run two processes.
T}
.TE
.TP
.B \-\-switch\-ops N
stop context switching workers after N bogo operations.
.RE
.TP
.B Symlink stressor
.RS 5
.TQ
.B \-\-symlink N
start N workers creating and removing symbolic links.
.TP
.B \-\-symlink\-ops N
stop symlink stress workers after N bogo operations.
.TP
.B \-\-symlink\-sync
sync dirty data and metadata to disk.
.RE
.TP
.B Partial file syncing (sync_file_range) stressor
.RS 5
.TQ
.B \-\-sync\-file N
start N workers that perform a range of data syncs across a file using
sync_file_range(2).  Three mixes of syncs are performed, from start to the end
of the file,  from end of the file to the start, and a random mix. A random
selection of valid sync types are used, covering the SYNC_FILE_RANGE_WAIT_BEFORE,
SYNC_FILE_RANGE_WRITE and SYNC_FILE_RANGE_WAIT_AFTER flag bits.
.TP
.B \-\-sync\-file\-bytes N
specify the size of the file to be sync'd. One can specify the size as % of free
space on the file system in units of Bytes, KBytes, MBytes and GBytes using the
suffix b, k, m or g.
.TP
.B \-\-sync\-file\-ops N
stop sync\-file workers after N bogo sync operations.
.RE
.TP
.B CPU synchronized loads stressor
.RS 5
.TQ
.B \-\-syncload N
start N workers that produce sporadic short lived loads synchronized across N
stressor processes. By default repeated cycles of 125ms busy load followed by 62.5ms sleep
occur across all the workers in step to create bursts of load to exercise C state
transitions and CPU frequency scaling. The busy load and sleeps have \(+-10% jitter
added to try exercising scheduling patterns.
.TP
.B \-\-syncload\-msbusy M
specify the busy load duration in milliseconds.
.TP
.B \-\-syncload\-mssleep M
specify the sleep duration in milliseconds.
.TP
.B \-\-syncload\-ops N
stop syncload workers after N load/sleep cycles.
.RE
.TP
.B System calls bad address and fault handling stressor
.RS 5
.TQ
.B \-\-sysbadaddr N
start N workers that pass bad addresses to system calls to exercise bad address
and fault handling. The addresses used are null pointers, read only pages,
write only pages, unmapped addresses, text only pages, unaligned addresses and top of
memory addresses.
.TP
.B \-\-sysbadaddr\-ops N
stop the sysbadaddr stressors after N bogo system calls.
.RE
.TP
.B System calls stressor
.RS 5
.TQ
.B \-\-syscall N
start N workers that exercise a range of available system calls. System calls
that fail due to lack of capabilities or errors are ignored. The stressor will
try to maximize the rate of system calls being executed based the entire time
taken to setup, run and cleanup after each system call.
.TP
.B \-\-syscall\-method method
select the choice of system calls to executed based on the fastest test duration times.
Note that this includes the time to setup, execute the system call and cleanup afterwards.
The available methods are as follows:
.sp
.TS
lB lB
l lx.
Method	Description
all	select all the available system calls
fast10	select the fastest 10% system call tests
fast25	select the fastest 25% system call tests
fast50	select the fastest 50% system call tests
fast75	select the fastest 75% system call tests
fast90	select the fastest 90% system call tests
geomean1	T{
select tests that are less or equal to the
geometric mean of all the test times
T}
geomean1	T{
select tests that are less or equal to 2 \(mu the
geometric mean of all the test times
T}
geomean1	T{
select tests that are less or equal to 3 \(mu the
geometric mean of all the test times
T}
.TE
.TP
.B \-\-syscall\-ops N
stop after N system calls
.TP
.B \-\-sycsall\-top N
report the fastest top N system calls. Setting N to zero will report all
the system calls that could be exercised.
.RE
.TP
.B System information stressor
.RS 5
.TQ
.B \-\-sysinfo N
start N workers that continually read system and process specific information.
This reads the process user and system times using the times(2) system call.
For Linux systems, it also reads overall system statistics using the sysinfo(2)
system call and also the file system statistics for all mounted file systems
using statfs(2).
.TP
.B \-\-sysinfo\-ops N
stop the sysinfo workers after N bogo operations.
.RE
.TP
.B System calls with invalid arguments stressor (Linux)
.RS 5
.TQ
.B \-\-sysinval N
start N workers that exercise system calls in random order with permutations
of invalid arguments to force kernel error handling checks. The stress test
autodetects system calls that cause processes to crash or exit prematurely
and will blocklist these after several repeated breakages. System call
arguments that cause system calls to work successfully are also detected an
blocklisted too.  Linux only.
.TP
.B \-\-sysinval\-ops N
stop sysinval workers after N system call attempts.
.RE
.TP
.B /sys stressor (Linux)
.RS 5
.TQ
.B \-\-sysfs N
start N workers that recursively read files from /sys (Linux only).  This may
cause specific kernel drivers to emit messages into the kernel log.
.TP
.B \-\-sysfs\-ops N
stop sysfs reading after N bogo read operations. Note, since the number of
entries may vary between kernels, this bogo ops metric is probably very
misleading.
.RE
.TP
.B Tee stressor (Linux)
.RS 5
.TQ
.B \-\-tee N
move data from a writer process to a reader process through pipes and to
/dev/null without any copying between kernel address space and user address
space using tee(2). This is only available for Linux.
.TP
.B \-\-tee\-ops N
stop after N bogo tee operations.
.RE
.TP
.B Timer event stressor (Linux)
.RS 5
.TQ
.B \-T N, \-\-timer N
start N workers creating timer events at a default rate of 1 MHz (Linux only);
this can create a many thousands of timer clock interrupts. Each timer event
is caught by a signal handler and counted as a bogo timer op.
.TP
.B \-\-timer\-freq F
run timers at F Hz; range from 1 to 1000000000 Hz (Linux only). By selecting
an appropriate frequency stress\-ng can generate hundreds of thousands of
interrupts per second.  Note: it is also worth using \-\-timer\-slack 0 for
high frequencies to stop the kernel from coalescing timer events.
.TP
.B \-\-timer\-ops N
stop timer stress workers after N bogo timer events (Linux only).
.TP
.B \-\-timer\-rand
select a timer frequency based around the timer frequency \(+-12.5% random
jitter. This tries to force more variability in the timer interval to make the
scheduling less predictable.
.RE
.TP
.B Timerfd stressor (Linux)
.RS 5
.TQ
.B \-\-timerfd N
start N workers creating timerfd events at a default rate of 1 MHz (Linux
only); this can create a many thousands of timer clock events. Timer events
are waited for on the timer file descriptor using select(2) and then read and
counted as a bogo timerfd op.
.TP
.B \-\-timerfs\-fds N
try to use a maximum of N timerfd file descriptors per stressor.
.TP
.B \-\-timerfd\-freq F
run timers at F Hz; range from 1 to 1000000000 Hz (Linux only). By selecting
an appropriate frequency stress\-ng can generate hundreds of thousands of
interrupts per second.
.TP
.B \-\-timerfd\-ops N
stop timerfd stress workers after N bogo timerfd events (Linux only).
.TP
.B \-\-timerfd\-rand
select a timerfd frequency based around the timer frequency \(+-12.5% random
jitter. This tries to force more variability in the timer interval to make the
scheduling less predictable.
.RE
.TP
.B Timer Mix stressor
.RS 5
.TQ
.B \-\-timermix N
start N workers creating timer and itimer signals at a high rate, this can
create a many thousands of timer clock interrupts per second. Each signal
that gets handled is counted as a bogo-operation. For timers, the following
clocks types (where available) are used: CLOCK_REALTIME, CLOCK_MONOTONIC,
CLOCK_PROCESS_CPUTIME_ID, CLOCK_THREAD_CPUTIME_ID, CLOCK_BOOTTIME and
CLOCK_TAI. For itimers, the following interval timer types are
used: ITIMER_REAL, ITIMER_VIRTUAL and ITIMER_PROF. Some systems may support
none or a subset of these timer or itimer types. The freqeuency of the
itimers is auto-adjusted to try and maximize the timer interrupt rate.
.TP
.B \-\-timermix\-ops N
stop after N signals from timers and itimers.
.RE
.TP
.B Time warp stressor
.RS 5
.TQ
.B \-\-time\-warp N
start N workers that read the system time and where appropriate for monotonic
clocks perform a check for reverse time warping. At the end of the run there are time
wrap-around checks. This stressor exercises clock_gettime(2) on all
available clocks, gettimeofday(2), time(2) and getrusage(2) to check for
unexpected time behaviour. Note that only some clocks are reliably monotonic.
.TP
.B \-\-time\-warp\-ops N
stop after N rounds of checking all the available clocks and time fetching
system calls.
.RE
.TP
.B Translation lookaside buffer shootdowns stressor
.RS 5
.TQ
.B \-\-tlb\-shootdown N
start N workers that force Translation Lookaside Buffer (TLB) shootdowns.
This is achieved by creating up to 16 child processes that all share a
region of memory and these processes are shared amongst the available
CPUs.  The processes adjust the page mapping settings causing TLBs to
be force flushed on the other processors, causing the TLB shootdowns.
.TP
.B \-\-tlb\-shootdown\-ops N
stop after N bogo TLB shootdown operations are completed.
.RE
.TP
.B Tmpfs stressor
.RS 5
.TQ
.B \-\-tmpfs N
start N workers that create a temporary file on an available tmpfs
file system and perform various file based mmap operations upon it.
.TP
.B \-\-tmpfs\-mmap\-async
enable file based memory mapping and use asynchronous msync'ing on each page,
see \-\-tmpfs\-mmap\-file.
.TP
.B \-\-tmpfs\-mmap\-file
enable tmpfs file based memory mapping and by default use synchronous
msync'ing on each page.
.TP
.B \-\-tmpfs\-ops N
stop tmpfs stressors after N bogo mmap operations.
.RE
.TP
.B Touching files stressor
.RS 5
.TQ
.B \-\-touch N
touch files by using open(2) or creat(2) and then closing and unlinking them. The
filename contains the bogo-op number and is incremented on each touch operation,
hence this fills the dentry cache. Note that the user time and system time may be very low
as most of the run time is waiting for file I/O and this produces very large bogo-op
rates for the very low CPU time used.
.TP
.B \-\-touch\-method [ random | open | creat ]
select the method the file is created, either randomly using open(2) or create(2), just
using open(2) with the O_CREAT open flag, or with creat(2).
.TP
.B \-\-touch\-ops N
stop the touch workers after N file touches.
.TP
.B \-\-touch\-opts [ all | direct | dsync | excl | noatime | sync ]
specify various file open options as a comma separated list. Options are as
follows:
.sp
.TS
lB lB
l lx.
Option	Description
all	T{
use all the open options, namely direct, dsync, excl, noatime and sync
T}
direct	T{
try to minimize cache effects of the I/O to and from this file, using the O_DIRECT open flag.
T}
dsync	T{
ensure output has been transferred to underlying hardware and file metadata
has been updated using the O_DSYNC open flag.
T}
excl	T{
fail if file already exists (it should not).
T}
noatime	T{
do not update the file last access time if the file is read.
T}
sync	T{
ensure output has been transferred to underlying hardware using the O_SYNC open flag.
T}
.TE
.RE
.TP
.B Tree data structures stressor
.RS 5
.TQ
.B \-\-tree N
start N workers that exercise tree data structures. The default is
to add, find and remove 250000 64 bit integers into AVL (avl),
Red-Black (rb), Splay (splay), btree and binary trees.  The intention of
this stressor is to exercise memory and cache with the various tree
operations.
.TP
.B \-\-tree\-method [ all | avl | binary | btree | rb | splay ]
specify the tree to be used. By default, all the trees are
used (the `all' option).
.TP
.B \-\-tree\-ops N
stop tree stressors after N bogo ops. A bogo op covers the addition,
finding and removing all the items into the tree(s).
.TP
.B \-\-tree\-size N
specify the size of the tree, where N is the number of 64 bit integers
to be added into the tree.
.RE
.TP
.B Trigonometric functions stressor
.RS 5
.TQ
.B \-\-trig N
start N workers that exercise sin, cos, sincos (where available) and tan
libm trigonometric functions using float, double and long double floating point
variants. Each function is exercised 10000 times per bogo-operation.
.TP
.B \-\-trig\-method function
specify a trigonometric stress function. By default, all the functions are exercised
sequentially, however one can specify just one function to be used if required.
Available options are as follows:
.sp
.TS
lB2 lB
l lx.
Method	Description
all	T{
iterate through all of the following trigonometric functions
T}
cos	T{
cosine (double precision)
T}
cosf	T{
cosine (float precision)
T}
cosl	T{
cosine (long double precision)
T}
sin	T{
sine (double precision)
T}
sinf	T{
sine (float precision)
T}
sinl	T{
sine (long double precision)
T}
sincos	T{
sine and cosine (double precision)
T}
sincosf	T{
sine and cosine (float precision)
T}
sincosl	T{
sine and cosine (long double precision)
T}
tan	T{
tangent (double precision)
T}
tanf	T{
tangent (float precision)
T}
tanl 	T{
tangent (long double precision)
T}
.TE
.TP
.B \-\-trig\-ops N
stop after N bogo-operations.
.RE
.TP
.B Time stamp counter (TSC) stressor
.RS 5
.TQ
.B \-\-tsc N
start N workers that read the Time Stamp Counter (TSC) 256 times per loop
iteration (bogo operation).  This exercises the tsc instruction for x86,
the mftb instruction for ppc64, the rdcycle instruction for RISC-V,
the tick instruction on SPARC and the rdtime.d instruction for Loong64.
.TP
.B \-\-tsc\-lfence
add lfence after each tsc read to force serialization (x86 only).
.TP
.B \-\-tsc\-ops N
stop the tsc workers after N bogo operations are completed.
.TP
.B \-\-tsc\-rdtscp
use the rdtscp instruction instead of rdtsc (x86 only). This also disables
the \-\-tsc\-lfence option.
.RE
.TP
.B Binary tree stressor
.RS 5
.TQ
.B \-\-tsearch N
start N workers that insert, search and delete 32 bit integers on a binary
tree using tsearch(3), tfind(3) and tdelete(3). By default, there are 65536
randomized integers used in the tree.  This is a useful method to exercise
random access of memory and processor cache.
.TP
.B \-\-tsearch\-ops N
stop the tsearch workers after N bogo tree operations are completed.
.TP
.B \-\-tsearch\-size N
specify the size (number of 32 bit integers) in the array to tsearch. Size
can be from 1 K to 4 M.
.RE
.TP
.B Network tunnel stressor
.RS 5
.TQ
.B \-\-tun N
start N workers that create a network tunnel device and sends and receives
packets over the tunnel using UDP and then destroys it. A new random
192.168.*.* IPv4 address is used each time a tunnel is created.
.TP
.B \-\-tun\-ops N
stop after N iterations of creating/sending/receiving/destroying a tunnel.
.TP
.B \-\-tun\-tap
use network tap device using level 2 frames (bridging) rather than a tun device
for level 3 raw packets (tunnelling).
.RE
.TP
.B UDP network stressor
.RS 5
.TQ
.B \-\-udp N
start N workers that transmit data using UDP. This involves a pair of
client/server processes performing rapid connect, send and receives and
disconnects on the local host.
.TP
.B \-\-udp\-domain D
specify the domain to use, the default is ipv4. Currently ipv4 and ipv6 are
supported.
.TP
.B \-\-udp\-gro
enable UDP-GRO (Generic Receive Offload) if supported.
.TP
.B \-\-udp\-if NAME
use network interface NAME. If the interface NAME does not exist, is not
up or does not support the domain then the loopback (lo) interface is used as the default.
.TP
.B \-\-udp\-lite
use the UDP-Lite (RFC 3828) protocol (only for ipv4 and ipv6 domains).
.TP
.B \-\-udp\-ops N
stop udp stress workers after N bogo operations.
.TP
.B \-\-udp\-port P
start at port P. For N udp worker processes, ports P to P \(mi 1 are used. By
default, ports 7000 upwards are used.
.RE
.TP
.B UDP flooding stressor
.RS 5
.TQ
.B \-\-udp\-flood N
start N workers that attempt to flood the host with UDP packets to random
ports. The IP address of the packets are currently not spoofed. This is only
available on systems that support AF_PACKET.
.TP
.B \-\-udp\-flood\-domain D
specify the domain to use, the default is ipv4. Currently ipv4 and ipv6 are
supported.
.TP
.B \-\-udp\-flood\-if NAME
use network interface NAME. If the interface NAME does not exist, is not
up or does not support the domain then the loopback (lo) interface is used as the default.
.TP
.B \-\-udp\-flood\-ops N
stop udp-flood stress workers after N bogo operations.
.RE
.TP
.B File umask stressor
.RS 5
.TQ
.B \-\-umask N
start N workers that exercise setting umask and creating/fstat'ing/closing/unlinking a
file and checking the file mode is set correctly. This exercises umask mask values
from octal 0000 to 0777 inclusive.
.TP
.B \-\-umask\-ops N
stop after N rounds of exercising umask values 0000 to 0777.
.RE
.TP
.B Umount stressor
.RS 5
.TQ
.B \-\-umount N
start N workers that exercise mounting and racying unmounting of small tmpfs and ramfs
file systems. Three child processes are invoked, one to mount, another to force umount
and a third to exercise /proc/mounts. Small random delays are used between mount and
umount calls to try to trigger race conditions on the umount calls.
.TP
.B \-\-umount\-ops N
stop umount workers after N successful bogo mount/umount operations.
.RE
.TP
.B Unlink stressor
.RS 5
.TQ
.B \-\-unlink N
start N workers that each run 4 processes per worker that create, open, unlink
and close 1024 files in randomized order to exercise unlinking (removal) of
files. This attempts to create races on file creation, linking and unlinking.
.TP
.B \-\-unlink\-ops N
stop after N bogo rounds of unlink operations on 1024 files by the
controlling worker.
.RE
.TP
.B Unshare stressor (Linux)
.RS 5
.TQ
.B \-\-unshare N
start N workers that each fork off 32 child processes, each of which exercises
the unshare(2) system call by disassociating parts of the process execution
context. (Linux only).
.TP
.B \-\-unshare\-ops N
stop after N bogo unshare operations.
.RE
.TP
.B Uprobe stressor (Linux)
.RS 5
.TQ
.B \-\-uprobe N
start N workers that trace the entry to libc function getpid(2) using the
Linux uprobe kernel tracing mechanism. This requires CAP_SYS_ADMIN
capabilities and a modern Linux uprobe capable kernel.
.TP
.B \-\-uprobe\-ops N
stop uprobe tracing after N trace events of the function that is being traced.
.RE
.TP
.B /dev/urandom stressor (Linux)
.RS 5
.TQ
.B \-u N, \-\-urandom N
start N workers reading /dev/urandom (Linux only). This will load the kernel
random number source.
.TP
.B \-\-urandom\-ops N
stop urandom stress workers after N urandom bogo read operations (Linux only).
.RE
.TP
.B Page faults stressor (Linux)
.RS 5
.TQ
.B \-\-userfaultfd N
start N workers that generate write page faults on a small anonymously mapped
memory region and handle these faults using the user space fault handling via
the userfaultfd(2) mechanism.  This will generate a large quantity of major page
faults and also context switches during the handling of the page faults.
(Linux only).
.TP
.B \-\-userfaultfd\-bytes N
mmap N bytes per userfaultfd worker to page fault on, the default is 16 MB.
One can specify the size as % of total available memory or in units of Bytes,
KBytes, MBytes and GBytes using the suffix b, k, m or g.
.TP
.B \-\-userfaultfd\-ops N
stop userfaultfd stress workers after N page faults.
.RE
.TP
.B SYGSYS stressor
.RS 5
.TQ
.B \-\-usersyscall N
start N workers that exercise the Linux prctl userspace system call
mechanism. A userspace system call is handled by a SIGSYS signal handler
and exercised with the system call disabled (ENOSYS) and enabled
(via SIGSYS) using prctl PR_SET_SYSCALL_USER_DISPATCH.
.TP
.B \-\-usersyscall\-ops N
stop after N successful userspace syscalls via a SIGSYS signal handler.
.RE
.TP
.B File timestamp stressor
.RS 5
.TQ
.B \-\-utime N
start N workers updating file timestamps. This is mainly CPU bound when the
default is used as the system flushes metadata changes only periodically.
.TP
.B \-\-utime\-fsync
force metadata changes on each file timestamp update to be flushed to disk.
This forces the test to become I/O bound and will result in many dirty metadata
writes.
.TP
.B \-\-utime\-ops N
stop utime stress workers after N utime bogo operations.
.RE
.TP
.B Virtual dynamic shared object stressor
.RS 5
.TQ
.B \-\-vdso N
start N workers that repeatedly call each of the system call functions in the
vDSO (virtual dynamic shared object).  The vDSO is a shared library that the
kernel maps into the address space of all user-space applications to allow
fast access to kernel data to some system calls without the need of
performing an expensive system call.
.TP
.B \-\-vdso\-func F
Instead of calling all the vDSO functions, just call the vDSO function F. The
functions depend on the kernel being used, but are typically clock_gettime(2),
getcpu(2), gettimeofday(2) and time(2).
.TP
.B \-\-vdso\-ops N
stop after N vDSO functions calls.
.RE
.TP
.B Vector integer comparison operations stressor
.RS 5
.TQ
.B \-\-veccmp N
start N workers that perform various unsigned integer math comparison operations on
various 128 bit vectors. A mix of integer vector comparison operations are performed
on the following vectors: 16 \(mu 8 bits, 8 \(mu 16 bits, 4 \(mu 32 bits, 2 \(mu 64
bits and if supported 1 \(mu 128 bits. The metrics produced by this mix depend on the
processor architecture and the vector math optimisations produced by the compiler.
.TP
.B \-\-veccmp\-ops N
stop after N bogo vector integer comparison operations.
.RE
.TP
.B Vector floating point operations stressor
.RS 5
.TQ
.B \-\-vecfp N
start N workers that exericise floating point (single and double precision)
addition, multiplication, division and negation on vectors of 128, 64, 32,
16 and 8 floating point values. The -v option will show the approximate
throughput in millions of floating pointer operations per second for each
operation.  For x86, the gcc/clang target clones attribute has been used to
produced vector optimizations for a range of mmx, sse, avx and processor
features.
.TP
.B \-\-vecfp\-method method
specify a vecfp stress method. By default, all the stress methods are exercised
sequentially, however one can specify just one method to be used if required.
.sp
.TS
lB2 lB
l lx.
Method	Description
all	T{
iterate through all of the following vector methods
T}
floatv128add	T{
addition of a vector of 128 single precision floating point values
T}
floatv64add	T{
addition of a vector of 64 single precision floating point values
T}
floatv32add	T{
addition of a vector of 32 single precision floating point values
T}
floatv16add 	T{
addition of a vector of 16 single precision floating point values
T}
floatv8add	T{
addition of a vector of 8 single precision floating point values
T}
floatv128mul	T{
multiplication of a vector of 128 single precision floating point values
T}
floatv64mul	T{
multiplication of a vector of 64 single precision floating point values
T}
floatv32mul	T{
multiplication of a vector of 32 single precision floating point values
T}
floatv16mul	T{
multiplication of a vector of 16 single precision floating point values
T}
floatv8mul	T{
multiplication of a vector of 8 single precision floating point values
T}
floatv128div	T{
division of a vector of 128 single precision floating point values
T}
floatv64div	T{
division of a vector of 64 single precision floating point values
T}
floatv32div	T{
division of a vector of 32 single precision floating point values
T}
floatv16div	T{
division of a vector of 16 single precision floating point values
T}
floatv8div	T{
division of a vector of 8 single precision floating point values
T}
doublev128add	T{
addition of a vector of 128 double precision floating point values
T}
doublev64add	T{
addition of a vector of 64 double precision floating point values
T}
doublev32add	T{
addition of a vector of 32 double precision floating point values
T}
doublev16add	T{
addition of a vector of 16 double precision floating point values
T}
doublev8add	T{
addition of a vector of 8 double precision floating point values
T}
doublev128mul	T{
multiplication of a vector of 128 double precision floating point values
T}
doublev64mul	T{
multiplication of a vector of 64 double precision floating point values
T}
doublev32mul	T{
multiplication of a vector of 32 double precision floating point values
T}
doublev16mul	T{
multiplication of a vector of 16 double precision floating point values
T}
doublev8mul	T{
multiplication of a vector of 8 double precision floating point values
T}
doublev128div	T{
division of a vector of 128 double precision floating point values
T}
doublev64div	T{
division of a vector of 64 double precision floating point values
T}
doublev32div	T{
division of a vector of 32 double precision floating point values
T}
doublev16div	T{
division of a vector of 16 double precision floating point values
T}
doublev8div	T{
division of a vector of 8 double precision floating point values
T}
doublev128neg	T{
negation of a vector of 128 double precision floating point values
T}
doublev64neg	T{
negation of a vector of 64 double precision floating point values
T}
doublev32neg	T{
negation of a vector of 32 double precision floating point values
T}
doublev16neg	T{
negation of a vector of 16 double precision floating point values
T}
doublev8neg	T{
negation of a vector of 8 double precision floating point values
T}
.TE
.TP
.B -\-vecfp\-ops N
stop after N vector floating point bogo-operations. Each bogo-op is equivalent
to 65536 loops of 2 vector operations. For example, one bogo-op on a 16 wide vector
is equivalent to 65536 \(mu 2 \(mu 16 floating point operations.
.RE
.TP
.B Vector math operations stressor
.RS 5
.TQ
.B \-\-vecmath N
start N workers that perform various unsigned integer math operations on
various 128 bit vectors. A mix of vector math operations are performed on the
following vectors: 16 \(mu 8 bits, 8 \(mu 16 bits, 4 \(mu 32 bits, 2 \(mu 64
bits and where supported 1 \(mu 128 bits. The metrics produced by this mix depend
on the processor architecture and the vector math optimisations produced by the
compiler.
.TP
.B \-\-vecmath\-ops N
stop after N bogo vector integer math operations.
.RE
.TP
.B Shuffled vector math operations stressor
.RS 5
.TQ
.B \-\-vecshuf N
start N workers that shuffle data on various 64 byte vectors comprised of
8, 16, 32, 64 and 128 bit unsigned integers. The integers are shuffled
around the vector with 4 shuffle operations per loop, 65536 loops make
up one bogo-op of shuffling. The data shuffling rates and shuffle operation
rates are logged when using the \-v option.  This stressor exercises vector
load, shuffle/permute, packing/unpacking and store operations.
.TP
.B \-\-vecshuf\-method method
specify a vector shuffling stress method. By default, all the stress
methods are exercised sequentially, however one can specify just one
method to be used if required.
.sp
.TS
lB2 lb
l lx.
Method	Description
all	T{
iterate through all of the following vector methods
T}
u8x64	T{
shuffle a vector of 64 unsigned 8 bit integers
T}
u16x32	T{
shuffle a vector of 32 unsigned 16 bit integers
T}
u32x16	T{
shuffle a vector of 16 unsigned 32 bit integers
T}
u64x8	T{
shuffle a vector of 8 unsigned 64 bit integers
T}
u128x4	T{
shuffle a vector of 4 unsigned 128 bit integers (when supported)
T}
.TE
.TP
.B \-\-vecshuf\-ops N
stop after N bogo vector shuffle ops. One bogo-op is equavlent of 4 \(mu
65536 vector shuffle operations on 64 bytes of vector data.
.RE
.TP
.B Wide vector math operations stressor
.RS 5
.TQ
.B \-\-vecwide N
start N workers that perform various 8 bit math operations on vectors
of 4, 8, 16, 32, 64, 128, 256, 512, 1024 and 2048 bytes. With the -v option
the relative compute performance vs the expected compute performance based
on total run time is shown for the first vecwide worker. The vecwide stressor
exercises various processor vector instruction mixes and how well the
compiler can map the vector operations to the target instruction set.
.TP
.B \-\-vecwide\-ops N
stop after N bogo vector operations (2048 iterations of a mix of vector
instruction operations).
.RE
.TP
.B File based authenticy protection (verity) stressor
.RS 5
.TQ
.B \-\-verity N
start N workers that exercise read-only file based authenticy protection
using the verity ioctls FS_IOC_ENABLE_VERITY and FS_IOC_MEASURE_VERITY.
This requires file systems with verity support (currently ext4 and f2fs
on Linux) with the verity feature enabled. The test attempts to creates
a small file with multiple small extents and enables verity on the file
and verifies it. It also checks to see if the file has verity enabled
with the FS_VERITY_FL bit set on the file flags.
.TP
.B \-\-verity\-ops N
stop the verity workers after N file create, enable verity, check verity
and unlink cycles.
.RE
.TP
.B vfork stressor
.RS 5
.TQ
.B \-\-vfork N
start N workers continually vforking children that immediately exit.
.TP
.B \-\-vfork\-max P
create P processes and then wait for them to exit per iteration. The default
is just 1; higher values will create many temporary zombie processes that are
waiting to be reaped. One can potentially fill up the process table using
high values for \-\-vfork\-max and \-\-vfork.
.TP
.B \-\-vfork\-ops N
stop vfork stress workers after N bogo operations.
.RE
.TP
.B vfork processes as much as possible stressor
.RS 5
.TQ
.B \-\-vforkmany N
start N workers that spawn off a chain of vfork children until the process
table fills up and/or vfork fails.  vfork can rapidly create child processes
and the parent process has to wait until the child dies, so this stressor
rapidly fills up the process table.
.TP
.B \-\-vforkmany\-ops N
stop vforkmany stressors after N vforks have been made.
.TP
.B \-\-vforkmany\-vm
enable detrimental performance virtual memory advice using madvise(2) on
all pages of the vforked process. Where possible this will try to set
every page in the new process with using madvise(2) MADV_MERGEABLE,
MADV_WILLNEED, MADV_HUGEPAGE and MADV_RANDOM flags. Linux only.
.TP
.B \-\-vforkmany\-vm\-bytes N
mmap N bytes per vm worker for more memory pressure, the default is 64 MB. This
also enables the \-\-vforkmany\-vm option.  One can specify the size
as % of total available memory or in units of Bytes, KBytes, MBytes and GBytes
using the suffix b, k, m or g.
.RE
.TP
.B Memory allocate and write stressor
.RS 5
.TQ
.B \-m N, \-\-vm N
start N workers continuously calling mmap(2)/munmap(2) and writing to the
allocated memory. Note that this can cause systems to trip the kernel OOM
killer on Linux systems if not enough physical memory and swap is not
available.
.TP
.B \-\-vm\-bytes N
mmap N bytes in total, this is shared by each vm worker, the default is 256 MB.
One can specify the size as % of total available memory or in units of Bytes,
KBytes, MBytes and GBytes using the suffix b, k, m or g.
.TP
.B \-\-vm\-flush
cache flush mapped memory after each memory region has been completely
written to.
.TP
.B \-\-vm\-hang N
sleep N seconds before unmapping memory, the default is zero seconds.
Specifying 0 will do an infinite wait.
.TP
.B \-\-vm\-keep
do not continually unmap and map memory, just keep on re-writing to it.
.TP
.B \-\-vm\-locked
Lock the pages of the mapped region into memory using mmap MAP_LOCKED (since
Linux 2.5.37).  This is similar to locking memory as described in mlock(2).
.TP
.B \-\-vm\-madvise advice
Specify the madvise `advice' option used on the memory mapped regions used in
the vm stressor. Non-linux systems will only have the `normal' madvise
advice, linux systems support `collapse', `dontneed', `hugepage', `mergeable'
, `nohugepage', `normal', `random', `sequential', `unmergeable'
and `willneed' advice. If this option is not used then the default is to pick
random madvise advice for each mmap call. See madvise(2) for more details.
.TP
.B \-\-vm\-method method
specify a vm stress method. By default, all the stress methods are exercised
sequentially, however one can specify just one method to be used if required.
Each of the vm workers have 3 phases:
.RS
.PP
1. Initialised. The anonymously memory mapped region is set to a known pattern.
.PP
2. Exercised. Memory is modified in a known predictable way. Some vm workers
alter memory sequentially, some use small or large strides to step along memory.
.PP
3. Checked. The modified memory is checked to see if it matches the expected
result.
.PP
The vm methods containing `prime' in their name have a stride of the largest
prime less than 2\[ua]64, allowing to them to thoroughly step through memory and
touch all locations just once while also doing without touching memory cells
next to each other. This strategy exercises the cache and page non-locality.
.PP
Since the memory being exercised is virtually mapped then there is no
guarantee of touching page addresses in any particular physical order.  These
workers should not be used to test that all the system's memory is working
correctly either, use tools such as memtest86 instead.
.PP
The vm stress methods are intended to exercise memory in ways to possibly find
memory issues and to try to force thermal errors.
.PP
Available vm stress methods are described as follows:
.sp
.TS
lB2 lB
l lx.
Method	Description
all	T{
iterate over all the vm stress methods as listed below.
T}
cache\-lines	T{
work through memory in 64 byte cache sized steps writing a single byte
per cache line. Once the write is complete, the memory is read to verify
the values are written correctly.
T}
cache\-stripe	T{
work through memory in 64 byte cache sized chunks, writing in ascending
address order on even offsets and descending address order on odd offsets.
T}
checkboard	T{
work through memory writing alternative zero/one bit values into memory
in a mixed checkerboard pattern. Memory is swapped around to ensure every
bit is read, bit flipped and re-written and then re-read for verification.
T}
flip	T{
sequentially work through memory 8 times, each time just one bit in memory
flipped (inverted). This will effectively invert each byte in 8 passes.
T}
fwdrev	T{
write to even addressed bytes in a forward direction and odd addressed bytes
in reverse direction. rhe contents are sanity checked once all the addresses
have been written to.
T}
galpat\-0	T{
galloping pattern zeros. This sets all bits to 0 and flips just 1 in 4096 bits
to 1. It then checks to see if the 1s are pulled down to 0 by their neighbours
or of the neighbours have been pulled up to 1.
T}
galpat\-1	T{
galloping pattern ones. This sets all bits to 1 and flips just 1 in 4096 bits
to 0. It then checks to see if the 0s are pulled up to 1 by their neighbours
or of the neighbours have been pulled down to 0.
T}
gray	T{
fill the memory with sequential gray codes (these only change 1 bit at a time
between adjacent bytes) and then check if they are set correctly.
T}
grayflip	T{
fill memory with adjacent bytes of gray code and inverted gray code pairs
to change as many bits at a time between adjacent bytes and check if
these are set correctly.
T}
incdec	T{
work sequentially through memory twice, the first pass increments each byte by
a specific value and the second pass decrements each byte back to the original
start value. The increment/decrement value changes on each invocation of the
stressor.
T}
inc\-nybble	T{
initialise memory to a set value (that changes on each invocation of the
stressor) and then sequentially work through each byte incrementing the bottom
4 bits by 1 and the top 4 bits by 15.
T}
lfsr32	T{
fill memory with values generated from a 32 bit Galois linear feedback shift
register using the polynomial  x\[ua]32 \(pl x\[ua]31 \(pl x\[ua]29 \(pl x \(pl 1. This
generates a ring of  2\[ua]32 \(mi 1 unique values (all 32 bit values except
for 0).
T}
modulo\-x	T{
fill memory over 23 iterations. Each iteration starts one byte further along
from the start of the memory and steps along in 23 byte strides. In each
stride, the first byte is set to a random pattern and all other bytes are set
to the inverse.  Then it checks see if the first byte contains the expected
random pattern. This exercises cache store/reads as well as seeing if
neighbouring cells influence each other.
T}
move\-inv	T{
sequentially fill memory 64 bits of memory at a time with random values, and
then check if the memory is set correctly.  Next, sequentially invert each 64
bit pattern and again check if the memory is set as expected.
T}
mscan	T{
fill each bit in each byte with 1s then check these are set, fill each bit
in each byte with 0s and check these are clear.
T}
one\-zero	T{
set all memory bits to one and then check if any bits are not one. Next, set
all the memory bits to zero and check if any bits are not zero.
T}
prime\-0	T{
iterate 8 times by stepping through memory in very large prime strides clearing
just on bit at a time in every byte. Then check to see if all bits are set to
zero.
T}
prime\-1	T{
iterate 8 times by stepping through memory in very large prime strides setting
just on bit at a time in every byte. Then check to see if all bits are set to
one.
T}
prime\-gray\-0	T{
first step through memory in very large prime strides clearing just on bit
(based on a gray code) in every byte. Next, repeat this but clear the other
7 bits. Then check to see if all bits are set to zero.
T}
prime\-gray\-1	T{
first step through memory in very large prime strides setting just on bit
(based on a gray code) in every byte. Next, repeat this but set the other 7
bits. Then check to see if all bits are set to one.
T}
prime\-incdec	T{
step through memory in large prime steps incrementing bytes and then re-do
again decrementing bytes.
T}
rand\-set	T{
sequentially work through memory in 64 bit chunks setting bytes in the chunk
to the same 8 bit random value.  The random value changes on each chunk.
Check that the values have not changed.
T}
rand\-sum	T{
sequentially set all memory to random values and then summate the number of
bits that have changed from the original set values.
T}
read64	T{
sequentially read memory using 32 \(mu 64 bit reads per bogo loop. Each loop
equates to one bogo operation.  This exercises raw memory reads.
T}
ror	T{
fill memory with a random pattern and then sequentially rotate 64 bits of
memory right by one bit, then check the final load/rotate/stored values.
T}
rowhammer	T{
try to force memory corruption using the rowhammer memory stressor. This
fetches two 32 bit integers from memory and forces a cache flush on the two
addresses multiple times. This has been known to force bit flipping on some
hardware, especially with lower frequency memory refresh cycles.
T}
swap	T{
fill memory in 64 byte chunks with random patterns. Then swap each 64 chunk
with a randomly chosen chunk. Finally, reverse the swap to put the chunks back
to their original place and check if the data is correct. This exercises
adjacent and random memory load/stores.
T}
walk\-0a	T{
in the given memory mapping, work through a range of specially chosen addresses
working through address lines to see if any address lines are stuck low. This
works best with physical memory addressing, however, exercising these virtual
addresses has some value too.
T}
walk\-0d	T{
for each byte in memory, walk through each data line setting them to low (and
the others are set high) and check that the written value is as expected. This
checks if any data lines are stuck.
T}
walk\-1a	T{
in the given memory mapping, work through a range of specially chosen addresses
working through address lines to see if any address lines are stuck high. This
works best with physical memory addressing, however, exercising these virtual
addresses has some value too.
T}
walk\-1d	T{
for each byte in memory, walk through each data line setting them to high (and
the others are set low) and check that the written value is as expected. This
checks if any data lines are stuck.
T}
walk\-flush	T{
walk through memory a byte at a time writing/flushing/reading 8 bytes of
incrementing 8 bit data. For architectures that support user space cache flushing
this will cause high data cache miss rates.
T}
write64	T{
sequentially write to memory using 32 \(mu 64 bit writes per bogo loop. Each loop
equates to one bogo operation. This exercises raw memory writes. Note that
memory writes are not checked at the end of each test iteration.
T}
write64ds	T{
sequentially write to memory using 32 \(mu 64 bit direct store writes per bogo loop.
Each loop equates to one bogo operation. This exercises cacheless write combining (WC)
memory type protocol for memory writes and is only available on x86
systems with the movediri instruction built with gcc and clang compilers. Note
that memory writes are not checked at the end of each test iteration.
T}
write64nt	T{
sequentially write to memory using 32 \(mu 64 bit non-temporal writes per bogo loop.
Each loop equates to one bogo operation. This exercises cacheless raw memory writes
and is only available on x86 sse2 capable systems built with gcc and clang
compilers. Note that memory writes are not checked at the end of each test iteration.
T}
write1024v	T{
sequentially write to memory using 1 \(mu 1024 bit vector write per bogo loop
(only available if the compiler supports vector types).
Each loop equates to one bogo operation. This exercises raw memory writes.
Note that memory writes are not checked at the end of each test iteration.
T}
wrrd128nt	T{
write to memory in 128 bit chunks using non-temporal writes (bypassing the cache).
Each chunk is written 4 times to hammer the memory. Then check to see if the
data is correct using non-temporal reads if they are available or normal memory reads
if not. Only available with processors that provide non-temporal 128 bit writes.
T}
zero\-one	T{
set all memory bits to zero and then check if any bits are not zero. Next, set
all the memory bits to one and check if any bits are not one.
T}
.TE
.RE
.TP
.B \-\-vm\-numa
assign memory mapped pages to randomly selected NUMA nodes. This is disabled
for systems that do not support NUMA.
.TP
.B \-\-vm\-ops N
stop vm workers after N bogo operations.
.TP
.B \-\-vm\-populate
populate (prefault) page tables for the memory mappings; this can stress
swapping. Only available on systems that support MAP_POPULATE (since Linux
2.5.46).
.RE
.TP
.B Virtual memory addressing stressor
.RS 5
.TQ
.B \-\-vm\-addr N
start N workers that exercise virtual memory addressing using various
methods to walk through a memory mapped address range. This will exercise
mapped private addresses from 8 MB to 64 MB per worker and try to generate
cache and TLB inefficient addressing patterns. Each method will set the
memory to a random pattern in a write phase and then sanity check this
in a read phase.
.TP
.B \-\-vm\-addr\-method method
specify a vm address stress method. By default, all the stress methods are exercised
sequentially, however one can specify just one method to be used if required.
.RS
.PP
Available vm address stress methods are described as follows:
.sp
.TS
lB2 lB
l lx.
Method	Description
all	T{
iterate over all the vm stress methods as listed below.
T}
bitposn	T{
iteratively write to memory in powers of 2 strides of max_stride to 1
and then read check memory in powers of 2 strides 1 to max_stride
where max_stride is half the size of the memory mapped region. All
bit positions of the memory address space are bit flipped in the
striding.
T}
dec	T{
work through the address range backwards sequentially, byte
by byte.
T}
decinv	T{
like dec, but with all the relevant address bits inverted.
T}
flip	T{
address memory using gray coded addresses and their inverse
to flip as many address bits per write/read operation
T}
gray	T{
work through memory with gray coded addresses so that each
change of address just changes 1 bit compared to the previous
address.
T}
grayinv	T{
like gray, but with the all relevant address bits inverted,
hence all bits change apart from 1 in the address range.
T}
inc	T{
work through the address range forwards sequentially, byte
by byte.
T}
incinv 	T{
like inc, but with all the relevant address bits inverted.
T}
pwr2	T{
work through memory addresses in steps of powers of two.
T}
pwr2inv	T{
like pwr2, but with the all relevant address bits inverted.
T}
rev	T{
work through the address range with the bits in the address
range reversed.
T}
revinv	T{
like rev, but with all the relevant address bits inverted.
T}
.TE
.RE
.TP
.B \-\-vm\-addr\-mlock
attempt to mlock(2) pages into memory causing more memory pressure by
preventing pages from swapped out.
.TP
.B \-\-vm\-addr\-numa
assign memory mapped pages to randomly selected NUMA nodes. This is disabled
for systems that do not support NUMA.
.TP
.B \-\-vm\-addr\-ops N
stop N workers after N bogo addressing passes.
.RE
.TP
.B Memory transfer between parent and child processes stressor (Linux)
.RS 5
.TQ
.B \-\-vm\-rw N
start N workers that transfer memory to/from a parent/child using
process_vm_writev(2) and process_vm_readv(2). This is feature is only
supported on Linux.  Memory transfers are only verified if the \-\-verify
option is enabled.
.TP
.B \-\-vm\-rw\-bytes N
mmap N bytes per vm\-rw worker, the default is 16 MB. One can specify the size
as % of total available memory or in units of Bytes, KBytes, MBytes and GBytes
using the suffix b, k, m or g.
.TP
.B \-\-vm\-rw\-ops N
stop vm\-rw workers after N memory read/writes.
.RE
.TP
.B Memory unmap from a child process stressor
.RS 5
.TQ
.B \-\-vm\-segv N
start N workers that create a child process that unmaps its address space
causing a SIGSEGV on return from the unmap.
.TP
.B \-\-vm\-segv\-ops N
stop after N bogo vm\-segv SIGSEGV faults.
.RE
.TP
.B Vmsplice stressor (Linux)
.RS 5
.TQ
.B \-\-vm\-splice N
move data from memory to /dev/null through a pipe without any copying between
kernel address space and user address space using vmsplice(2) and splice(2).
This is only available for Linux.
.TP
.B \-\-vm\-splice\-bytes N
transfer N bytes per vmsplice call, the default is 64 K. One can specify the
size as % of total available memory or in units of Bytes, KBytes, MBytes and
GBytes using the suffix b, k, m or g.
.TP
.B \-\-vm\-splice\-ops N
stop after N bogo vm\-splice operations.
.RE
.TP
.B Virtual Memory Area (VMA) stressor
.RS 5
.TQ
.B \-\-vma N
start M workers that create pthreads to mmap(2), munmap(2), mlock(2),
munlock(2), madvise(2), msync(2), mprotect(2), mincore(2) and access
32 pages in a randomly selected virtual memory address space. This is
designed to trip races on VMA page modifications.  Every 15 seconds a
different virtual address space is randomly chosen.
.TP
.B \-\-vma\-ops N
stop the vma stressors after N successful memory mappings.
.RE
.TP
.B Vector neural network instructions stressor
.RS 5
.TQ
.B \-\-vnni N
start N workers that exercise vector neural network instructions (VNNI) used in
convolutional neural network loops. A 256 byte vector is operated upon
using 8 bit multiply with 16 bit summation, 16 bit multiply and
32 bit summation, and 8 bit summation. When processor features allow,
these operations using 512, 256 and 128 bit vector operations. Generic
non-vectorized code variants also provided (which may be vectorized by
more advanced optimising compilers).
.TP
.B \-\-vnni\-intrinsic
just use the vnni methods that use intrinsic VNNI instructions and ignore
the generic non-vectorized methods.
.TP
.B \-\-vnni\-method N
select the VNNI method to be exercised, may be one of:
.sp
.TS
lB2 lB
l lx.
Method	Description
all	T{
exercise all the following VNNI methods
T}
vpaddb512	T{
8 bit vector addition using 512 bit vector operations on 64 \(mu 8 bit integers, (x86 vpaddb)
T}
vpaddb256	T{
8 bit vector addition using 256 bit vector operations on 32 \(mu 8 bit integers, (x86 vpaddb)
T}
vpaddb128	T{
8 bit vector addition using 128 bit vectors operations on 32 \(mu 8 bit integers, (x86 vpaddb)
T}
vpaddb	T{
8 bit vector addition using 8 bit sequential addition (may be vectorized by the compiler)
T}
vpdpbusd512	T{
8 bit vector multiplication of unsigned and signed 8 bit values followed by 16 bit summation using
512 bit vector operations on 64 \(mu 8 bit integers, (x86 vpdpbusd)
T}
vpdpbusd256	T{
8 bit vector multiplication of unsigned and signed 8 bit values followed by 16 bit summation using
256 bit vector operations on 32 \(mu 8 bit integers, (x86 vpdpbusd)
T}
vpdpbusd128	T{
8 bit vector multiplication of unsigned and signed 8 bit values followed by 16 bit summation using
128 bit vector operations on 32 \(mu 8 bit integers, (x86 vpdpbusd)
T}
vpdpbusd	T{
8 bit vector multiplication of unsigned and signed 8 bit values followed by 16 bit summation using
sequential operations (may be vectorized by the compiler)
T}
vpdpwssd512	T{
16 bit vector multiplication of unsigned and signed 16 bit values followed by 32 bit summation using
512 bit vector operations on 64 \(mu 8 bit integers, (x86 vpdpwssd)
T}
vpdpwssd256	T{
16 bit vector multiplication of unsigned and signed 16 bit values followed by 32 bit summation using
256 bit vector operations on 64 \(mu 8 bit integers, (x86 vpdpwssd)
T}
vpdpwssd128	T{
16 bit vector multiplication of unsigned and signed 16 bit values followed by 32 bit summation using
128 bit vector operations on 64 \(mu 8 bit integers, (x86 vpdpwssd)
T}
vpdpwssd	T{
16 bit vector multiplication of unsigned and signed 16 bit values followed by 32 bit summation using
sequential operations (may be vectorized by the compiler)
T}
.TE
.TP
.B \-\-vnni\-ops N
stop after N bogo VNNI computation operations. 1 bogo-op is equivalent to 1024
convolution loops operating on 256 bytes of data.
.RE
.TP
.B Pausing and resuming threads stressor
.RS 5
.TQ
.B \-\-wait N
start N workers that spawn off two children; one spins in a pause(2) loop, the
other continually stops and continues the first. The controlling process waits
on the first child to be resumed by the delivery of SIGCONT using waitpid(2)
and waitid(2).
.TP
.B \-\-wait\-ops N
stop after N bogo wait operations.
.TP
.RE
.TP
.B CPU wait instruction stressor
.RS 5
.TQ
.B \-\-waitcpu N
start N workers that exercise processor wait instructions. For x86 these
are pause, tpause and umwait (when available) and nop. For ARM the yield
instruction is used. For PPC64 the yield, mdoio and mdooom instructions
are used. For RISC-V the pause instruction is used. For Loong64 the
dbar instruction is used. For other architectures no-op instructions
are used.
.TP
.B \-\-waitcpu\-ops N
stop after N bogo processor wait operations.
.RE
.TP
.B Watchdog stressor
.RS 5
.TQ
.B \-\-watchdog N
start N workers that exercising the /dev/watchdog watchdog interface by
opening it, perform various watchdog specific ioctl(2) commands on the
device and close it.  Before closing the special watchdog magic close
message is written to the device to try and force it to never trip a
watchdog reboot after the stressor has been run.  Note that this stressor
needs to be run as root with the \-\-pathological option and is only
available on Linux.
.TP
.B \-\-watchdog\-ops N
stop after N bogo operations on the watchdog device.
.RE
.TP
.B Libc wide characterstring function stressor
.RS 5
.TQ
.B \-\-wcs N
start N workers that exercise various libc wide character string functions on
random strings.
.TP
.B \-\-wcs\-method wcsfunc
select a specific libc wide character string function to stress. Available
string functions to stress are: all, wcscasecmp, wcscat, wcschr, wcscoll,
wcscmp, wcscpy, wcslen, wcsncasecmp, wcsncat, wcsncmp, wcsrchr and wcsxfrm.
The `all' method is the default and will exercise all the string methods.
.TP
.B \-\-wcs\-ops N
stop after N bogo wide character string operations.
.RE
.TP
.B scheduler workload stressor
.RS 5
.TQ
.B \-\-workload N
start N workers that exercise the scheduler with items of work that
are started at random times with random sleep delays between work items. By
default a 100000 microsecond slice of time has 100 work items
that start at random times during the slice. The work items by default run
for a quanta of 1000 microseconds scaled by the percentage work load (default of 30%).
For a slice of S microseconds and a work item quanta duration of Q microseconds,
S / Q work items are executed per slice. For a work load of L percent, the run time
per item is the quanta Q \(mu L / 100 microseconds.  The \-\-workload\-threads option
allows work items to be taken from a queue and run concurrently if the scheduling
run times overlap.
.br
If a work item is already running when a new work item is scheduled to run then
the new work item is delayed and starts directly after the completion of the
currently running work item when running with the default of zero worker threads.
This emulates bursty scheduled compute, such as handling input packets where
one may have lots of work items bunched together or with random unpredictable
delays between work items.
.TP
.B \-\-workload\-load L
specify the percentage run time load of each work item with respect to the
run quanta duration. Essentially the run duration of each work item is the
quanta duration Q \(mu L / 100.
.TP
.B \-\-workload\-method method
select the workload method. Each quanta of execution time is consumed using
a tight spin-loop executing a workload method. The available methods are
described as follows:
.sp
.TS
lB2 lB
l lx.
Method  Description
all	T{
randomly select any one of all the following methods:
T}
fma	T{
perform multiply-add operations, on modern processors these may be compiled
into fused-multiply-add instructions.
T}
getpid	T{
get the stressor's PID via getpid(2).
T}
time	T{
get the current time via time(2).
T}
inc64	T{
increment a 64 bit integer.
T}
memmove	T{
copy (move) a 1 MB buffer using memmove(3).
T}
memread	T{
read from a 1 MB buffer using fast memory reads.
T}
memset	T{
write to a 1 MB buffer using memset(3).
T}
mcw64	T{
compute 64 bit random numbers using a mwc random generator.
T}
nop	T{
waste cycles using no-op instructions.
T}
pause	T{
stop execution using CPU pause/yield or memory barrier instructions where available.
T}
procname	T{
where possible, change the stressor process name.
T}
random	T{
a random mix of all the workload methods, changing the workload method on every spin-loop.
T}
sqrt	T{
perform double precision floating point sqrt(3) and hypot(3) math operations.
T}
vecfp	T{
perform multiplication and addition on a vector of 64 double precision floating point
values.
T}
.TE
.TP
.B \-\-workload\-sched [ batch | deadline | ext | fifo | idle | other | rr ]
select scheduling policy. Note that deadline, fifo and rr require root privilege.
.TP
.B \-\-workload\-slice\-us S
specify the duration of each scheduling slice in microseconds. The default is
100000 microseconds (0.1 seconds).
.TP
.B \-\-workload\-quanta\-us Q
specify the duration of each work item in microseconds. The default is 1000
microseconds (1 millisecond).
.TP
.B \-\-workload\-threads N
use N process threads to take scheduler work items of a workqueue and run the
work item (default is 2). When N is 0, no threads are used and the work items are
run back-to-back sequentially without using work queue. Using more than 2
threads allows work items to be handled concurrently if enough idle processors
are available.
.TP
.B \-\-workload\-dist [ cluster | even | poisson | random1 | random2 | random3 ]
specify the scheduling distribution of work items, the default is cluster.
The distribution methods are described as follows:
.sp
.TS
lB2 lB
l lx.
Method	Description
cluster	T{
cluster 2/3 of the start times to try to start at the random time during the time slice,
with the other 1/3 of start times evenly randomly distributed using a single random
variable. The clustered start times causes a burst of items to be scheduled in a bunch
with no delays between each clustered work item.
T}
even	T{
evenly distribute scheduling start times across the workload slice
T}
poisson	T{
generate scheduling events that occur individually at random moments, but which
tend to occur at an average rate (known as a Poisson process).
T}
random1	T{
evenly randomly distribute scheduling start times using a single random variable.
T}
random2	T{
randomly distribute scheduling start times using a sum of two random variables, much
like throwing 2 dice.
T}
random3	T{
randomly distribute scheduling start times using a sum of three random variables, much
like throwing 3 dice.
T}
.TE
.TP
.B \-\-workload\-ops N
stop the workload workers after N workload bogo-operations.
.RE
.TP
.B x86 cpuid stressor
.RS 5
.TQ
.B \-\-x86cpuid N
start N workers that exercise the x86 cpuid instruction with 18 different leaf
types.
.TP
.B \-\-x86cpuid\-ops N
stop after N iterations that exercise the different cpuid leaf types.
.RE
.TP
.B x86-64 syscall stressor (Linux)
.RS 5
.TQ
.B \-\-x86syscall N
start N workers that repeatedly exercise the x86-64 syscall instruction to
call the getcpu(2), geteuid(2), getgid(2), getpid(2), gettimeofday(2) and time(2)
system calls using the Linux vsyscall handler. Only for Linux.
.TP
.B \-\-x86syscall\-func F
Instead of exercising the 6 syscall system calls, just call the syscall
function F. The function F must be one of getcpu, geteuid, getgid, getpid,
gettimeofday or time.
.TP
.B \-\-x86syscall\-ops N
stop after N x86syscall system calls.
.RE
.TP
.B Extended file attributes stressor
.RS 5
.TQ
.B \-\-xattr N
start N workers that create, update and delete batches of extended attributes
on a file.
.TP
.B \-\-xattr\-ops N
stop after N bogo extended attribute operations.
.RE
.TP
.B Yield scheduling stressor
.RS 5
.TQ
.B \-y N, \-\-yield N
start N workers that call sched_yield(2). This stressor ensures that at
least 2 child processes per CPU exercise shield_yield(2) no matter how
many workers are specified, thus always ensuring rapid context switching.
.TP
.B \-\-yield\-ops N
stop yield stress workers after N sched_yield(2) bogo operations.
.TP
.B \-\-yield\-procs N
specify the number of child processes to run per stressor instance. The
default is 2, range 1 to 65536.
.TP
.B \-\-yield\-sched [ batch | deadline | ext | fifo | idle | other | rr ]
select scheduling policy. Note that deadline, fifo and rr require root privilege.
.RE
.TP
.B /dev/zero stressor
.RS 5
.TQ
.B \-\-zero N
start N workers that exercise /dev/zero with read(2), lseek(2), ioctl(2) and mmap(2)
calls. For just /dev/zero read benchmarking use the \-\-zero\-read option.
.TP
.B \-\-zero\-ops N
stop zero stress workers after N /dev/zero bogo read operations.
.TP
.B \-\-zero\-read
just read /dev/zero with 4 K reads with no additional exercising on /dev/zero.
.RE
.TP
.B Zlib stressor
.RS 5
.TQ
.B \-\-zlib N
start N workers compressing and decompressing random data using zlib. Each
worker has two processes, one that compresses random data and pipes it to
another process that decompresses the data. This stressor exercises CPU,
cache and memory.
.TP
.B \-\-zlib\-level L
specify the compression level (0..9), where 0 \(eq no compression, 1 \(eq fastest
compression and 9 \(eq best compression.
.TP
.B \-\-zlib\-mem\-level L
specify the reserved compression state memory for zlib.  Default is 8.
.sp
.TS
cB2 lB lB lB
c l s s.
Value
1	minimum memory usage.
9	maximum memory usage.
.TE
.TP
.B \-\-zlib\-method method
specify the type of random data to send to the zlib library.  By default,
the data stream is created from a random selection of the different data
generation processes.  However one can specify just one method to be used if required.
Available zlib data generation methods are described as follows:
.sp
.TS
lB2 lB
l lx.
Method	Description
00ff	T{
randomly distributed 0x00 and 0xFF values.
T}
ascii01	T{
randomly distributed ASCII 0 and 1 characters.
T}
asciidigits	T{
randomly distributed ASCII digits in the range of 0 and 9.
T}
bcd	T{
packed binary coded decimals, 0..99 packed into 2 4-bit nybbles.
T}
binary	T{
32 bit random numbers.
T}
brown	T{
8 bit brown noise (Brownian motion/Random Walk noise).
T}
double	T{
double precision floating point numbers from sin(\(*h).
T}
fixed	T{
data stream is repeated 0x04030201.
T}
gcr	T{
random values as 4 \(mu 4 bit data turned into 4 \(mu 5 bit group coded recording
(GCR) patterns.  Each 5 bit GCR value starts or ends with at most one zero bit
so that concatenated GCR codes have no more than two zero bits in a row.
T}
gray	T{
16 bit gray codes generated from an incrementing counter.
T}
inc16	T{
16 bit incrementing values starting from a random 16 bit value.
T}
latin	T{
Random latin sentences from a sample of Lorem Ipsum text.
T}
lehmer	T{
Fast random values generated using Lehmer's generator using a
128 bit multiply.
T}
lfsr32	T{
Values generated from a 32 bit Galois linear feedback shift register using
the polynomial  x\[ua]32 \(pl x\[ua]31 \(pl x\[ua]29 \(pl x \(pl 1. This generates a
ring of  2\[ua]32 \(mi 1 unique values (all 32 bit values except for 0).
T}
logmap	T{
Values generated from a logistical map of the equation
\[*X]\dn+1\u \(eq r \(mu  \[*X]n \(mu (1 \(mi \[*X]n) where r > \(ap 3.56994567
to produce chaotic data. The values are scaled by a large arbitrary
value and the lower 8 bits of this value are compressed.
T}
lrand48	T{
Uniformly distributed pseudo-random 32 bit values generated from lrand48(3).
T}
morse	T{
Morse code generated from random latin sentences from a sample of Lorem Ipsum text.
T}
nybble	T{
randomly distributed bytes in the range of 0x00 to 0x0f.
T}
objcode	T{
object code selected from a random start point in the stress\-ng text segment.
T}
parity	T{
7 bit binary data with 1 parity bit.
T}
pink	T{
pink noise in the range 0..255 generated using the Gardner method with
the McCartney selection tree optimization. Pink noise is where the power
spectral density is inversely proportional to the frequency of the signal
and hence is slightly compressible.
T}
random	T{
segments of the data stream are created by randomly calling the different data generation
methods.
T}
rarely1	T{
data that has a single 1 in every 32 bits, randomly located.
T}
rarely0	T{
data that has a single 0 in every 32 bits, randomly located.
T}
rdrand	T{
generate random data using rdrand instruction (x86) or use 64 bit mwc psuedo-random
number generator for non-x86 systems.
T}
ror32	T{
generate a 32 bit random value, rotate it right 0 to 7 places
and store the rotated value for each of the rotations.
T}
text	T{
random ASCII text.
T}
utf8	T{
random 8 bit data encoded to UTF-8.
T}
zero	T{
all zeros, compresses very easily.
T}
.TE
.TP
.B \-\-zlib\-ops N
stop after N bogo compression operations, each bogo compression operation
is a compression of 64 K of random data at the highest compression level.
.TP
.B \-\-zlib\-strategy S
specifies the strategy to use when deflating data. This is used to tune the
compression algorithm. Default is 0.
.sp
.TS
cB2 lB lB lB
c l s s.
Value
0	used for normal data (Z_DEFAULT_STRATEGY).
1	for data generated by a filter or predictor (Z_FILTERED)
2	forces huffman encoding (Z_HUFFMAN_ONLY).
3	Limit match distances to one run-length-encoding (Z_RLE).
4	prevents dynamic huffman codes (Z_FIXED).
.TE
.TP
.B \-\-zlib\-stream\-bytes S
specify the amount of bytes to deflate until deflate should finish the block
and return with Z_STREAM_END. One can specify the size in units of Bytes,
KBytes, MBytes and GBytes using the suffix b, k, m or g.
Default is 0 which creates and endless stream until stressor ends.
.sp
.TS
cB2 lB lB lB
c l s s.
Value
0	creates an endless deflate stream until stressor stops.
n	creates an stream of n bytes over and over again.
	Each block will be closed with Z_STREAM_END.
.TE
.TP
.B \-\-zlib\-window\-bits W
specify the window bits used to specify the history buffer size. The value is
specified as the base two logarithm of the buffer size (e.g. value 9 is 2\[ua]9 \(eq
512 bytes). Default is 15.
.sp
.TS
cB2 lB lB lB
c l s s.
Value
-8-(-15)	raw deflate format.
8-15	zlib format.
24-31	gzip format.
40-47	inflate auto format detection using zlib deflate format.
.TE
.RE
.TP
.B Zombie processes stressor
.RS 5
.TQ
.B \-\-zombie N
start N workers that create zombie processes. This will rapidly try to create
a default of 8192 child processes that immediately die and wait in a zombie
state until they are reaped.  Once the maximum number of processes is reached
(or fork fails because one has reached the maximum allowed number of children)
the oldest child is reaped and a new process is then created in a first-in
first-out manner, and then repeated.
.TP
.B \-\-zombie\-max N
try to create as many as N zombie processes. This may not be reached if the
system limit is less than N.
.TP
.B \-\-zombie\-ops N
stop zombie stress workers after N bogo zombie operations.
.RE
.LP
.SH EXAMPLES
.LP
\f[CR]stress\-ng \-\-vm 8 \-\-vm\-bytes 80% -t 1h\f[]
.IP
run 8 virtual memory stressors that combined use 80% of the available memory
for 1 hour. Thus each stressor uses 10% of the available memory.
.LP
\f[CR]stress\-ng \-\-vm 50% -t 1h\f[]
.IP
run virtual memory stressors on 50% of the number of online cpus for 1 hour.
.LP
\f[CR]stress\-ng \-\-vm 200% -t 1h\f[]
.IP
run virtual memory stressors on 2 times the number of online cpus for 1 hour.
.LP
\f[CR]stress\-ng \-\-cpu 4 \-\-io 2 \-\-vm 1 \-\-vm\-bytes 1G \-\-timeout 60s\f[]
.IP
runs for 60 seconds with 4 cpu stressors, 2 io stressors and 1 vm stressor
using 1 GB of virtual memory.
.LP
\f[CR]stress\-ng \-\-iomix 2 \-\-iomix\-bytes 10% -t 10m\f[]
.IP
runs 2 instances of the mixed I/O stressors using a total of 10% of the
available file system space for 10 minutes. Each stressor will use 5% of the
available file system space.
.LP
\f[CR]stress\-ng \-\-with cpu,matrix,vecmath,fp \-\-seq 8 \-t 1m\f[]
.IP
run 8 instances of cpu, matrix, vecmath and fp stressors sequentially one
after another, for 1 minute per stressor.
.LP
\f[CR]stress\-ng --trig 25% --fp 50% --fma 25% -t 5m --verify\f[]
.IP
run trigonometric function stressor on 25% of the online cpus, floating point
stressor on 50% of the online cpus and fused\-multiple\-add stressor on 25% of
the online cpus for 5 minutes and enable verification of results.
.LP
\f[CR]stress\-ng \-\-with cpu,matrix,vecmath,fp \-\-permute 5 \-t 10s\f[]
.IP
run permutations of 5 instances of cpu, matrix, vecmath and fp stressors sequentially one
after another, for 10 seconds per permutation mix.
.LP
\f[CR]stress\-ng \-\-cyclic 1 \-\-cyclic\-dist 2500 \-\-cyclic\-method clock_ns \-\-cyclic\-prio 100 \-\-cyclic\-sleep 10000 \-\-hdd 0 -t 1m\f[]
.IP
measures real time scheduling latencies created by the hdd stressor. This
uses the high resolution nanosecond clock to measure latencies during
sleeps of 10000 nanoseconds. At the end of 1 minute of stressing, the
latency distribution with 2500 ns intervals will be displayed. NOTE: this
must be run with the CAP_SYS_NICE capability to enable the real time scheduling
to get accurate measurements.
.LP
\f[CR]stress\-ng \-\-cpu 8 \-\-cpu\-ops 800000\f[]
.IP
runs 8 cpu stressors and stops after 800000 bogo operations.
.LP
\f[CR]stress\-ng \-\-sequential 2 \-\-timeout 2m \-\-metrics\f[]
.IP
run 2 simultaneous instances of all the stressors sequentially one by one,
each for 2 minutes and summarise with performance metrics at the end.
.LP
\f[CR]stress\-ng \-\-cpu 4 \-\-cpu\-method fft \-\-cpu\-ops 10000 \-\-metrics\-brief\f[]
.IP
run 4 FFT cpu stressors, stop after 10000 bogo operations and produce a
summary just for the FFT results.
.LP
\f[CR]stress\-ng \-\-cpu -1 \-\-cpu\-method all \-t 1h \-\-cpu\-load 90\f[]
.IP
run cpu stressors on all online CPUs working through all the available CPU
stressors for 1 hour, loading the CPUs at 90% load capacity.
.LP
\f[CR]stress\-ng \-\-cpu 0 \-\-cpu\-method all \-t 20m\f[]
.IP
run cpu stressors on all configured CPUs working through all the available CPU
stressors for 20 minutes
.LP
\f[CR]stress\-ng \-\-all 4 \-\-timeout 5m\f[]
.IP
run 4 instances of all the stressors for 5 minutes.
.LP
\f[CR]stress\-ng \-\-random 64\f[]
.IP
run 64 stressors that are randomly chosen from all the available stressors.
.LP
\f[CR]stress\-ng \-\-cpu 64 \-\-cpu\-method all \-\-verify \-t 10m \-\-metrics\-brief\f[]
.IP
run 64 instances of all the different cpu stressors and verify that the
computations are correct for 10 minutes with a bogo operations summary at the
end.
.LP
\f[CR]stress\-ng \-\-sequential -1 \-t 10m\f[]
.IP
run all the stressors one by one for 10 minutes, with the number of instances
of each stressor matching the number of online CPUs.
.LP
\f[CR]stress\-ng \-\-sequential 8 \-\-class io \-t 5m \-\-times\f[]
.IP
run all the stressors in the io class one by one for 5 minutes each, with 8
instances of each stressor running concurrently and show overall time
utilisation statistics at the end of the run.
.LP
\f[CR]stress\-ng \-\-class io\\?\f[]
.IP
show all the stressors in the io class
.LP
\f[CR]sudo stress-ng \-\-class scheduler \-\-seq 0 \-t 1m \-\-taskset-random \-\-progress \-\-klog-check\f[]
.IP
run all the scheduler exercising stressors sequentually on all online CPUs
for 1 minute per stressor type, frequently changing the CPUs that the
processes are running on, show progress and report any detected kernel issues.
.LP
\f[CR]stress\-ng \-\-all -1 \-\-maximize \-\-aggressive\f[]
.IP
run all the stressors (1 instance of each per online CPU) simultaneously, maximize
the settings (memory sizes, file allocations, etc.) and select the most
demanding/aggressive options.
.LP
\f[CR]stress\-ng \-\-all 8 \-\-with cpu,hash,nop,vm \-\-timeout 1m\f[]
.IP
run 8 instances of cpu, hash, nop and vm stressors altogether for 1 minute.
.LP
\f[CR]stress\-ng \-\-seq 8 \-\-with cpu,hash,nop,vm \-\-timeout 1m \-\-progress\f[]
.IP
run 8 instances of cpu, hash, nop and vm stressors one after another for 1 minute
each and show the run progress.
.LP
\f[CR]stress\-ng \-\-random 32 \-x numa,hdd,key\f[]
.IP
run 32 randomly selected stressors and exclude the numa, hdd and key stressors
.LP
\f[CR]stress\-ng \-\-sequential 4 \-\-class vm \-\-exclude bigheap,brk,stack\f[]
.IP
run 4 instances of the VM stressors one after another, excluding the
bigheap, brk and stack stressors
.LP
\f[CR]stress\-ng \-\-taskset 0,2-3 \-\-cpu 3\f[]
.IP
run 3 instances of the CPU stressor and pin them to CPUs 0, 2 and 3.
.LP
\f[CR]stress\-ng \-\-taskset odd \-\-cpu 32\f[]
.IP
run 32 instances of the CPU stressor and pin them to odd numbered CPUs.
.SH EXIT STATUS
.TS
cBw(10) lBx
c l.
Status	Description
0	T{
Success.
T}
1	T{
Error; incorrect user options or a fatal resource issue in the stress\-ng
stressor harness (for example, out of memory).
T}
2	T{
One or more stressors failed.
T}
3	T{
One or more stressors failed to initialise because of lack of resources,
for example ENOMEM (no memory), ENOSPC (no space on file system) or a
missing or unimplemented system call.
T}
4	T{
One or more stressors were not implemented on a specific architecture
or operating system.
T}
5	T{
A stressor has been killed by an unexpected signal.
T}
6	T{
A stressor exited by exit(2) which was not expected and timing metrics
could not be gathered.
T}
7	T{
The bogo ops metrics maybe untrustworthy. This is most likely to occur when
a stress test is terminated during the update of a bogo-ops counter such
as when it has been OOM killed. A less likely reason is that the counter
ready indicator has been corrupted.
T}
.TE
.SH BUGS
File bug reports at: https://github.com/ColinIanKing/stress-ng/issues - please
note that no support will be provided if stress\-ng is packaged without this
manual.
.SH SEE ALSO
.BR cpuburn (1),
.BR perf (1),
.BR stress (1),
.BR taskset (1)
.br
.B https://github.com/ColinIanKing/stress-ng/blob/master/README.md
.SH AUTHOR
stress\-ng was written by Colin Ian King <colin.i.king@gmail.com> and
is a clean room re-implementation and extension of the original
stress tool by Amos Waterland. Thanks also to the many contributors
to stress\-ng. The README.md file in the source contains a full list
of the contributors.
.SH NOTES
Sending a SIGALRM, SIGINT or SIGHUP to stress\-ng causes it to
terminate all the stressor processes and ensures temporary files and
shared memory segments are removed cleanly.
.PP
Sending a SIGUSR2 to stress\-ng will dump out the current load average
and memory statistics.
.PP
Note that the stress\-ng cpu, io, vm and hdd tests are different
implementations of the original stress
tests and hence may produce different stress characteristics.
.PP
The bogo operations metrics may change with each release  because of bug
fixes to the code, new features, compiler optimisations, changes in support
libraries or system call performance.
.SH COPYRIGHT
Copyright \(co 2013-2021 Canonical Ltd, Copyright \(co 2021-2025 Colin Ian King.
.br
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
